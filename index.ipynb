{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Preprocessing with scikit-learn - Cumulative Lab\n", "\n", "## Introduction\n", "In this cumulative lab, you'll practice applying various preprocessing techniques with scikit-learn (`sklearn`) to the Ames Housing dataset in order to prepare the data for predictive modeling. The main emphasis here is on preprocessing (not EDA or modeling theory), so we will skip over most of the visualization and metrics steps that you would take in an actual modeling process.\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "* Practice identifying which preprocessing technique to use\n", "* Practice filtering down to relevant columns\n", "* Practice applying `sklearn.impute` to fill in missing values\n", "* Practice applying `sklearn.preprocessing`:\n", "  * `LabelBinarizer` for converting binary categories to 0 and 1 within a single column\n", "  * `OneHotEncoder` for creating multiple \"dummy\" columns to represent multiple categories\n", "  * `PolynomialFeatures` for creating interaction terms\n", "  * `StandardScaler` for scaling data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Your Task: Prepare the Ames Housing Dataset for Modeling\n", "\n", "![house in Ames](images/ames_house.jpg)\n", "\n", "<span>Photo by <a href=\"https://unsplash.com/@kjkempt17?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Kyle Kempt</a> on <a href=\"https://unsplash.com/s/photos/ames?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Requirements\n", "\n", "#### 1. Drop Irrelevant Columns\n", "\n", "For the purposes of this lab, we will only be using a subset of all of the features present in the Ames Housing dataset. In this step you will drop all irrelevant columns.\n", "\n", "#### 2. Handle Missing Values\n", "\n", "Often for reasons outside of a data scientist's control, datasets are missing some values. In this step you will assess the presence of NaN values in our subset of data, and use `MissingIndicator` and `SimpleImputer` from the `sklearn.impute` submodule to handle any missing values.\n", "\n", "#### 3. Convert Categorical Features into Numbers\n", "\n", "A built-in assumption of the scikit-learn library is that all data being fed into a machine learning model is already in a numeric format, otherwise you will get a `ValueError` when you try to fit a model. In this step you will use a `LabelBinarizer` to replace data within individual non-numeric columns with 0s and 1s, and a `OneHotEncoder` to replace columns containing more than 2 categories with multiple \"dummy\" columns containing 0s and 1s.\n", "\n", "At this point, a scikit-learn model should be able to run without errors!\n", "\n", "#### 4. Add Interaction Terms\n", "\n", "This step gets into the feature engineering part of preprocessing. Does our model improve as we add interaction terms? In this step you will use a `PolynomialFeatures` transformer to augment the existing features of the dataset.\n", "\n", "#### 5. Scale Data\n", "\n", "Because we are using a model with regularization, it's important to scale the data so that coefficients are not artificially penalized based on the units of the original feature. In this step you will use a `StandardScaler` to standardize the units of your data.\n", "\n", "#### 6. Preprocess Test Data\n", "\n", "Apply Steps 1-5 to the test data in order to perform a final model evaluation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Lab Setup\n", "\n", "### Getting the Data\n", "\n", "In the cell below, we import the `pandas` library, open the CSV containing the Ames Housing data as a pandas `DataFrame`, and inspect its contents."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Id</th>\n", "      <th>MSSubClass</th>\n", "      <th>MSZoning</th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>Alley</th>\n", "      <th>LotShape</th>\n", "      <th>LandContour</th>\n", "      <th>Utilities</th>\n", "      <th>...</th>\n", "      <th>PoolArea</th>\n", "      <th>PoolQC</th>\n", "      <th>Fence</th>\n", "      <th>MiscFeature</th>\n", "      <th>MiscVal</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>SaleType</th>\n", "      <th>SaleCondition</th>\n", "      <th>SalePrice</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>1</td>\n", "      <td>60</td>\n", "      <td>RL</td>\n", "      <td>65.0</td>\n", "      <td>8450</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>2</td>\n", "      <td>2008</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>208500</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>2</td>\n", "      <td>20</td>\n", "      <td>RL</td>\n", "      <td>80.0</td>\n", "      <td>9600</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>181500</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>3</td>\n", "      <td>60</td>\n", "      <td>RL</td>\n", "      <td>68.0</td>\n", "      <td>11250</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>IR1</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>9</td>\n", "      <td>2008</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>223500</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>4</td>\n", "      <td>70</td>\n", "      <td>RL</td>\n", "      <td>60.0</td>\n", "      <td>9550</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>IR1</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>2</td>\n", "      <td>2006</td>\n", "      <td>WD</td>\n", "      <td>Abnorml</td>\n", "      <td>140000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>5</td>\n", "      <td>60</td>\n", "      <td>RL</td>\n", "      <td>84.0</td>\n", "      <td>14260</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>IR1</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>12</td>\n", "      <td>2008</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>250000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1455</th>\n", "      <td>1456</td>\n", "      <td>60</td>\n", "      <td>RL</td>\n", "      <td>62.0</td>\n", "      <td>7917</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>175000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1456</th>\n", "      <td>1457</td>\n", "      <td>20</td>\n", "      <td>RL</td>\n", "      <td>85.0</td>\n", "      <td>13175</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>MnPrv</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>2</td>\n", "      <td>2010</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>210000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1457</th>\n", "      <td>1458</td>\n", "      <td>70</td>\n", "      <td>RL</td>\n", "      <td>66.0</td>\n", "      <td>9042</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>GdPrv</td>\n", "      <td>Shed</td>\n", "      <td>2500</td>\n", "      <td>5</td>\n", "      <td>2010</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>266500</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1458</th>\n", "      <td>1459</td>\n", "      <td>20</td>\n", "      <td>RL</td>\n", "      <td>68.0</td>\n", "      <td>9717</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2010</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>142125</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1459</th>\n", "      <td>1460</td>\n", "      <td>20</td>\n", "      <td>RL</td>\n", "      <td>75.0</td>\n", "      <td>9937</td>\n", "      <td>Pave</td>\n", "      <td>NaN</td>\n", "      <td>Reg</td>\n", "      <td>Lvl</td>\n", "      <td>AllPub</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0</td>\n", "      <td>6</td>\n", "      <td>2008</td>\n", "      <td>WD</td>\n", "      <td>Normal</td>\n", "      <td>147500</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1460 rows \u00d7 81 columns</p>\n", "</div>"], "text/plain": ["        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n", "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n", "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n", "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n", "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n", "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n", "...    ...         ...      ...          ...      ...    ...   ...      ...   \n", "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n", "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n", "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n", "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n", "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n", "\n", "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n", "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "...          ...       ...  ...      ...    ...    ...         ...     ...   \n", "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n", "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n", "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n", "\n", "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n", "0         2   2008        WD         Normal     208500  \n", "1         5   2007        WD         Normal     181500  \n", "2         9   2008        WD         Normal     223500  \n", "3         2   2006        WD        Abnorml     140000  \n", "4        12   2008        WD         Normal     250000  \n", "...     ...    ...       ...            ...        ...  \n", "1455      8   2007        WD         Normal     175000  \n", "1456      2   2010        WD         Normal     210000  \n", "1457      5   2010        WD         Normal     266500  \n", "1458      4   2010        WD         Normal     142125  \n", "1459      6   2008        WD         Normal     147500  \n", "\n", "[1460 rows x 81 columns]"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "df = pd.read_csv(\"data/ames.csv\")\n", "df"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Id</th>\n", "      <th>MSSubClass</th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>MasVnrArea</th>\n", "      <th>BsmtFinSF1</th>\n", "      <th>...</th>\n", "      <th>WoodDeckSF</th>\n", "      <th>OpenPorchSF</th>\n", "      <th>EnclosedPorch</th>\n", "      <th>3SsnPorch</th>\n", "      <th>ScreenPorch</th>\n", "      <th>PoolArea</th>\n", "      <th>MiscVal</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>SalePrice</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>count</th>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1201.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1452.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>...</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "      <td>1460.000000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>mean</th>\n", "      <td>730.500000</td>\n", "      <td>56.897260</td>\n", "      <td>70.049958</td>\n", "      <td>10516.828082</td>\n", "      <td>6.099315</td>\n", "      <td>5.575342</td>\n", "      <td>1971.267808</td>\n", "      <td>1984.865753</td>\n", "      <td>103.685262</td>\n", "      <td>443.639726</td>\n", "      <td>...</td>\n", "      <td>94.244521</td>\n", "      <td>46.660274</td>\n", "      <td>21.954110</td>\n", "      <td>3.409589</td>\n", "      <td>15.060959</td>\n", "      <td>2.758904</td>\n", "      <td>43.489041</td>\n", "      <td>6.321918</td>\n", "      <td>2007.815753</td>\n", "      <td>180921.195890</td>\n", "    </tr>\n", "    <tr>\n", "      <th>std</th>\n", "      <td>421.610009</td>\n", "      <td>42.300571</td>\n", "      <td>24.284752</td>\n", "      <td>9981.264932</td>\n", "      <td>1.382997</td>\n", "      <td>1.112799</td>\n", "      <td>30.202904</td>\n", "      <td>20.645407</td>\n", "      <td>181.066207</td>\n", "      <td>456.098091</td>\n", "      <td>...</td>\n", "      <td>125.338794</td>\n", "      <td>66.256028</td>\n", "      <td>61.119149</td>\n", "      <td>29.317331</td>\n", "      <td>55.757415</td>\n", "      <td>40.177307</td>\n", "      <td>496.123024</td>\n", "      <td>2.703626</td>\n", "      <td>1.328095</td>\n", "      <td>79442.502883</td>\n", "    </tr>\n", "    <tr>\n", "      <th>min</th>\n", "      <td>1.000000</td>\n", "      <td>20.000000</td>\n", "      <td>21.000000</td>\n", "      <td>1300.000000</td>\n", "      <td>1.000000</td>\n", "      <td>1.000000</td>\n", "      <td>1872.000000</td>\n", "      <td>1950.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>...</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>1.000000</td>\n", "      <td>2006.000000</td>\n", "      <td>34900.000000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>25%</th>\n", "      <td>365.750000</td>\n", "      <td>20.000000</td>\n", "      <td>59.000000</td>\n", "      <td>7553.500000</td>\n", "      <td>5.000000</td>\n", "      <td>5.000000</td>\n", "      <td>1954.000000</td>\n", "      <td>1967.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>...</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>5.000000</td>\n", "      <td>2007.000000</td>\n", "      <td>129975.000000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>50%</th>\n", "      <td>730.500000</td>\n", "      <td>50.000000</td>\n", "      <td>69.000000</td>\n", "      <td>9478.500000</td>\n", "      <td>6.000000</td>\n", "      <td>5.000000</td>\n", "      <td>1973.000000</td>\n", "      <td>1994.000000</td>\n", "      <td>0.000000</td>\n", "      <td>383.500000</td>\n", "      <td>...</td>\n", "      <td>0.000000</td>\n", "      <td>25.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>6.000000</td>\n", "      <td>2008.000000</td>\n", "      <td>163000.000000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>75%</th>\n", "      <td>1095.250000</td>\n", "      <td>70.000000</td>\n", "      <td>80.000000</td>\n", "      <td>11601.500000</td>\n", "      <td>7.000000</td>\n", "      <td>6.000000</td>\n", "      <td>2000.000000</td>\n", "      <td>2004.000000</td>\n", "      <td>166.000000</td>\n", "      <td>712.250000</td>\n", "      <td>...</td>\n", "      <td>168.000000</td>\n", "      <td>68.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>8.000000</td>\n", "      <td>2009.000000</td>\n", "      <td>214000.000000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>max</th>\n", "      <td>1460.000000</td>\n", "      <td>190.000000</td>\n", "      <td>313.000000</td>\n", "      <td>215245.000000</td>\n", "      <td>10.000000</td>\n", "      <td>9.000000</td>\n", "      <td>2010.000000</td>\n", "      <td>2010.000000</td>\n", "      <td>1600.000000</td>\n", "      <td>5644.000000</td>\n", "      <td>...</td>\n", "      <td>857.000000</td>\n", "      <td>547.000000</td>\n", "      <td>552.000000</td>\n", "      <td>508.000000</td>\n", "      <td>480.000000</td>\n", "      <td>738.000000</td>\n", "      <td>15500.000000</td>\n", "      <td>12.000000</td>\n", "      <td>2010.000000</td>\n", "      <td>755000.000000</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>8 rows \u00d7 38 columns</p>\n", "</div>"], "text/plain": ["                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n", "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n", "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n", "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n", "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n", "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n", "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n", "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n", "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n", "\n", "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n", "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n", "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n", "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n", "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n", "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n", "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n", "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n", "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n", "\n", "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n", "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n", "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n", "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n", "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n", "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n", "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n", "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n", "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n", "\n", "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n", "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n", "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n", "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n", "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n", "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n", "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n", "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n", "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n", "\n", "[8 rows x 38 columns]"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["df.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The prediction target for this analysis is the sale price of the home, so we separate the data into `X` and `y` accordingly:"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["y = df[\"SalePrice\"]\n", "X = df.drop(\"SalePrice\", axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we separate the data into a train set and a test set prior to performing any preprocessing steps:"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["(If you are working through this lab and you just want to start over with the original value for `X_train`, re-run the cell above.)"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X_train is a DataFrame with 1095 rows and 80 columns\n", "y_train is a Series with 1095 values\n"]}], "source": ["print(f\"X_train is a DataFrame with {X_train.shape[0]} rows and {X_train.shape[1]} columns\")\n", "print(f\"y_train is a Series with {y_train.shape[0]} values\")\n", "\n", "# We always should have the same number of rows in X as values in y\n", "assert X_train.shape[0] == y_train.shape[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Fitting a Model\n", "\n", "For this lab we will be using an `ElasticNet` model from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)). You are welcome to read about the details of this model implementation at that link, but for the purposes of this lab, what you need to know is that this is a form of linear regression with *regularization* (meaning we will need to standardize the features).\n", "\n", "Right now, we have not done any preprocessing, so we expect that trying to fit a model will fail:"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"scrolled": true}, "outputs": [{"ename": "ValueError", "evalue": "could not convert string to float: 'RL'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-6-6102dd698287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0mX_copied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             X, y = self._validate_data(X, y, accept_sparse='csc',\n\u001b[0m\u001b[1;32m    760\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                                        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'RL'"]}], "source": ["from sklearn.linear_model import ElasticNet\n", "\n", "model = ElasticNet(random_state=1)\n", "model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As you can see, we got `ValueError: could not convert string to float: 'RL'`.\n", "\n", "In order to fit a scikit-learn model, all values must be numeric, and the third column of our full dataset (`MSZoning`) contains values like `'RL'` and `'RH'`, which are strings. So this error was expected, but after some preprocessing, this model will work!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Drop Irrelevant Columns\n", "\n", "For the purpose of this analysis, we'll only use the following columns, described by `relevant_columns`. You can find the full description of their values in the file `data/data_description.txt` included in this repository.\n", "\n", "In the cell below, reassign `X_train` so that it only contains the columns in `relevant_columns`.\n", "\n", "**Hint:** Even though we describe this as \"dropping\" irrelevant columns, it's easier if you invert the logic, so that we are only keeping relevant columns, rather than using the `.drop()` method. It is possible to use the `.drop()` method if you really want to, but first you would need to create a list of the column names that you don't want to keep."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>Fa</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>NaN</td>\n", "      <td>12342</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>Pave</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>TA</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 15 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182   Pave            7            5       2005   \n", "810          78.0    10140   Pave            6            6       1974   \n", "1384         60.0     9060   Pave            6            5       1939   \n", "626           NaN    12342   Pave            5            5       1960   \n", "813          75.0     9750   Pave            6            6       1958   \n", "...           ...      ...    ...          ...          ...        ...   \n", "1095         78.0     9317   Pave            6            5       2006   \n", "1130         65.0     7804   Pave            4            3       1928   \n", "1294         60.0     8172   Pave            5            7       1955   \n", "860          55.0     7642   Pave            7            8       1918   \n", "1126         53.0     3684   Pave            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023          2006       1504         2             2             7   \n", "810           1999       1309         1             3             5   \n", "1384          1950       1258         1             2             6   \n", "626           1978       1422         1             3             6   \n", "813           1958       1442         1             4             7   \n", "...            ...        ...       ...           ...           ...   \n", "1095          2006       1314         2             3             6   \n", "1130          1950       1981         2             4             7   \n", "1294          1990        864         1             2             5   \n", "860           1998       1426         1             3             7   \n", "1126          2007       1555         2             2             7   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  \n", "1023           1          Gd       5    2008  \n", "810            1          Fa       1    2006  \n", "1384           0         NaN      10    2009  \n", "626            1          TA       8    2007  \n", "813            0         NaN       4    2007  \n", "...          ...         ...     ...     ...  \n", "1095           1          Gd       3    2007  \n", "1130           2          TA      12    2009  \n", "1294           0         NaN       4    2006  \n", "860            1          Gd       6    2007  \n", "1126           1          TA       6    2009  \n", "\n", "[1095 rows x 15 columns]"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Declare relevant columns\n", "relevant_columns = [\n", "    'LotFrontage',  # Linear feet of street connected to property\n", "    'LotArea',      # Lot size in square feet\n", "    'Street',       # Type of road access to property\n", "    'OverallQual',  # Rates the overall material and finish of the house\n", "    'OverallCond',  # Rates the overall condition of the house\n", "    'YearBuilt',    # Original construction date\n", "    'YearRemodAdd', # Remodel date (same as construction date if no remodeling or additions)\n", "    'GrLivArea',    # Above grade (ground) living area square feet\n", "    'FullBath',     # Full bathrooms above grade\n", "    'BedroomAbvGr', # Bedrooms above grade (does NOT include basement bedrooms)\n", "    'TotRmsAbvGrd', # Total rooms above grade (does not include bathrooms)\n", "    'Fireplaces',   # Number of fireplaces\n", "    'FireplaceQu',  # Fireplace quality\n", "    'MoSold',       # Month Sold (MM)\n", "    'YrSold'        # Year Sold (YYYY)\n", "]\n", "\n", "# Reassign X_train so that it only contains relevant columns\n", "X_train = X_train.loc[:, relevant_columns]\n", "\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check that the new shape is correct:"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["\n", "# X_train should have the same number of rows as before\n", "assert X_train.shape[0] == 1095\n", "\n", "# Now X_train should only have as many columns as relevant_columns\n", "assert X_train.shape[1] == len(relevant_columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Handle Missing Values\n", "\n", "In the cell below, we check to see if there are any NaNs in the selected subset of data:"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["LotFrontage     200\n", "LotArea           0\n", "Street            0\n", "OverallQual       0\n", "OverallCond       0\n", "YearBuilt         0\n", "YearRemodAdd      0\n", "GrLivArea         0\n", "FullBath          0\n", "BedroomAbvGr      0\n", "TotRmsAbvGrd      0\n", "Fireplaces        0\n", "FireplaceQu     512\n", "MoSold            0\n", "YrSold            0\n", "dtype: int64"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, it looks like we have some NaNs in `LotFrontage` and `FireplaceQu`.\n", "\n", "Before we proceed to fill in those values, we need to ask: **do these NaNs actually represent** ***missing*** **values, or is there some real value/category being represented by NaN?**\n", "\n", "### Fireplace Quality\n", "\n", "To start with, let's look at `FireplaceQu`, which means \"Fireplace Quality\". Why might we have NaN fireplace quality?\n", "\n", "Well, some properties don't have fireplaces!\n", "\n", "Let's confirm this guess with a little more analysis.\n", "\n", "First, we know that there are 512 records with NaN fireplace quality. How many records are there with zero fireplaces?"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>839</th>\n", "      <td>70.0</td>\n", "      <td>11767</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>6</td>\n", "      <td>1946</td>\n", "      <td>1995</td>\n", "      <td>1200</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "    </tr>\n", "    <tr>\n", "      <th>430</th>\n", "      <td>21.0</td>\n", "      <td>1680</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1971</td>\n", "      <td>1971</td>\n", "      <td>987</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>7</td>\n", "      <td>2008</td>\n", "    </tr>\n", "    <tr>\n", "      <th>513</th>\n", "      <td>71.0</td>\n", "      <td>9187</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1983</td>\n", "      <td>1983</td>\n", "      <td>1080</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>87</th>\n", "      <td>40.0</td>\n", "      <td>3951</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2009</td>\n", "      <td>2009</td>\n", "      <td>1224</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "    </tr>\n", "    <tr>\n", "      <th>330</th>\n", "      <td>NaN</td>\n", "      <td>10624</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>4</td>\n", "      <td>1964</td>\n", "      <td>1964</td>\n", "      <td>1728</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>10</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>11</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1238</th>\n", "      <td>63.0</td>\n", "      <td>13072</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2005</td>\n", "      <td>1141</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>3</td>\n", "      <td>2006</td>\n", "    </tr>\n", "    <tr>\n", "      <th>121</th>\n", "      <td>50.0</td>\n", "      <td>6060</td>\n", "      <td>Pave</td>\n", "      <td>4</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1123</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>4</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>512 rows \u00d7 15 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea Street  OverallQual  OverallCond  YearBuilt  \\\n", "1384         60.0     9060   Pave            6            5       1939   \n", "813          75.0     9750   Pave            6            6       1958   \n", "839          70.0    11767   Pave            5            6       1946   \n", "430          21.0     1680   Pave            6            5       1971   \n", "513          71.0     9187   Pave            6            5       1983   \n", "...           ...      ...    ...          ...          ...        ...   \n", "87           40.0     3951   Pave            6            5       2009   \n", "330           NaN    10624   Pave            5            4       1964   \n", "1238         63.0    13072   Pave            6            5       2005   \n", "121          50.0     6060   Pave            4            5       1939   \n", "1294         60.0     8172   Pave            5            7       1955   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1384          1950       1258         1             2             6   \n", "813           1958       1442         1             4             7   \n", "839           1995       1200         1             3             6   \n", "430           1971        987         1             2             4   \n", "513           1983       1080         1             3             5   \n", "...            ...        ...       ...           ...           ...   \n", "87            2009       1224         2             2             4   \n", "330           1964       1728         2             6            10   \n", "1238          2005       1141         1             3             6   \n", "121           1950       1123         1             3             4   \n", "1294          1990        864         1             2             5   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  \n", "1384           0         NaN      10    2009  \n", "813            0         NaN       4    2007  \n", "839            0         NaN       5    2008  \n", "430            0         NaN       7    2008  \n", "513            0         NaN       6    2007  \n", "...          ...         ...     ...     ...  \n", "87             0         NaN       6    2009  \n", "330            0         NaN      11    2007  \n", "1238           0         NaN       3    2006  \n", "121            0         NaN       6    2007  \n", "1294           0         NaN       4    2006  \n", "\n", "[512 rows x 15 columns]"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train[X_train[\"Fireplaces\"] == 0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, that's 512 rows, same as the number of NaN `FireplaceQu` records. To double-check, let's query for that combination of factors (zero fireplaces and `FireplaceQu` is NaN):"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>839</th>\n", "      <td>70.0</td>\n", "      <td>11767</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>6</td>\n", "      <td>1946</td>\n", "      <td>1995</td>\n", "      <td>1200</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "    </tr>\n", "    <tr>\n", "      <th>430</th>\n", "      <td>21.0</td>\n", "      <td>1680</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1971</td>\n", "      <td>1971</td>\n", "      <td>987</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>7</td>\n", "      <td>2008</td>\n", "    </tr>\n", "    <tr>\n", "      <th>513</th>\n", "      <td>71.0</td>\n", "      <td>9187</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1983</td>\n", "      <td>1983</td>\n", "      <td>1080</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>87</th>\n", "      <td>40.0</td>\n", "      <td>3951</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2009</td>\n", "      <td>2009</td>\n", "      <td>1224</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "    </tr>\n", "    <tr>\n", "      <th>330</th>\n", "      <td>NaN</td>\n", "      <td>10624</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>4</td>\n", "      <td>1964</td>\n", "      <td>1964</td>\n", "      <td>1728</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>10</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>11</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1238</th>\n", "      <td>63.0</td>\n", "      <td>13072</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2005</td>\n", "      <td>1141</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>3</td>\n", "      <td>2006</td>\n", "    </tr>\n", "    <tr>\n", "      <th>121</th>\n", "      <td>50.0</td>\n", "      <td>6060</td>\n", "      <td>Pave</td>\n", "      <td>4</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1123</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>4</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>NaN</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>512 rows \u00d7 15 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea Street  OverallQual  OverallCond  YearBuilt  \\\n", "1384         60.0     9060   Pave            6            5       1939   \n", "813          75.0     9750   Pave            6            6       1958   \n", "839          70.0    11767   Pave            5            6       1946   \n", "430          21.0     1680   Pave            6            5       1971   \n", "513          71.0     9187   Pave            6            5       1983   \n", "...           ...      ...    ...          ...          ...        ...   \n", "87           40.0     3951   Pave            6            5       2009   \n", "330           NaN    10624   Pave            5            4       1964   \n", "1238         63.0    13072   Pave            6            5       2005   \n", "121          50.0     6060   Pave            4            5       1939   \n", "1294         60.0     8172   Pave            5            7       1955   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1384          1950       1258         1             2             6   \n", "813           1958       1442         1             4             7   \n", "839           1995       1200         1             3             6   \n", "430           1971        987         1             2             4   \n", "513           1983       1080         1             3             5   \n", "...            ...        ...       ...           ...           ...   \n", "87            2009       1224         2             2             4   \n", "330           1964       1728         2             6            10   \n", "1238          2005       1141         1             3             6   \n", "121           1950       1123         1             3             4   \n", "1294          1990        864         1             2             5   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  \n", "1384           0         NaN      10    2009  \n", "813            0         NaN       4    2007  \n", "839            0         NaN       5    2008  \n", "430            0         NaN       7    2008  \n", "513            0         NaN       6    2007  \n", "...          ...         ...     ...     ...  \n", "87             0         NaN       6    2009  \n", "330            0         NaN      11    2007  \n", "1238           0         NaN       3    2006  \n", "121            0         NaN       6    2007  \n", "1294           0         NaN       4    2006  \n", "\n", "[512 rows x 15 columns]"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train[\n", "    (X_train[\"Fireplaces\"] == 0) &\n", "    (X_train[\"FireplaceQu\"].isna())\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Looks good, still 512 records. So, NaN fireplace quality is not actually information that is missing from our dataset, it is a genuine category which means \"fireplace quality is not applicable\". This interpretation aligns with what we see in `data/data_description.txt`:\n", "\n", "```\n", "...\n", "FireplaceQu: Fireplace quality\n", "\n", "       Ex\tExcellent - Exceptional Masonry Fireplace\n", "       Gd\tGood - Masonry Fireplace in main level\n", "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n", "       Fa\tFair - Prefabricated Fireplace in basement\n", "       Po\tPoor - Ben Franklin Stove\n", "       NA\tNo Fireplace\n", "...\n", "```\n", "\n", "So, let's replace those NaNs with the string \"N/A\" to indicate that this is a real category, not missing data:"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["N/A    512\n", "Gd     286\n", "TA     236\n", "Fa      26\n", "Ex      19\n", "Po      16\n", "Name: FireplaceQu, dtype: int64"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train[\"FireplaceQu\"] = X_train[\"FireplaceQu\"].fillna(\"N/A\")\n", "X_train[\"FireplaceQu\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Eventually we will still need to perform some preprocessing to prepare the `FireplaceQu` column for modeling (because models require numeric inputs rather than inputs of type `object`), but we don't need to worry about filling in missing values."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Lot Frontage\n", "\n", "Now let's look at `LotFrontage` \u2014 it's possible that NaN is also a genuine category here, and it's possible that it's just missing data instead. Let's apply some domain understanding to understand whether it's possible that lot frontage can be N/A just like fireplace quality can be N/A.\n", "\n", "Lot frontage is defined as the \"Linear feet of street connected to property\", i.e. how much of the property runs directly along a road. The amount of frontage required for a property depends on its zoning. Let's look at the zoning of all records with NaN for `LotFrontage`:"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": ["RL    229\n", "RM     19\n", "FV      8\n", "RH      3\n", "Name: MSZoning, dtype: int64"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["df[df[\"LotFrontage\"].isna()][\"MSZoning\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So, we have RL (residential low density), RM (residential medium density), FV (floating village residential), and RH (residential high density). Looking at the building codes from the City of Ames, it appears that all of these zones require at least 24 feet of frontage.\n", "\n", "Nevertheless, we can't assume that all properties have frontage just because the zoning regulations require it. Maybe these properties predate the regulations, or they received some kind of variance permitting them to get around the requirement. **It's still not as clear here as it was with the fireplaces whether this is a genuine \"not applicable\" kind of NaN or a \"missing information\" kind of NaN.**\n", "\n", "In a case like this, we can take a double approach:\n", "\n", "1. Make a new column in the dataset that simply represents whether `LotFrontage` was originally NaN\n", "2. Fill in the NaN values of `LotFrontage` with median frontage in preparation for modeling"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Missing Indicator for `LotFrontage`\n", "\n", "First, we import `sklearn.impute.MissingIndicator` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html)). The goal of using a `MissingIndicator` is creating a new column to represent which values were NaN (or some other \"missing\" value) in the original dataset, in case NaN ends up being a meaningful indicator rather than a random missing bit of data.\n", "\n", "A `MissingIndicator` is a scikit-learn transformer, meaning that we will use the standard steps for any scikit-learn transformer:\n", "\n", "1. Identify data to be transformed (typically not every column is passed to every transformer)\n", "2. Instantiate the transformer object\n", "3. Fit the transformer object (on training data only)\n", "4. Transform data using the transformer object\n", "5. Add the transformed data to the other data that was not transformed"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[False],\n", "       [False],\n", "       [False],\n", "       ...,\n", "       [False],\n", "       [False],\n", "       [False]])"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.impute import MissingIndicator\n", "\n", "# (1) Identify data to be transformed\n", "# We only want missing indicators for LotFrontage\n", "frontage_train = X_train[[\"LotFrontage\"]]\n", "\n", "# (2) Instantiate the transformer object\n", "missing_indicator = MissingIndicator()\n", "\n", "# (3) Fit the transformer object on frontage_train\n", "missing_indicator.fit(frontage_train)\n", "\n", "# (4) Transform frontage_train and assign the result\n", "# to frontage_missing_train\n", "frontage_missing_train = missing_indicator.transform(frontage_train)\n", "\n", "# Visually inspect frontage_missing_train\n", "frontage_missing_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The result of transforming `frontage_train` should be an array of arrays, each containing `True` or `False`. Make sure the `assert`s pass before moving on to the next step."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "# frontage_missing_train should be a NumPy array\n", "assert type(frontage_missing_train) == np.ndarray\n", "\n", "# We should have the same number of rows as the full X_train\n", "assert frontage_missing_train.shape[0] == X_train.shape[0]\n", "\n", "# But we should only have 1 column\n", "assert frontage_missing_train.shape[1] == 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's add this new information as a new column of `X_train`:"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"scrolled": false}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>Fa</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>NaN</td>\n", "      <td>12342</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>True</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>Pave</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>TA</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 16 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182   Pave            7            5       2005   \n", "810          78.0    10140   Pave            6            6       1974   \n", "1384         60.0     9060   Pave            6            5       1939   \n", "626           NaN    12342   Pave            5            5       1960   \n", "813          75.0     9750   Pave            6            6       1958   \n", "...           ...      ...    ...          ...          ...        ...   \n", "1095         78.0     9317   Pave            6            5       2006   \n", "1130         65.0     7804   Pave            4            3       1928   \n", "1294         60.0     8172   Pave            5            7       1955   \n", "860          55.0     7642   Pave            7            8       1918   \n", "1126         53.0     3684   Pave            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023          2006       1504         2             2             7   \n", "810           1999       1309         1             3             5   \n", "1384          1950       1258         1             2             6   \n", "626           1978       1422         1             3             6   \n", "813           1958       1442         1             4             7   \n", "...            ...        ...       ...           ...           ...   \n", "1095          2006       1314         2             3             6   \n", "1130          1950       1981         2             4             7   \n", "1294          1990        864         1             2             5   \n", "860           1998       1426         1             3             7   \n", "1126          2007       1555         2             2             7   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  LotFrontage_Missing  \n", "1023           1          Gd       5    2008                False  \n", "810            1          Fa       1    2006                False  \n", "1384           0         N/A      10    2009                False  \n", "626            1          TA       8    2007                 True  \n", "813            0         N/A       4    2007                False  \n", "...          ...         ...     ...     ...                  ...  \n", "1095           1          Gd       3    2007                False  \n", "1130           2          TA      12    2009                False  \n", "1294           0         N/A       4    2006                False  \n", "860            1          Gd       6    2007                False  \n", "1126           1          TA       6    2009                False  \n", "\n", "[1095 rows x 16 columns]"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5) add the transformed data to the other data\n", "X_train[\"LotFrontage_Missing\"] = frontage_missing_train\n", "X_train"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["\n", "# Now we should have 1 extra column compared to\n", "# our original subset\n", "assert X_train.shape[1] == len(relevant_columns) + 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Imputing Missing Values for LotFrontage\n", "\n", "Now that we have noted where missing values were originally present, let's use a `SimpleImputer` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)) to fill in those NaNs in the `LotFrontage` column.\n", "\n", "The process is very similar to the `MissingIndicator` process, except that we want to replace the original `LotFrontage` column with the transformed version instead of just adding a new column on.\n", "\n", "In the cell below, create and use a `SimpleImputer` with `strategy=\"median\"` to transform the value of `frontage_train` (declared above)."]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[43.],\n", "       [78.],\n", "       [60.],\n", "       ...,\n", "       [60.],\n", "       [55.],\n", "       [53.]])"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "from sklearn.impute import SimpleImputer\n", "\n", "# (1) frontage_train was created previously, so we don't\n", "# need to extract the relevant data again\n", "\n", "# (2) Instantiate a SimpleImputer with strategy=\"median\"\n", "imputer = SimpleImputer(strategy=\"median\")\n", "\n", "# (3) Fit the imputer on frontage_train\n", "imputer.fit(frontage_train)\n", "\n", "# (4) Transform frontage_train using the imputer and\n", "# assign the result to frontage_imputed_train\n", "frontage_imputed_train = imputer.transform(frontage_train)\n", "\n", "# Visually inspect frontage_imputed_train\n", "frontage_imputed_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can replace the original value of `LotFrontage` in `X_train` with the new value:"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>Fa</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>70.0</td>\n", "      <td>12342</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>True</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>Pave</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>Pave</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>TA</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>Pave</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>Pave</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 16 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182   Pave            7            5       2005   \n", "810          78.0    10140   Pave            6            6       1974   \n", "1384         60.0     9060   Pave            6            5       1939   \n", "626          70.0    12342   Pave            5            5       1960   \n", "813          75.0     9750   Pave            6            6       1958   \n", "...           ...      ...    ...          ...          ...        ...   \n", "1095         78.0     9317   Pave            6            5       2006   \n", "1130         65.0     7804   Pave            4            3       1928   \n", "1294         60.0     8172   Pave            5            7       1955   \n", "860          55.0     7642   Pave            7            8       1918   \n", "1126         53.0     3684   Pave            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023          2006       1504         2             2             7   \n", "810           1999       1309         1             3             5   \n", "1384          1950       1258         1             2             6   \n", "626           1978       1422         1             3             6   \n", "813           1958       1442         1             4             7   \n", "...            ...        ...       ...           ...           ...   \n", "1095          2006       1314         2             3             6   \n", "1130          1950       1981         2             4             7   \n", "1294          1990        864         1             2             5   \n", "860           1998       1426         1             3             7   \n", "1126          2007       1555         2             2             7   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  LotFrontage_Missing  \n", "1023           1          Gd       5    2008                False  \n", "810            1          Fa       1    2006                False  \n", "1384           0         N/A      10    2009                False  \n", "626            1          TA       8    2007                 True  \n", "813            0         N/A       4    2007                False  \n", "...          ...         ...     ...     ...                  ...  \n", "1095           1          Gd       3    2007                False  \n", "1130           2          TA      12    2009                False  \n", "1294           0         N/A       4    2006                False  \n", "860            1          Gd       6    2007                False  \n", "1126           1          TA       6    2009                False  \n", "\n", "[1095 rows x 16 columns]"]}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5) Replace value of LotFrontage\n", "X_train[\"LotFrontage\"] = frontage_imputed_train\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now the shape of `X_train` should still be the same as before:"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["assert X_train.shape == (1095, 16)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And now our `X_train` no longer contains any NaN values:"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"data": {"text/plain": ["LotFrontage            0\n", "LotArea                0\n", "Street                 0\n", "OverallQual            0\n", "OverallCond            0\n", "YearBuilt              0\n", "YearRemodAdd           0\n", "GrLivArea              0\n", "FullBath               0\n", "BedroomAbvGr           0\n", "TotRmsAbvGrd           0\n", "Fireplaces             0\n", "FireplaceQu            0\n", "MoSold                 0\n", "YrSold                 0\n", "LotFrontage_Missing    0\n", "dtype: int64"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great! Now we have completed Step 2."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Convert Categorical Features into Numbers\n", "\n", "Despite dropping irrelevant columns and filling in those NaN values, if we feed the current `X_train` into our scikit-learn `ElasticNet` model, it will crash:"]}, {"cell_type": "code", "execution_count": 22, "metadata": {"scrolled": true}, "outputs": [{"ename": "ValueError", "evalue": "could not convert string to float: 'Pave'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-22-5a4f775ea40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# __SOLUTION__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0mX_copied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             X, y = self._validate_data(X, y, accept_sparse='csc',\n\u001b[0m\u001b[1;32m    760\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                                        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Pave'"]}], "source": ["model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now the first column to cause a problem is `Street`, which is documented like this:\n", "\n", "```\n", "...\n", "Street: Type of road access to property\n", "\n", "       Grvl\tGravel\t\n", "       Pave\tPaved\n", "...\n", "```\n", "\n", "Let's look at the full `X_train`:"]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "Int64Index: 1095 entries, 1023 to 1126\n", "Data columns (total 16 columns):\n", " #   Column               Non-Null Count  Dtype  \n", "---  ------               --------------  -----  \n", " 0   LotFrontage          1095 non-null   float64\n", " 1   LotArea              1095 non-null   int64  \n", " 2   Street               1095 non-null   object \n", " 3   OverallQual          1095 non-null   int64  \n", " 4   OverallCond          1095 non-null   int64  \n", " 5   YearBuilt            1095 non-null   int64  \n", " 6   YearRemodAdd         1095 non-null   int64  \n", " 7   GrLivArea            1095 non-null   int64  \n", " 8   FullBath             1095 non-null   int64  \n", " 9   BedroomAbvGr         1095 non-null   int64  \n", " 10  TotRmsAbvGrd         1095 non-null   int64  \n", " 11  Fireplaces           1095 non-null   int64  \n", " 12  FireplaceQu          1095 non-null   object \n", " 13  MoSold               1095 non-null   int64  \n", " 14  YrSold               1095 non-null   int64  \n", " 15  LotFrontage_Missing  1095 non-null   bool   \n", "dtypes: bool(1), float64(1), int64(12), object(2)\n", "memory usage: 137.9+ KB\n"]}], "source": ["X_train.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So, our model is crashing because some of the columns are non-numeric.\n", "\n", "Anything that is already `float64` or `int64` will work with our model, but these features need to be converted:\n", "\n", "* `Street` (currently type `object`)\n", "* `FireplaceQu` (currently type `object`)\n", "* `LotFrontage_Missing` (currently type `bool`)\n", "\n", "There are two main approaches to converting these values, depending on whether there are 2 values (meaning the categorical variable can be converted into a single binary number) or more than 2 values (meaning we need to create extra columns to represent all categories). (If there is only 1 value, this is not a useful feature for the purposes of predictive analysis.)\n", "\n", "In the cell below, we inspect the value counts of the specified features:"]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Pave    1091\n", "Grvl       4\n", "Name: Street, dtype: int64\n", "\n", "N/A    512\n", "Gd     286\n", "TA     236\n", "Fa      26\n", "Ex      19\n", "Po      16\n", "Name: FireplaceQu, dtype: int64\n", "\n", "False    895\n", "True     200\n", "Name: LotFrontage_Missing, dtype: int64\n"]}], "source": ["\n", "print(X_train[\"Street\"].value_counts())\n", "print()\n", "print(X_train[\"FireplaceQu\"].value_counts())\n", "print()\n", "print(X_train[\"LotFrontage_Missing\"].value_counts())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So, it looks like `Street` and `LotFrontage_Missing` have only 2 categories and can be converted into binary in place, whereas `FireplaceQu` has 6 categories and will need to be expanded into multiple columns."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Binary Categories\n", "\n", "For binary categories, we will use `LabelBinarizer` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html)) to convert the categories of `Street` and `LotFrontage_Missing` into binary values (0s and 1s).\n", "\n", "Just like in Step 2 when we used the `MissingIndicator` and `SimpleImputer`, we will follow these steps:\n", "\n", "1. Identify data to be transformed\n", "2. Instantiate the transformer object\n", "3. Fit the transformer object (on training data only)\n", "4. Transform data using the transformer object\n", "5. Add the transformed data to the other data that was not transformed\n", "\n", "Let's start with transforming `Street`:"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"data": {"text/plain": ["array(['Grvl', 'Pave'], dtype='<U4')"]}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (0) import LabelBinarizer from sklearn.preprocessing\n", "from sklearn.preprocessing import LabelBinarizer\n", "\n", "# (1) Create a variable street_train that is the\n", "# relevant column from X_train\n", "street_train = X_train[\"Street\"]\n", "\n", "# (2) Instantiate a LabelBinarizer\n", "binarizer_street = LabelBinarizer()\n", "\n", "# (3) Fit the binarizer on street_train\n", "binarizer_street.fit(street_train)\n", "\n", "# Inspect the classes of the fitted binarizer\n", "binarizer_street.classes_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The `.classes_` attribute of `LabelBinarizer` is only present once the `.fit` method has been called. (The trailing `_` indicates this convention.)\n", "\n", "What this tells us is that when `binarizer_street` is used to transform the street data into 1s and 0s, `0` will mean `'Grvl'` (gravel) in the original data, and `1` will mean `'Pave'` (paved) in the original data.\n", "\n", "The eventual scikit-learn model only cares about the 1s and 0s, but this information can be useful for us to understand what our code is doing and help us debug when things go wrong.\n", "\n", "Now let's transform `street_train` with the fitted binarizer:"]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[1],\n", "       [1],\n", "       [1],\n", "       ...,\n", "       [1],\n", "       [1],\n", "       [1]])"]}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (4) Transform street_train using the binarizer and\n", "# assign the result to street_binarized_train\n", "street_binarized_train = binarizer_street.transform(street_train)\n", "\n", "# Visually inspect street_binarized_train\n", "street_binarized_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["All of the values we see appear to be `1` right now, but that makes sense since there were only 4 properties with gravel (`0`) streets in `X_train`.\n", "\n", "Now let's replace the original `Street` column with the binarized version:"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>Fa</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>70.0</td>\n", "      <td>12342</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>True</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>TA</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>False</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 16 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea  Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182       1            7            5       2005   \n", "810          78.0    10140       1            6            6       1974   \n", "1384         60.0     9060       1            6            5       1939   \n", "626          70.0    12342       1            5            5       1960   \n", "813          75.0     9750       1            6            6       1958   \n", "...           ...      ...     ...          ...          ...        ...   \n", "1095         78.0     9317       1            6            5       2006   \n", "1130         65.0     7804       1            4            3       1928   \n", "1294         60.0     8172       1            5            7       1955   \n", "860          55.0     7642       1            7            8       1918   \n", "1126         53.0     3684       1            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023          2006       1504         2             2             7   \n", "810           1999       1309         1             3             5   \n", "1384          1950       1258         1             2             6   \n", "626           1978       1422         1             3             6   \n", "813           1958       1442         1             4             7   \n", "...            ...        ...       ...           ...           ...   \n", "1095          2006       1314         2             3             6   \n", "1130          1950       1981         2             4             7   \n", "1294          1990        864         1             2             5   \n", "860           1998       1426         1             3             7   \n", "1126          2007       1555         2             2             7   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  LotFrontage_Missing  \n", "1023           1          Gd       5    2008                False  \n", "810            1          Fa       1    2006                False  \n", "1384           0         N/A      10    2009                False  \n", "626            1          TA       8    2007                 True  \n", "813            0         N/A       4    2007                False  \n", "...          ...         ...     ...     ...                  ...  \n", "1095           1          Gd       3    2007                False  \n", "1130           2          TA      12    2009                False  \n", "1294           0         N/A       4    2006                False  \n", "860            1          Gd       6    2007                False  \n", "1126           1          TA       6    2009                False  \n", "\n", "[1095 rows x 16 columns]"]}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5) Replace value of Street\n", "X_train[\"Street\"] = street_binarized_train\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "Int64Index: 1095 entries, 1023 to 1126\n", "Data columns (total 16 columns):\n", " #   Column               Non-Null Count  Dtype  \n", "---  ------               --------------  -----  \n", " 0   LotFrontage          1095 non-null   float64\n", " 1   LotArea              1095 non-null   int64  \n", " 2   Street               1095 non-null   int64  \n", " 3   OverallQual          1095 non-null   int64  \n", " 4   OverallCond          1095 non-null   int64  \n", " 5   YearBuilt            1095 non-null   int64  \n", " 6   YearRemodAdd         1095 non-null   int64  \n", " 7   GrLivArea            1095 non-null   int64  \n", " 8   FullBath             1095 non-null   int64  \n", " 9   BedroomAbvGr         1095 non-null   int64  \n", " 10  TotRmsAbvGrd         1095 non-null   int64  \n", " 11  Fireplaces           1095 non-null   int64  \n", " 12  FireplaceQu          1095 non-null   object \n", " 13  MoSold               1095 non-null   int64  \n", " 14  YrSold               1095 non-null   int64  \n", " 15  LotFrontage_Missing  1095 non-null   bool   \n", "dtypes: bool(1), float64(1), int64(13), object(1)\n", "memory usage: 137.9+ KB\n"]}], "source": ["X_train.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Perfect! Now `Street` should by type `int64` instead of `object`.\n", "\n", "Now, repeat the same process with `LotFrontage_Missing`:"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([False,  True])"]}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (1) We already have a variable frontage_missing_train\n", "# from earlier, no additional step needed\n", "\n", "# (2) Instantiate a LabelBinarizer for missing frontage\n", "binarizer_frontage_missing = LabelBinarizer()\n", "\n", "# (3) Fit the binarizer on frontage_missing_train\n", "binarizer_frontage_missing.fit(frontage_missing_train)\n", "\n", "# Inspect the classes of the fitted binarizer\n", "binarizer_frontage_missing.classes_"]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[0],\n", "       [0],\n", "       [0],\n", "       ...,\n", "       [0],\n", "       [0],\n", "       [0]])"]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (4) Transform frontage_missing_train using the binarizer and\n", "# assign the result to frontage_missing_binarized_train\n", "frontage_missing_binarized_train = binarizer_frontage_missing.transform(frontage_missing_train)\n", "\n", "# Visually inspect frontage_missing_binarized_train\n", "frontage_missing_binarized_train"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>FireplaceQu</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>Fa</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>70.0</td>\n", "      <td>12342</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>TA</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>N/A</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>Gd</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>TA</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 16 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea  Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182       1            7            5       2005   \n", "810          78.0    10140       1            6            6       1974   \n", "1384         60.0     9060       1            6            5       1939   \n", "626          70.0    12342       1            5            5       1960   \n", "813          75.0     9750       1            6            6       1958   \n", "...           ...      ...     ...          ...          ...        ...   \n", "1095         78.0     9317       1            6            5       2006   \n", "1130         65.0     7804       1            4            3       1928   \n", "1294         60.0     8172       1            5            7       1955   \n", "860          55.0     7642       1            7            8       1918   \n", "1126         53.0     3684       1            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023          2006       1504         2             2             7   \n", "810           1999       1309         1             3             5   \n", "1384          1950       1258         1             2             6   \n", "626           1978       1422         1             3             6   \n", "813           1958       1442         1             4             7   \n", "...            ...        ...       ...           ...           ...   \n", "1095          2006       1314         2             3             6   \n", "1130          1950       1981         2             4             7   \n", "1294          1990        864         1             2             5   \n", "860           1998       1426         1             3             7   \n", "1126          2007       1555         2             2             7   \n", "\n", "      Fireplaces FireplaceQu  MoSold  YrSold  LotFrontage_Missing  \n", "1023           1          Gd       5    2008                    0  \n", "810            1          Fa       1    2006                    0  \n", "1384           0         N/A      10    2009                    0  \n", "626            1          TA       8    2007                    1  \n", "813            0         N/A       4    2007                    0  \n", "...          ...         ...     ...     ...                  ...  \n", "1095           1          Gd       3    2007                    0  \n", "1130           2          TA      12    2009                    0  \n", "1294           0         N/A       4    2006                    0  \n", "860            1          Gd       6    2007                    0  \n", "1126           1          TA       6    2009                    0  \n", "\n", "[1095 rows x 16 columns]"]}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5) Replace value of LotFrontage_Missing\n", "X_train[\"LotFrontage_Missing\"] = frontage_missing_binarized_train\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "Int64Index: 1095 entries, 1023 to 1126\n", "Data columns (total 16 columns):\n", " #   Column               Non-Null Count  Dtype  \n", "---  ------               --------------  -----  \n", " 0   LotFrontage          1095 non-null   float64\n", " 1   LotArea              1095 non-null   int64  \n", " 2   Street               1095 non-null   int64  \n", " 3   OverallQual          1095 non-null   int64  \n", " 4   OverallCond          1095 non-null   int64  \n", " 5   YearBuilt            1095 non-null   int64  \n", " 6   YearRemodAdd         1095 non-null   int64  \n", " 7   GrLivArea            1095 non-null   int64  \n", " 8   FullBath             1095 non-null   int64  \n", " 9   BedroomAbvGr         1095 non-null   int64  \n", " 10  TotRmsAbvGrd         1095 non-null   int64  \n", " 11  Fireplaces           1095 non-null   int64  \n", " 12  FireplaceQu          1095 non-null   object \n", " 13  MoSold               1095 non-null   int64  \n", " 14  YrSold               1095 non-null   int64  \n", " 15  LotFrontage_Missing  1095 non-null   int64  \n", "dtypes: float64(1), int64(14), object(1)\n", "memory usage: 145.4+ KB\n"]}], "source": ["X_train.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, now we only have 1 column remaining that isn't type `float64` or `int64`!\n", "\n", "#### Note on Preprocessing Boolean Values\n", "For binary values like `LotFrontage_Missing`, you might see a few different approaches to preprocessing. Python treats `True` and `1` as equal:"]}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["True\n", "True\n"]}], "source": ["print(True == 1)\n", "print(False == 0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This means that if your model is purely using Python, you actually might just be able to leave columns as type `bool` without any issues. You will likely see examples that do this. However if your model relies on C or Java \"under the hood\", this might cause problems.\n", "\n", "There is also a technique using `pandas` rather than scikit-learn for this particular conversion of boolean values to integers:"]}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>True</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1090</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1091</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1092</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1093</th>\n", "      <td>False</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1094</th>\n", "      <td>False</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 1 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage_Missing\n", "0                   False\n", "1                   False\n", "2                   False\n", "3                    True\n", "4                   False\n", "...                   ...\n", "1090                False\n", "1091                False\n", "1092                False\n", "1093                False\n", "1094                False\n", "\n", "[1095 rows x 1 columns]"]}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": ["df_example = pd.DataFrame(frontage_missing_train, columns=[\"LotFrontage_Missing\"])\n", "df_example"]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1090</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1091</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1092</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1093</th>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1094</th>\n", "      <td>0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 1 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage_Missing\n", "0                       0\n", "1                       0\n", "2                       0\n", "3                       1\n", "4                       0\n", "...                   ...\n", "1090                    0\n", "1091                    0\n", "1092                    0\n", "1093                    0\n", "1094                    0\n", "\n", "[1095 rows x 1 columns]"]}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": ["df_example[\"LotFrontage_Missing\"] = df_example[\"LotFrontage_Missing\"].astype(int)\n", "df_example"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This code is casting every value in the `LotFrontage_Missing` column to an integer, achieving the same result as the `LabelBinarizer` example with less code.\n", "\n", "The downside of using this approach is that it doesn't fit into a scikit-learn pipeline as neatly because it is using `pandas` to do the transformation instead of scikit-learn.\n", "\n", "In the future, you will need to make your own determination of which strategy to use!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Multiple Categories\n", "\n", "Unlike `Street` and `LotFrontage_Missing`, `FireplaceQu` has more than two categories. Therefore the process for encoding it numerically is a bit more complicated, because we will need to create multiple \"dummy\" columns that are each representing one category.\n", "\n", "To do this, we can use a `OneHotEncoder` from `sklearn.preprocessing` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)).\n", "\n", "The first several steps are very similar to all of the other transformers we've used so far, although the process of combining the data with the original data differs.\n", "\n", "In the cells below, complete steps `(0)`-`(4)` of preprocessing the `FireplaceQu` column using a `OneHotEncoder`:"]}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [{"data": {"text/plain": ["[array(['Ex', 'Fa', 'Gd', 'N/A', 'Po', 'TA'], dtype=object)]"]}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (0) import OneHotEncoder from sklearn.preprocessing\n", "from sklearn.preprocessing import OneHotEncoder\n", "\n", "# (1) Create a variable fireplace_qu_train\n", "# extracted from X_train\n", "# (double brackets due to shape expected by OHE)\n", "fireplace_qu_train = X_train[[\"FireplaceQu\"]]\n", "\n", "# (2) Instantiate a OneHotEncoder with categories=\"auto\",\n", "# sparse=False, and handle_unknown=\"ignore\"\n", "ohe = OneHotEncoder(categories=\"auto\", sparse=False, handle_unknown=\"ignore\")\n", "\n", "# (3) Fit the encoder on fireplace_qu_train\n", "ohe.fit(fireplace_qu_train)\n", "\n", "# Inspect the categories of the fitted encoder\n", "ohe.categories_"]}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[0., 0., 1., 0., 0., 0.],\n", "       [0., 1., 0., 0., 0., 0.],\n", "       [0., 0., 0., 1., 0., 0.],\n", "       ...,\n", "       [0., 0., 0., 1., 0., 0.],\n", "       [0., 0., 1., 0., 0., 0.],\n", "       [0., 0., 0., 0., 0., 1.]])"]}, "execution_count": 37, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (4) Transform fireplace_qu_train using the encoder and\n", "# assign the result to fireplace_qu_encoded_train\n", "fireplace_qu_encoded_train = ohe.transform(fireplace_qu_train)\n", "\n", "# Visually inspect fireplace_qu_encoded_train\n", "fireplace_qu_encoded_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that this time, unlike with `MissingIndicator`, `SimpleImputer`, or `LabelBinarizer`, we have created multiple columns of data out of a single column. The code below converts this unlabeled NumPy array into a readable pandas dataframe in preparation for merging it back with the rest of `X_train`:"]}, {"cell_type": "code", "execution_count": 38, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Ex</th>\n", "      <th>Fa</th>\n", "      <th>Gd</th>\n", "      <th>N/A</th>\n", "      <th>Po</th>\n", "      <th>TA</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 6 columns</p>\n", "</div>"], "text/plain": ["       Ex   Fa   Gd  N/A   Po   TA\n", "1023  0.0  0.0  1.0  0.0  0.0  0.0\n", "810   0.0  1.0  0.0  0.0  0.0  0.0\n", "1384  0.0  0.0  0.0  1.0  0.0  0.0\n", "626   0.0  0.0  0.0  0.0  0.0  1.0\n", "813   0.0  0.0  0.0  1.0  0.0  0.0\n", "...   ...  ...  ...  ...  ...  ...\n", "1095  0.0  0.0  1.0  0.0  0.0  0.0\n", "1130  0.0  0.0  0.0  0.0  0.0  1.0\n", "1294  0.0  0.0  0.0  1.0  0.0  0.0\n", "860   0.0  0.0  1.0  0.0  0.0  0.0\n", "1126  0.0  0.0  0.0  0.0  0.0  1.0\n", "\n", "[1095 rows x 6 columns]"]}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5a) Make the transformed data into a dataframe\n", "fireplace_qu_encoded_train = pd.DataFrame(\n", "    # Pass in NumPy array\n", "    fireplace_qu_encoded_train,\n", "    # Set the column names to the categories found by OHE\n", "    columns=ohe.categories_[0],\n", "    # Set the index to match X_train's index\n", "    index=X_train.index\n", ")\n", "\n", "# Visually inspect new dataframe\n", "fireplace_qu_encoded_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A couple notes on the code above:\n", "\n", "* The main goal of converting this into a dataframe (rather than converting `X_train` into a NumPy array, which would also allow them to be combined) is **readability** \u2014 to help you and others understand what your code is doing, and to help you debug. Eventually when you write this code as a pipeline, it will be NumPy arrays \"under the hood\".\n", "* We are using just the **raw categories** from `FireplaceQu` as our new dataframe columns, but you'll also see examples where a lambda function or list comprehension is used to create column names indicating the original column name, e.g. `FireplaceQu_Ex`, `FireplaceQu_Fa` rather than just `Ex`, `Fa`. This is a design decision based on readability \u2014 the scikit-learn model will work the same either way.\n", "* It is very important that **the index of the new dataframe matches the index of the main `X_train` dataframe**. Because we used `train_test_split`, the index of `X_train` is shuffled, so it goes `1023`, `810`, `1384` etc. instead of `0`, `1`, `2`, etc. If you don't specify an index for the new dataframe, it will assign the first record to the index `0` rather than `1023`. If you are ever merging encoded data like this and a bunch of NaNs start appearing, make sure that the indexes are lined up correctly! You also may see examples where the index of `X_train` has been reset, rather than specifying the index of the new dataframe \u2014 either way works."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we want to drop the original `FireplaceQu` column containing the categorical data:\n", "\n", "(For previous transformations we didn't need to drop anything because we were replacing 1 column with 1 new column in place, but one-hot encoding works differently.)"]}, {"cell_type": "code", "execution_count": 39, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>70.0</td>\n", "      <td>12342</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 15 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea  Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182       1            7            5       2005   \n", "810          78.0    10140       1            6            6       1974   \n", "1384         60.0     9060       1            6            5       1939   \n", "626          70.0    12342       1            5            5       1960   \n", "813          75.0     9750       1            6            6       1958   \n", "...           ...      ...     ...          ...          ...        ...   \n", "1095         78.0     9317       1            6            5       2006   \n", "1130         65.0     7804       1            4            3       1928   \n", "1294         60.0     8172       1            5            7       1955   \n", "860          55.0     7642       1            7            8       1918   \n", "1126         53.0     3684       1            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023          2006       1504         2             2             7   \n", "810           1999       1309         1             3             5   \n", "1384          1950       1258         1             2             6   \n", "626           1978       1422         1             3             6   \n", "813           1958       1442         1             4             7   \n", "...            ...        ...       ...           ...           ...   \n", "1095          2006       1314         2             3             6   \n", "1130          1950       1981         2             4             7   \n", "1294          1990        864         1             2             5   \n", "860           1998       1426         1             3             7   \n", "1126          2007       1555         2             2             7   \n", "\n", "      Fireplaces  MoSold  YrSold  LotFrontage_Missing  \n", "1023           1       5    2008                    0  \n", "810            1       1    2006                    0  \n", "1384           0      10    2009                    0  \n", "626            1       8    2007                    1  \n", "813            0       4    2007                    0  \n", "...          ...     ...     ...                  ...  \n", "1095           1       3    2007                    0  \n", "1130           2      12    2009                    0  \n", "1294           0       4    2006                    0  \n", "860            1       6    2007                    0  \n", "1126           1       6    2009                    0  \n", "\n", "[1095 rows x 15 columns]"]}, "execution_count": 39, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5b) Drop original FireplaceQu column\n", "X_train.drop(\"FireplaceQu\", axis=1, inplace=True)\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, we want to concatenate the new dataframe together with the original `X_train`:"]}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>...</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>Ex</th>\n", "      <th>Fa</th>\n", "      <th>Gd</th>\n", "      <th>N/A</th>\n", "      <th>Po</th>\n", "      <th>TA</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2005</td>\n", "      <td>2006</td>\n", "      <td>1504</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1974</td>\n", "      <td>1999</td>\n", "      <td>1309</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>1939</td>\n", "      <td>1950</td>\n", "      <td>1258</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>70.0</td>\n", "      <td>12342</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1960</td>\n", "      <td>1978</td>\n", "      <td>1422</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1958</td>\n", "      <td>1442</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2006</td>\n", "      <td>1314</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1928</td>\n", "      <td>1950</td>\n", "      <td>1981</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>...</td>\n", "      <td>2</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>7</td>\n", "      <td>1955</td>\n", "      <td>1990</td>\n", "      <td>864</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>8</td>\n", "      <td>1918</td>\n", "      <td>1998</td>\n", "      <td>1426</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2007</td>\n", "      <td>1555</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 21 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea  Street  OverallQual  OverallCond  YearBuilt  \\\n", "1023         43.0     3182       1            7            5       2005   \n", "810          78.0    10140       1            6            6       1974   \n", "1384         60.0     9060       1            6            5       1939   \n", "626          70.0    12342       1            5            5       1960   \n", "813          75.0     9750       1            6            6       1958   \n", "...           ...      ...     ...          ...          ...        ...   \n", "1095         78.0     9317       1            6            5       2006   \n", "1130         65.0     7804       1            4            3       1928   \n", "1294         60.0     8172       1            5            7       1955   \n", "860          55.0     7642       1            7            8       1918   \n", "1126         53.0     3684       1            7            5       2007   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  ...  Fireplaces  \\\n", "1023          2006       1504         2             2  ...           1   \n", "810           1999       1309         1             3  ...           1   \n", "1384          1950       1258         1             2  ...           0   \n", "626           1978       1422         1             3  ...           1   \n", "813           1958       1442         1             4  ...           0   \n", "...            ...        ...       ...           ...  ...         ...   \n", "1095          2006       1314         2             3  ...           1   \n", "1130          1950       1981         2             4  ...           2   \n", "1294          1990        864         1             2  ...           0   \n", "860           1998       1426         1             3  ...           1   \n", "1126          2007       1555         2             2  ...           1   \n", "\n", "      MoSold  YrSold  LotFrontage_Missing   Ex   Fa   Gd  N/A   Po   TA  \n", "1023       5    2008                    0  0.0  0.0  1.0  0.0  0.0  0.0  \n", "810        1    2006                    0  0.0  1.0  0.0  0.0  0.0  0.0  \n", "1384      10    2009                    0  0.0  0.0  0.0  1.0  0.0  0.0  \n", "626        8    2007                    1  0.0  0.0  0.0  0.0  0.0  1.0  \n", "813        4    2007                    0  0.0  0.0  0.0  1.0  0.0  0.0  \n", "...      ...     ...                  ...  ...  ...  ...  ...  ...  ...  \n", "1095       3    2007                    0  0.0  0.0  1.0  0.0  0.0  0.0  \n", "1130      12    2009                    0  0.0  0.0  0.0  0.0  0.0  1.0  \n", "1294       4    2006                    0  0.0  0.0  0.0  1.0  0.0  0.0  \n", "860        6    2007                    0  0.0  0.0  1.0  0.0  0.0  0.0  \n", "1126       6    2009                    0  0.0  0.0  0.0  0.0  0.0  1.0  \n", "\n", "[1095 rows x 21 columns]"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5c) Concatenate the new dataframe with current X_train\n", "X_train = pd.concat([X_train, fireplace_qu_encoded_train], axis=1)\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "Int64Index: 1095 entries, 1023 to 1126\n", "Data columns (total 21 columns):\n", " #   Column               Non-Null Count  Dtype  \n", "---  ------               --------------  -----  \n", " 0   LotFrontage          1095 non-null   float64\n", " 1   LotArea              1095 non-null   int64  \n", " 2   Street               1095 non-null   int64  \n", " 3   OverallQual          1095 non-null   int64  \n", " 4   OverallCond          1095 non-null   int64  \n", " 5   YearBuilt            1095 non-null   int64  \n", " 6   YearRemodAdd         1095 non-null   int64  \n", " 7   GrLivArea            1095 non-null   int64  \n", " 8   FullBath             1095 non-null   int64  \n", " 9   BedroomAbvGr         1095 non-null   int64  \n", " 10  TotRmsAbvGrd         1095 non-null   int64  \n", " 11  Fireplaces           1095 non-null   int64  \n", " 12  MoSold               1095 non-null   int64  \n", " 13  YrSold               1095 non-null   int64  \n", " 14  LotFrontage_Missing  1095 non-null   int64  \n", " 15  Ex                   1095 non-null   float64\n", " 16  Fa                   1095 non-null   float64\n", " 17  Gd                   1095 non-null   float64\n", " 18  N/A                  1095 non-null   float64\n", " 19  Po                   1095 non-null   float64\n", " 20  TA                   1095 non-null   float64\n", "dtypes: float64(7), int64(14)\n", "memory usage: 188.2 KB\n"]}], "source": ["X_train.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, everything is numeric now! We have completed the minimum necessary preprocessing to use these features in a scikit-learn model!"]}, {"cell_type": "code", "execution_count": 42, "metadata": {}, "outputs": [{"data": {"text/plain": ["ElasticNet(random_state=1)"]}, "execution_count": 42, "metadata": {}, "output_type": "execute_result"}], "source": ["model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, no error this time.\n", "\n", "Let's use cross validation to take a look at the model's performance:"]}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0.73895092, 0.66213118, 0.8124859 ])"]}, "execution_count": 43, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.model_selection import cross_val_score\n", "\n", "cross_val_score(model, X_train, y_train, cv=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Not terrible, we are explaining between 66% and 81% of the variance in the target with our current feature set."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Add Interaction Terms\n", "\n", "Now that we have completed the minimum preprocessing to run a model without errors, let's try to improve the model performance.\n", "\n", "Linear models (including `ElasticNet`) are limited in the information they can learn because they are assuming a linear relationship between features and target. Often our real-world features aren't related to the target this way:"]}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [{"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["import matplotlib.pyplot as plt\n", "\n", "fig, ax = plt.subplots()\n", "ax.scatter(X_train[\"LotArea\"], y_train, alpha=0.2)\n", "ax.set_xlabel(\"Lot Area\")\n", "ax.set_ylabel(\"Sale Price\")\n", "ax.set_title(\"Lot Area vs. Sale Price for Ames Housing Data\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sometimes we can improve the linearity by introducing an *interaction term*. In this case, multiplying the lot area by the overall quality:"]}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [{"data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEWCAYAAAAO4GKjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABN20lEQVR4nO3dd5wkV3nw+9/TuXty2qwNQqtVQgEtQhhjMEESUdgmCANauLIFGPPCxTbB10ZEv+D3vQbzYoJsQBJZiCRzCV4kk5VWSCiy0kq72l1tmhw6V/dz/zinZ3tmZ2Z7dqZnemee7+czn6k+lU5VV9XT59SpU6KqGGOMMSe70GJnwBhjjJkPFtCMMcYsCRbQjDHGLAkW0IwxxiwJFtCMMcYsCRbQjDHGLAkNH9BE5H+KyDsXOx9meiKyR0Re4Ic/ICJfWcS8/ExE/sIPv05E/usEl7NSRB4Wkfj85rB+FnLfi8iYiJw6z8vcIiL3iMioiPyP+Vy2ARH5nIj842Lno54aOqCJSA9wJfB5//m5IrL/BJZznYh8pIbpREQeF5GHZp/bhSMi7SLyWRE5JCIZEblfRN602PmqxTR531aPdanqV1X1kqp1q4icVuO8h4H/Bq6uR96m4/fPF/3+GRWRR0TkPQuw3j0ikvWB6rCIfElEmqebXlWbVfXxec7Gu4GfqWqLqn5qvhYqIm/03/2r52uZc1H9A7Aq7Y0i8qt6rldV36KqH57v5YrIRr9/x6qOnx+IyAtnsYx52f6GDmjAG4Efqmp2gdb3R8AK4FQRefp0E/nAtyj7TkRiwE+BDcAzgTbg74CPici76rC+yDwua7q8/3OD/iL/KvDmBV7nJ4Bm4Ezc/nk58NgCrftlqtoMPA14OvAPkyeYz+NhChuAB09kxuPkaxsw4P+b+mn3x895wHbguyLyxgXNgao27B9wK/D6qs/PBfZPM+2ZwM+AIdxJ8XKffjVQBArAGPCfM6zvi7iL2HeAT08a9zPgo8CvgSxwGnAG7osbAHYCr66a/iXAPcAIsA/4wAzrfQ9wOxDxn9/qtyExxbRXAUeApknpr/Hb1wq8F7hp0vh/BT7lh9uALwAHgSeBjwBhP+6Nfhs/4bfrI8BT/HfRD/T5fdRetew9wAv88AeAr0yznTPlfQRo8Z8VOK1q/HXAR/xwB/ADoBcY9MPrJn1Pf1G1Lb/yw7/wy037/fQa4AHcRbwyb9Rv3/n+cwTIABum2JaLgUOV/ebT/gS4zw9fBOzw23UY+Jcaj/kHgFfMMP5f/fE0AtwNPLtq3IR97/P4G9w58TvguTMsd/w79J//F/CDqu/jbcCjwO7J3xGQBP5f4AlgGPgVkJxNHvzxVQJy/vs5HXec3uC/6ydwATY03XE6zXI3AGXgz4AAWDn5eoIrGR7BnQ+vAF4MPOKX+/dV04dw59ZjuHPhRqDTj0sAX/HpQ8Bd1euaaV9PPlZnup5NPsanOM7F75Mj/ru4DzhnivOosu1/U7Xtb6paZhfwn7jj7C7cdeBX02zPRn88RCal/y3u2K98Z5V9Nwo8BPxJ1bbm/Pc/BgzN9ho6vs5aTrLF+vMH8tMnH4BTTBcFdgF/D8SA5/mdtmXyFznDulJ+x70Yd/D3AbFJB9Fe4Gzcha7N7+Q3+c9P8/OcXZXXp+JOgnP9FzvlhcpP8wvcBWkz7kJ9wTTTfgO4for0CO6EvRR3EmeAVj8u7A/Yi/3n7+GqcZtwJdI7gTdXnRwB8Ha/zCQueL8QiAM9Pq+fnOoEZeaAdry8v9B/nimgdfnvJwW0AN8CvjfVyc6xF4nJy3038M2qz5cD90/K231UXUwmjXuskmf/+VvAe/3wbcAb/HBzZd/XcMz/B+4C9iZg8xTjX+/3QQR3MTqE/+FTve+BtbiL64v98fVC/7lnmvVWf4en+Dx8uGq/bQc6ORqoqgPav/n9vhZ3rP2BP1Zmm4fx785/vgH4vv+eN+KCzFXTHafTLPMfgTv98P3AuyZdTwLg/bhryF/irjlf8+s8G3ehPdVP/07cD891fvs+D3zdj3szLgCk/D64EH/+zbSvq9LeyNGgdLzr2eT9VD3vpbgfOu244HYmsHqK86iy7R/y63sx7prRUXWufsNvz1m4a91sA9qpPv1M//lVwBp/LLwG9+Ny9eRtmPT91HQNHZ+nlpNssf5wJaszJm3gVAHt2bgTO1SV9nV8RKe2gPZ6fzBH/ME6hP8FUXUQfajq82uAX05axueBa6ZZ/ieBT8yw/o24X4QPA++bYbqfAh+bZtwh4HV++FfAlX74hcBjfnglkKfqAgC8FvjvqgNr73H21SuAe6o+76G2gHa8vP+5H542oE0x3/nA4KTvqdaAtgZ3oagE/puAd09a/q8r+3GKdX8E+KIfbsGdoBv8518AHwS6Z3nMJ3EXsrtxx/8u4EUzTD8InDd53+NK/V+eNO1PgG3TLGcP/tcxrjT0GSYGr+dNml5xP3RCuBqL86ZY5mzzUP3dhf1xelbV+Dfj7rHVdJz66R4F3umH3wf8rmrcc33eK7UTLX67nlE1zd34iyju3Hx+1bjV/juKAP8XriR6bg15qt7Xlb8MR4PS8a5n4/tp8nGOC36P4ErGoUnrvY6JAS1LVRDCldQu9vu+iA+gVcf6bANawqc/a5r57gUun+pcnWb6TzLDNVRVG/4e2iDuIDueNcA+VS1XpT2B+4VYq23AjaoaqGoeV+24bdI0+6qGNwDPEJGhyh/wOmAVgIg8Q0T+W0R6RWQYeAvQPd3KVXUPrhHCRtwv3un04U6kCfw9hG4/HtyvzNf64T/3nyv5jgIHq/L9eVxJbartRERWiMg3RORJERnBVa1Muy1zyHvv8RYgIikR+byIPOHz8gugXUTCs82Mqh7ABaw/E5F24EW46tRqLbgLzlS+Bvypbwn5p8BvVfUJP+4qXLXZ70XkLhF5aY15yqrqP6nqhbiS2I3At0SkE0BE/sa3vhz2310bU38XG4BXTTo+/5Ap9n+VV6hqu6puUNW/0on3rvdNM0837sI11X2+E8lD9XJjuPO4YvI5PV2eABCRZwGbcCUNcN/XU0Xk/KrJ+lW15Icr23u4anwWV8KubM93q7blYVw12Urgy7hg/Q0ROSAi/ywi0RmyV9nX7araDvxV1bgTvp6p6q3Ap3HXkMMicq2ItE4zeb+qBlWfM35be3BBunr/zrivp1HJ7wCAiFwpIvdW7b9zmOE6MttrKDR+o5D7cBeF4zkAnDKpocZ63P0hcL8SpiUi63C/bF7vW5cdAl4JvFhEqndg9XL2AT+vPijVtfx6qx//NeBm4BRVbQM+h6sCmC4PL8Y1lLgFd/9iOj8FXiQiTZPS/wz3i/Z2//lbwHP9tv0JRwPaPj9dd1W+W1X17Gm2E+B/+rRzVbUVV5qddltOMO9FXNUnuBMrVTV+VdXw3wBbcL+iW3ENeTjB/ABcj9ueVwG3qWrlmKkE2tNw936OoaoP4S40L2LijwZU9VFVfS3uh8LHgZum2O4ZqeoI8E+4quFNIvJsXKnn1biqoXbcfZKptn0frnRUfXw2qerHZpOH6uxMk96Hq5Z7yjznoQ93TGyoSqs+p2fKU8U23L6515/Td/j0K2tY/1T24UrL1duTUNUnVbWoqh9U1bNwVa4vncN6jnc9SzP9+YGqfsr/IDobd/38u1muvxdXHbmuKu2UWS4D3HXnCLBTRDYA/w78NdDlj90HOHrsTvVdzuoaCo0f0H4IPGdyoogkqv9wF8I08G4RiYrIc4GXcfSX2WFcfe503oArpm/BVWGdjzsQ9nO0lDPZD4DTReQNfp1REXm6iJzpx7cAA6qaE5GLcBe8Kfmg+QXgL3An4ct8gJvKl32+vuWby0ZF5FLgU7gqiWEAVe3FVU18CXcj/2GffhD4L+D/FZFWEQmJyFNE5Jj9XKUFX0UiImuZ/QlSS97/uZJ3XFXEn4tIWEQuY+Ix0IL71TzkSy3XzGL9Ux0H38Pd/3wH7p5NtYuAPVWlrql8DfgfuMD6rUqiiLxeRHr8r+whn1w6dvaJROQf/XEU88f2O/z8O3HbHuCrxkXk/bhGQFP5Cu44utTvx4S4x17WTTP9CfHb90XgX0RkjV/XM32p9YTz4EtNNwIfFZEWf0F8l1/mcfl992pco7Dzq/7eDrzuBFtrfs7nZ4NfR4+IXO6H/1hEnuprCkZwwfi43/c07mDm69m9uJqBlLjHUK6qzOiPnWf40mGao40taub3/XeAD/h1nMEsgrO4Zzj/Gnduvs8fI024oNXrp3kTroRWcRhYJ64ldEXN19CKRg9oN+BKScmqtLW4C1r13ym45s0vwv2y+wzuvsfv/TxfAM7yRd3vTbGebcBnVPVQ9R/uAJ5c7QiAqo4ClwBX4H5RHcL9Eq88iPtXwIdEZBR30/nGGbbzWuD7qvpDVe3HHaD/ISJdU6w3D7wA92vxDtzJ8y/A/6Oqk0t2X/PTfm1S+pW46pyHcNW6NzFzNdAHcRf9YeD/wx3sszZF3rPAj3F14x+smvQduBN4CFeN+72qcZ/E3Wfqw5VGfzyLLHwAuN4fB6/2ecoC38ZVTU3ertfhjoGZfB13P+JWVe2rSr8MeFBExnAtE69Q1RyMP5T87GmWp7gfIX244+qFwEtUdQxXpfUj3I+vJ3AXqymrglR1H66Ry9/jLiL7cD9E6nHO/y2uwcVduOqlj+Pu38w1D2/HXZQfx90T/houeNbiFbjj64ZJ5/QXcPeILqtxOdX+FVdi+C9/Xt8OPMOPW4U7j0ZwVZE/p8bgO5mqFpj5evYJXKvtw7gahupq8lZcSWgQd4z0A//7BLLx17jq7EO4H6Jfx9XszGRIRNK4Y+HFwKtU9Yt+mx7CtYS9zef7qbjq/opbcQ2RDolI5TyazTUUAPE32xqWiPwTcERVP7nYeTHzy/+K/BGuKuWNukgHoy/pnK6qr69KW4G7KF1QCUTGLFci8nFglapO+QO/UTR8QDNLm4i04UpkN1b9Al3I9XfinnV5g6r+YqHXb0wj8tWMMVxp6+m42z9/oarfW8x8HY8FNLNsichf4qowv6yqb1nk7BjTMMT1lPR1XIvLI7iW0B9brFqUWllAM8YYsyQ0eqMQY4wxpib17Gj0pNLd3a0bN25c7GwYY8xJ5e677+5T1Z7FzgdYQBu3ceNGduzYsdjZMMaYk4qIzPSc5oKyKkdjjDFLggU0Y4wxS4IFNGOMMUuCBTRjjDFLggU0Y4wxS4K1cjxJDWUK7O5LM5It0pqMsqm7ifZU7PgzGmPMEmUltJPQUKbAPXsHKQRlOlIxCkGZe/YOMpQpLHbWjDFm0VhAOwnt7kuTikVIxSKIyPjw7r70YmfNGGMWjQW0k9BItkgyGp6QloyGGckWFylHxhiz+CygnYRak1GyxYkvoc0WS7Qmo4uUI2OMWXwW0E5Cm7qbyBQCMoUAVR0f3tTdtNhZM8aYRWMB7STUnopxwfoOYpEQg5kCsUiIC9Z3WCtHY8yyZs32T1IuqFkAM8aYCiuhGWOMWRIsoBljjFkSLKAZY4xZEiygGWOMWRIsoBljjFkS6hbQRGSLiNxb9TciIu8UkU4R2S4ij/r/HVXzvE9EdonIThG5tCr9QhG534/7lIiIT4+LyDd9+h0isrFqnm1+HY+KyLZ6bacxxpjGULeApqo7VfV8VT0fuBDIAN8F3gvcoqqbgVv8Z0TkLOAK4GzgMuAzIlLp3+mzwNXAZv93mU+/ChhU1dOATwAf98vqBK4BngFcBFxTHTiNMcYsPQtV5fh84DFVfQK4HLjep18PvMIPXw58Q1Xzqrob2AVcJCKrgVZVvU1VFbhh0jyVZd0EPN+X3i4FtqvqgKoOAts5GgSNMcYsQQsV0K4Avu6HV6rqQQD/f4VPXwvsq5pnv09b64cnp0+YR1UDYBjommFZE4jI1SKyQ0R29Pb2nvDGGWOMWXx1D2giEgNeDnzreJNOkaYzpJ/oPEcTVK9V1a2qurWnp+c42TPGGNPIFqKE9iLgt6p62H8+7KsR8f+P+PT9wClV860DDvj0dVOkT5hHRCJAGzAww7KMMcYsUQsR0F7L0epGgJuBSqvDbcD3q9Kv8C0XN+Eaf9zpqyVHReRif3/syknzVJb1SuBWf5/tJ8AlItLhG4Nc4tOMMcYsUXXtnFhEUsALgTdXJX8MuFFErgL2Aq8CUNUHReRG4CEgAN6mqpWXfr0VuA5IAj/yfwBfAL4sIrtwJbMr/LIGROTDwF1+ug+p6kBdNtIYY0xDEFegMVu3btUdO3YsdjaMMeakIiJ3q+rWxc4HWE8hxhhjlggLaMYYY5YEC2jGGGOWBAtoxhhjlgQLaMYYY5YEC2jGGGOWBAtoxhhjlgQLaMYYY5YEC2jGGGOWBAtoxhhjlgQLaMYYY5YEC2jGGGOWhLr2tm+Wt6FMgd19aUayRVqTUTZ1N9Geii12towxS5SV0ExdDGUK3LN3kEJQpiMVoxCUuWfvIEOZwmJnzRizRFlAM3Wxuy9NKhYhFYsgIuPDu/vSi501Y8wSZQHN1MVItkgyGp6QloyGGckWFylHxpilzgKaqYvWZJRssTQhLVss0ZqMLlKOjDFLnQU0UxebupvIFAIyhQBVHR/e1N202FkzxixRdQ1oItIuIjeJyO9F5GEReaaIdIrIdhF51P/vqJr+fSKyS0R2isilVekXisj9ftynRER8elxEvunT7xCRjVXzbPPreFREttVzO82x2lMxLljfQSwSYjBTIBYJccH6DmvlaIypm3qX0P4V+LGqngGcBzwMvBe4RVU3A7f4z4jIWcAVwNnAZcBnRKRyE+azwNXAZv93mU+/ChhU1dOATwAf98vqBK4BngFcBFxTHTjNwqgEtedsWWHBzBhTd3ULaCLSCvwR8AUAVS2o6hBwOXC9n+x64BV++HLgG6qaV9XdwC7gIhFZDbSq6m2qqsANk+apLOsm4Pm+9HYpsF1VB1R1ENjO0SBojDFmCapnCe1UoBf4kojcIyL/ISJNwEpVPQjg/6/w068F9lXNv9+nrfXDk9MnzKOqATAMdM2wLGOMMUtUPQNaBHga8FlVvQBI46sXpyFTpOkM6Sc6z9EVilwtIjtEZEdvb+8MWTPGGNPo6hnQ9gP7VfUO//kmXIA77KsR8f+PVE1/StX864ADPn3dFOkT5hGRCNAGDMywrAlU9VpV3aqqW3t6ek5wM+ur0uPGz3cesZ42jDFmBnULaKp6CNgnIlt80vOBh4CbgUqrw23A9/3wzcAVvuXiJlzjjzt9teSoiFzs749dOWmeyrJeCdzq77P9BLhERDp8Y5BLfNpJxbqPMsaY2tW7c+K3A18VkRjwOPAmXBC9UUSuAvYCrwJQ1QdF5EZc0AuAt6lq5cnctwLXAUngR/4PXIOTL4vILlzJ7Aq/rAER+TBwl5/uQ6o6UM8NrYfq7qOA8f+7+9JcsN5aDBpjTDVxBRqzdetW3bFjx2JnY4Kf7zxCRyqGf+wOAFVlMFPgOVtWzDCnMcYsDBG5W1W3LnY+wHoKaWjWfZQxxtTOAloDs+6jjDGmdhbQGph1H2WMMbWzN1Y3OBfULIAZY8zxWEA7SQ1lCuzuSzOSLdKajLKpu8lKbsaYZc2qHE9C9nyaMcYcywLaSaj6+TQRGR/e3Zde7KwZY8yisYB2EhrJFklGwxPSktEwI9niIuXIGGMWnwW0k5A9n2aMMceyRiEnoU3dTdyzdxBwJbNssUSmELBl1dJ4h6k1eDHGnAgroZ2ElvLzadbgxRhzoqyEdpJaqs+nWYfMxpgTZSU001CswYsx5kRZQDMNxRq8GGNOlAU001CsQ2ZjzImygGYaylJu8GKMqS9rFGIazlJt8GKMqS8roRljjFkSLKAZY4xZEuoa0ERkj4jcLyL3isgOn9YpIttF5FH/v6Nq+veJyC4R2Skil1alX+iXs0tEPiUi4tPjIvJNn36HiGysmmebX8ejIrKtntu5GCoPIP985xF78NgYY1iYEtofq+r5qrrVf34vcIuqbgZu8Z8RkbOAK4CzgcuAz4hI5YGkzwJXA5v932U+/SpgUFVPAz4BfNwvqxO4BngGcBFwTXXgPNlZbxrGGHOsxahyvBy43g9fD7yiKv0bqppX1d3ALuAiEVkNtKrqbaqqwA2T5qks6ybg+b70dimwXVUHVHUQ2M7RIHjSs9fHGGPMseod0BT4LxG5W0Su9mkrVfUggP+/wqevBfZVzbvfp631w5PTJ8yjqgEwDHTNsKwJRORqEdkhIjt6e3tPeCMXmvWmYYwxx6p3s/1nqeoBEVkBbBeR388wrUyRpjOkn+g8RxNUrwWuBdi6desx4xtVpTeNSj+HYL1pGGNMXUtoqnrA/z8CfBd3P+uwr0bE/z/iJ98PnFI1+zrggE9fN0X6hHlEJAK0AQMzLOukMl3DD+tNwxhjjlW3gCYiTSLSUhkGLgEeAG4GKq0OtwHf98M3A1f4loubcI0/7vTVkqMicrG/P3blpHkqy3olcKu/z/YT4BIR6fCNQS7xaSeNmRp+WG8axhhzrHpWOa4Evutb2EeAr6nqj0XkLuBGEbkK2Au8CkBVHxSRG4GHgAB4m6pWeql9K3AdkAR+5P8AvgB8WUR24UpmV/hlDYjIh4G7/HQfUtWBOm7rvDvea1Tm0puGvUDTGLMUiSvQmK1bt+qOHTsWOxvjfr7zCB2pGP4HAQCqymCmwHO2rJhhzplVSn6pWGTC266thGeMOREicnfVY1mLynoKaVD1eo2KNfk3xixV1jlxg+psirH9oUOUytCZitLZFCcUgi2r5vZ8+Ei2SMekklgyGmbQHso2xpzkaiqhicgfisib/HCPb7Rh6mQoU+Dx3jE2dTXTmYoykCmwuz/NqT3Nc64WtBdoGmOWquOW0ETkGmArsAX4EhAFvgI8q75ZW76qqwVXtCYAyBQCBtIFNnTNrWn+pu4m7tk7CDDhHtpcS37GGLPYaimh/QnwciAN48+WtdQzU8tdPXsCsSb/xpilqpZ7aAVVVRFRGH+mzNRRvXsCsRdoGmOWolpKaDeKyOeBdhH5S+CnwL/XN1vL21Q9gfSO5hjNFe11McYYM43jBjRV/d+4nuy/jbuP9n5V/T/1zthyNrlaMB+UUCAeCdvrYowxZhq1NArZBPxSVbf7z0kR2aiqe+qdueWsPRVjU7drIPLbvYPEIyG6muLjz47B0V5DjDHG1Fbl+C2gXPW55NNMHVX35RgCQgg7D40ymnMNQ6ZrJGJvsjbGLFe1BLSIqo5fFf2wFQvqrLrpfksiiggkomEODGWBqRuJ2JusjTHLWS0BrVdEXl75ICKXA331y9LyNbF0NUBQcgXjNe1JcsUSqmXGcsG0r4uxbq2MMctZLc323wJ8VUQ+jXtx5j7cK1zMHFX3ei/inj/raUnQkYoRC4e578lhntLdzEiuSC4oc2g4T0syQiwSYsuqY58ds26tjDHL2XEDmqo+BlwsIs243vlH65+tpa+61/uOVIz7nhxiLFek0zf8OLWnmTt29/PLR49w5upW2hKuenFdR/KY171UAuNjvaPEwmFO7WmmxU9v3VoZY5aLaQOaiLxeVb8iIu+alA6Aqv5LnfO2pE1+31lQgtZElANDWbasitKSiNKRijKUKVAoQXM8xHnr2gmHZELrxurAuGVlK/c9Ocx9+wd56tp2IuGQdWtljFk2ZrqHVrlB0zLNn5mDyd1bNcfDgDCWD8bT8kGZc9a0cfrKZgAeOTzG3v70eMMQmBgYW5MxzlvXTnMiyu8Pj1q3VsaYZWXaEpqqfl5EwsCIqn5iAfO0LEzu3mpNe5Lf7R+iJR5BVckWSxSCMo/3jvHThw4TDYdY05GkPRkllgsYyhRoT8WOuW/Wkohy7tp2BjMFLlhvJTNjzPIxYytHVS3hOiY282xy91bhkLCuI8n6rtR47yBN8TA7D40SiYRIxELs7U/zWN8YPc3x8ZaL9joYY4xxamnl+BvfwvGb+B73AVT1t3XL1TJQ6d5qd1+awUyB1mSUZ2/uGa8evGfvIEEJIuEQ6VyRdE5oSUVoTUQpBKXxh6rtdTDGGOPUEtD+wP//UFWaAs+rZQW+2nIH8KSqvlREOnHBcSOwB3i1qg76ad8HXIXrjeR/qOpPfPqFwHVAEvgh8A7/BoA4cANwIdAPvKbSJZeIbAP+wWfjI6p6fS35XUgz9Xp/YCjLnv4xWhIRQhJDBAqlMkFJGcgUOW1lS9UyJgbGqZr0L7bqRxRak9FjWmoaY8xc1RLQXqWqc3mQ+h3Aw0Cr//xe4BZV/ZiIvNd/fo+InAVcAZwNrAF+KiKn+2rPzwJXA7fjAtplwI9wwW9QVU8TkSuAjwOv8UGz8mJSBe4WkZsrgfNkMJYLSEXDJGNR+sfyxMIhQBnKFNjQnZrwUHWjvw5m8iMK2WKJe/YOWoMVY8y8mqnZ/suALwJFESnjSlK/mc3CRWQd8BLgo0Cl+f/lwHP98PXAz4D3+PRvqGoe2C0iu4CLRGQP0Kqqt/ll3gC8AhfQLgc+4Jd1E/Bpcc8VXApsV9UBP892XBD8+mzyPx9qKZlUpnn08Ch7+jOIT0tGQwSlEl1NMYayBcayBVpTMV541qqTKhBMfkTBOlc2xtTDTCW0jwLPVtXfi8gzgH8GnjPL5X8SeDcTm/mvVNWDAKp6UERW+PS1uBJYxX6fVvTDk9Mr8+zzywpEZBjoqk6fYp5xInI1ruTH+vXrZ7lpxzdVyeSXj/bSloyi6hp0dDbFeLx3jJFswD17B4mHQ4TDgggcGSuwqauJdCGgIxVjy8pWzljdwoauk+sdq9aDiTFmIcwU0AJV/T2Aqt4hIrN69kxEXgocUdW7ReS5tcwyRZrOkH6i8xxNUL0WuBZg69atx4yfq8klk1JZ2T+YZThT5Nx17WSLJbY/dJhNXU3sOjJKSzxGcyJCISgRCZdRVXJBiZeft5be0Ty7+9OM5gJ+8cgRn39OivtR8/EGbrsHZ4w5npkC2opJvYRM+FxDTyHPAl4uIi8GEkCriHwFOCwiq33pbDVwxE+/Hzilav51wAGfvm6K9Op59otIBGgDBnz6cyfN87Pj5HfeTS6ZHBjK0paIMpQt8sjhUcbyJfb2p4mGYDBTpLvZTRuNhCjky5yxqpWHDo2wbzDDweEsm7qaSURD3PfkMILy1LXt4z3qN/L9qLm2xLR7cMaYWsz0HNq/M7FnkMmfZ6Sq71PVdaq6EdfY41ZVfT1wM7DNT7YN+L4fvhm4QkTi/qWim4E7ffXkqIhc7O+PXTlpnsqyXunXocBPgEtEpENEOoBLfNqCmvyM2Fi+RKZQpH8sT7GktCYiNMUiPHhglGQ0RCbvetcvBmVEYOfhUUazRe7eM0i5DMlYmIPDOdqTMdqSMQ4O506KHvUnv4F7tj2Y2FsEjDG1mKmnkA/WaZ0fA24UkauAvcCr/PoeFJEbgYeAAHibb+EI8FaONtv/kf8D+ALwZd+AZAAXOFHVARH5MHCXn+5DlQYiC2lyySQShseOZNjY3UzCd3vV3RJnrBDQnIhwaDhHIQgoapmRbMBApsh569rY05tmV+8odz8xQCIaYWNXkp6WBPkgGF92o9+PmktLTLsHZ0x9LLWqfHEFGrN161bdsWPHvC938itibn+8n3XtSRLRCIOZAgeGs6SiYfrTeZKxCIeHswxli5RKSndznFAI8sUyw9kiYREQ4dSeJt8jfxNPW99JphCMl3qWospLS6vvwS31bTam3qqr8qtvBcy2Kl9E7lbVrXXMas1qeQ7NzMFUJZO9/RkOj+boG8uzpi0J6p4v626Oc9HGTm55+Aj96TzhEIiEGMkVKJeVcERoiofpS+fpSEZR1fHus5ZyzyDWG4ox828pPk5TyxurzTw6d107azuStMQjPKW7iVQswoHhHBu7m2hPxnjgyWG6m2O0xCL0pQskY2FCoRDRaIRoWEhEwnSmYpy+soWxXLAsetSf6z04Y8yxJr/xA9wPxkq3eiej45bQRGQl8E/AGlV9ke/R45mq+oW6524JOtpV1RghQjQnhK7mOB2pOOlCwCOHx1jZGicXlBnLudJXNKSM5AI2rWljY1eKtmSMUzpTy6rKrdF7QzHmZDMfj9M0mlpKaNfhWgiu8Z8fAd5Zp/wsC+7i3MmZa1rZsqqVFS1xDgxluP2xfkZzRdL5Em2pKB1NMYazRZAQ3U1xVrcmEKAjFSNTCCZ0f2WMMbMx+Y0fleGT+bpSyz20blW90XccXOmRo3S8mczMqu8LtSQifO/eAfLFEm3JKE8OZYhFwjx9YwfxSJhQSGhNRFCF5kSEzubYSd8ayRizuE6Wjs1no5aAlhaRLnxPGyJyMTBc11wtA+2pGKf2NHP7Y/3cuaefsVyRlS1xkvEIyViYXLHEoZEcp/Y082dPW3dSH2TGmMa01Kryawlo78I9wPwUEfk10IN7iNnMwVCmwOO9Y2zsbuLRw6Ns6EgRAKvbUyQjYfJBwGgu4GnW+MEYY2py3ICmqr8VkecAW3B9JO5U1ZO3GUyDmNBkVqC7NcHhkTxPDqSJhIQDQ3nypYCLn9LFpszR6sWl9iCkMcbMl5leH/On04w6XURQ1e/UKU/LQqX3i9FckVyxxO8PjlL2PYQ0JyLEIyHOWNnC3v40o9mA1e0JRnMBB4dzbOpqoqclbn0aGmNMlZlKaC+bYZwCFtDmoNJryCNHRhlKF0hEQ+wfLDCYzZMrlnjKimZOXdFCSIQHDgxTLJeJh0NEBPYOpEnGwrQkXPPa6gchrQRnjFmuZurL8U0LmZHlZChTYCRbZN9ghkKxRCwsHBkJKAQBLfEIyWiEbLHEvoEMiWiIkAijuYA9Y3kEiIRDhEKjPG1954Q+Da1XemPMclZT11ci8hLgbNxrYABQ1Q/VK1NLyVQlpt19aXpaEqxpTzKSLZDJlwmHoLMpTlBWCkGZQlBmMFOgXIYVLTH6RnPEI2HcCweURw6NsHlFC+GQjD8IuRS7sjHGmFod98FqEfkc8Brg7bhGIa8CNtQ5X0tCpcRUCMp0pGLj7y47MJQlGQ3T0xynKRZhIFegdzTP4bG8C3DFgJFskYcOjPDwoWHu2TtErlCiPRVjJFdk/2COoUyRn+/spXc0N/4g5FLsysYYY2pVS08hf6CqVwKD/pUyz2TiizjNNKZ7j9dYLiBbLBEOCU/0ZwiCMiUtUwpKFAIlEQ6RK5YZyhRoS8ZoTUXoSxfZ1TvKWC6gGJTpao6RLQYTXsM9+f1rcPJ3ZWOMMbWqJaBl/f+MiKwBisCm+mVp6ZiuxCQC9z85zPaHDpKIhoiGwwxmiozmS4zmivSO5ciXyrQmo0TCQlM8ynCuyH37hzk8muOUrhQbupo4d107K1oS4y+6XIpd2RhjTK1qCWg/EJF24H8BvwX2AF+vY56WjKlKTL2jedfRcFcTI7kSe/rS7BvMgLovo1SGbBHGckWGskUGxwo0RSMMpfMMZ4poucxQJs8dj/ezdyDD3v40B4bcbw7rld4Ys5zV8mD1h/3gt0XkB0BCVa3rqxpM9R6v3f1jbOpqJhkLEwQligqRkBIWoYiiApUyXbYQMCTCb/cN0pWKEZRgIF1EybChK4UA6XzAcC5gKFOgPRVbcl3ZGGNMraYtoYnI00VkVdXnK4EbgQ+LSOdCZO5kN1WJaXVbkp6WOAeGsqgKo9kiI7mAfEkplqCsgEKxBMUAVMuM5Yuk8wHrOpM0J6N0N7uANZwrosCmrqbxakdjjFmuZiqhfR54AYCI/BHwMVxLx/OBa7H+HGsyVYmpdzTPnbsH2D+UJhIWKICqe1o9DCCQCEE4LBRLSjQM7U0xWhKu4+KmWIT+sQJnrk6wZVUrzfHI+LNoxhizXM10Dy2sqgN++DXAtar6bVX9R+C04y1YRBIicqeI/E5EHhSRD/r0ThHZLiKP+v8dVfO8T0R2ichOEbm0Kv1CEbnfj/uUuIexEJG4iHzTp98hIhur5tnm1/GoiGyb1V6po86mGDv29PPAgSGKJSVbKCEiRCNCGCgDkRBEIiESsQiRcJiOphjN8TDZQolTOpIko2E2dDXxzKd005KIWktGM/6IyM93HuGevYMM2Q8cswzNGNBEpFKCez5wa9W4Wh7IzgPPU9XzcKW6y/yrZ94L3KKqm4Fb/Gf8m7CvwD3AfRnwGRGp3E76LHA1sNn/XebTr8I9TnAa8Ang435ZncA1wDOAi4BrqgPnYnqiP00ZyBVLRMNhBBCUsirhEIQE4rEQ0XCIzqYYPc1RIhKmUCqzqi1OKh4lG5Q5d107zfGItWQ00z7vaEHNLDczBbSvAz8Xke/jmu7/EkBETqOG96GpM+Y/Rv2fApcD1/v064FX+OHLgW+oal5VdwO7gItEZDXQqqq3qaoCN0yap7Ksm4Dn+9LbpcB2VR1Q1UFgO0eD4KJ69MgYIWBNW5LWZJT2ZJymeJRULEJrMsK5a9o4Z007XS1xupsTPPWUDla3uY6JnxzM0ZoI8/qLN7C+K2UtGQ0w/fOOdl/VLDcz9eX4URG5BVgN/JcPJuCC4NtrWbgvYd2Nq6L8N1W9Q0RWqupBv46DIrLCT74WuL1q9v0+reiHJ6dX5tnnlxWIyDDQVZ0+xTzV+bsaV/Jj/fr1tWzSnAnKUKZIuQxDmTxBWSmWyiAQlRDDuQIDWaW7OYYI7Dw0QmdTnPPWtVNWyAfKnv40z97cY0HMAEff3FCtuo9PY5aLGasOVfX2KdIeqXXhqloCzvfPsX1XRM6ZYXKZahEzpJ/oPNX5uxbXwIWtW7ceM36upurHcVVbkl/u6qM/kydbLFEolglUiYSgpGXCkTCgDGYCRGFlS4JENIyEQrTFIrQnYwxni9Y/oxlXed6x0ncnWA8xZnmq5cHqOVPVIeBnuGq/w74aEf//iJ9sPxO71FoHHPDp66ZInzCPv9/XBgzMsKwFM919DYCVzXEODecAaE1FSURDBCUQhXS+SCoaJiiX6U0XOTicpS9d4NFDIzQlwsQjIYJArX9GM856iDHGqVtAE5EeXzJDRJK4RwB+D9wMVFodbgO+74dvBq7wLRc34Rp/3OmrJ0dF5GJ/f+zKSfNUlvVK4FZfNfoT4BIR6fCNQS7xaQumcl+jVFYeOTzKwwdHeHIwy4MHRsgUSkTDIYpBmbFcQL5QpliGdF4Zy5UYSBcolWEoXWAoUyQZDZGIhekdyTGYKRCJiP36NuOshxhjnJpeH3OCVgPX+/toIeBGVf2BiNwG3CgiVwF7cb33o6oPisiNwENAALzNV1kCvBW4DkgCP/J/AF8Aviwiu3Alsyv8sgZE5MPAXX66D1U9grAgRrJFIiHhkcOjJKJhWhNRBtJ57nligP50kWLZNdcvFMsUfGVnCQgLZItlMkGesEChVGZff8Y3IImQC8pctKlz/Ne3vdDTwNTPOy4EO/5MI5GjbT2Wt61bt+qOHTvmbXn37B3kwSeHCYeERNT9brh//yC7+9M8tH+Y0XyRbHDsjb1IyEX/wLUToSUVZm1rgmg4QkiUp23s4K+fdzrtqdiEF3pWutbKFAL7dW4WhB1/BkBE7lbVrYudD1ige2jL0abuJgbSBdcDiCq5Yok9/WkiIowWAjJTBDNwgaxQdg9YCxAPh2hNxQjKZRQZv/cG1lzbLC47/kyjsYBWB5VqmHDIPUh9eDRHsVRCFQ6P5sgWpy8VV+pnQ0Ai4vp2zBZKRMIhiuUS/ekCv3q0l6FMwV7oaRaVHX+m0dTzHtqyVF0Nc9qKFn61q4/B3jFakxES0TB7+jNTlswqFBfMBJCQEAkJpbJS1jKFktImwp27BzgymqMpFmU4W6QQlBnLBzTHI3SkYnQ2W3WPqT97XMA0GiuhzbPq1o0HhrJs7ErR1RRnT1+GI8M5ylqe8iG5ijKAQCgMuaKi6rrJKqsQFiEWDvHkYJpcsUwiGubWhw9zZDRHSzzCWK7IA08O0dl0bECzvv7MfLPHBUyjsYA2zyrVMAeGsiSiYTqbEmxe2cKqtiTZwFU7hmeKaEDE1+LEIqAo2WKZXLHE6rYE7ak4zckY2UKJYqnM6StbyBZKjOZLNCeinLO2nYH0xGBlff2ZerDHBUyjsSrHeVaphhnLB4RDwp6+NMO5In2jOXKFAFSIhJUgmH4ZxRIkI0I8GiZfLNMcj3JKe5JCUKYQBHQ2x0nGIozlA1a2JhjNl7hwg+t7WVWP6fKo+uY9MP7fehsxc2UvlDWNxEpo86xSDVMISuw6MuoadAjkimUikRDx6PF3ecnfZEvFInQ0xQiHhMf6MwxliqxoTbCxK8WKljjN8QijuSLN8aM35qe6h2E3740xy4EFtHlWqYaJhIVsISAcgY3dTRRKZdqTMc5a3UYsfPzdXlQFUVa1JljdlmB1S5zmRIiWRJRiqczqtgQdKdevY0cqdsw9jOp7ZoeGc/SO5ics327eG2OWGqtyrIP2VIyVrUlCIuwfzLrnz0JCtlDmwHCWfFA+7jLyAZRL0JaMkYiFyAc5xvIl+sdytK9oZihbZE17klc8bR0D6QKDmQKtyShbVrmqx0pLy45UjKCkPPDkEOfQTk9LfPwB2Mq0U6mlBwjrJcIY00gsoM2jygX+wFCWXz/aS7HkXg2TLgT0pfPk8iVGckUKpeMvKxGGUrnM/U8Osa4jSSwaYnN7M5tXtHLmmtbxklh7KsaGromtyirBLBVzVZKDmQIK3L13kLPXtLKmPcmWVdPfvK9+9KAjFSNbLHHP3sEJN/xrmcYYYxaSVTnOk+qWhL2jOUbzAY8cHqUQlAjKZYpFZShbpFAsz/gcWkWpjLvnFhH2DWbZP5AlLEIoxHF7ZKjcMxvNFdl5aJRiSTmlI0VbMkIqFj5uSaqWHiCslwhjTKOxEto8qb7A7x/MogpN8TAHh91LPMOiFEql8QYfxxMW10NIXkAQNq9o5snhHDCEAqf1NJMrTl3Uq7S0rDw6kIiGyRUDupri40FnppZptbww0l4q2disOtgsR1ZCmyfVLQlzQYnDI1mS0TBNiQhhUQ6OZskVlOLxb5+5ZZRdQGuKR+lsjlMMyrTGoqxsTXBoOMf9Tw4h0zzPVmlp2Z8uEAsLuWJArlhiTXuyptaNlYBYbXIjklqmMYvDnjs0y5UFtHlSfYEXIFMosX8wy8HBLJliiXJZqDGWjcsHSroQIALpQsndixvLM5QuoDP0N1JpadmejNKXzhMNh9iyqpWWRLSmoFNLDxDWS0Tjsupgs1xZQJsnlQv8kZEcmXyJzuYY2aBMNigxnAsISuVZB7RwCFoTrkurbKFIa8L13ThWCDi1u4mZ3vzTnopx6TmrOH1lC6d0pmiOR2oOOrX0AGG9RDQue+7QLFd2D22etKdinNrTzPW/eZwnBjKIKk3REH2FEoViQA0t9Y/RkYrSP1YkFQ+TikVJxUOkYu5B61/v6uPsNW0MZQozNqcPh4R8UCLnS2YztW6cvD3H6wHCeoloTNZpsFmurIQ2T4YyBe7fP8RYrsR5a9toSkQYyBRQVUplrallY7UwkIxFaIqH6UrFyBRd0/8ySkQgKJfpbo4fc29k8v2TeCRMqaycd0q7laCWCasONsuVBbR5srsvzVCmSFdzHAkJI9mAYqnMaK7IWFEJZhnRElEQgWg4xOqOJBds6CCEEAmFiUbCnLGqlRWtCWtOb45h1cFmubIqx3kyki1SLJVZ257kZzvdK12ioRCqNTxFPUkI9160fLFMZ1MUVQWFzqY4p69oJh+UOW1FC2DN6c3UrDrYLEd1K6GJyCki8t8i8rCIPCgi7/DpnSKyXUQe9f87quZ5n4jsEpGdInJpVfqFInK/H/cpEddgXUTiIvJNn36HiGysmmebX8ejIrKtXttZ0ZqMEg2HCIeEoVyAECJdCCidwL2zZBRS8QidzTFO6UqxrsNVFcUjQhlly6oWWhLufog1pzfGGKeeVY4B8DeqeiZwMfA2ETkLeC9wi6puBm7xn/HjrgDOBi4DPiMilaZanwWuBjb7v8t8+lXAoKqeBnwC+LhfVidwDfAM4CLgmurAWQ/uwdUoh0ZyDIzmCYeEYkmZbfksIpCIRCgUyxweySEqrOtIsrG7mWdt7mFte5JwSKw5vTHGTFK3gKaqB1X1t354FHgYWAtcDlzvJ7seeIUfvhz4hqrmVXU3sAu4SERWA62qepuqKnDDpHkqy7oJeL4vvV0KbFfVAVUdBLZzNAjWRaVPxfv2DdE7mqd3NEvoBPZuoJAvKc2JCCERDgzneLxvjFO7m2iKRaw5vTHGTGNB7qH5qsALgDuAlap6EFzQE5EVfrK1wO1Vs+33aUU/PDm9Ms8+v6xARIaBrur0KeapztfVuJIf69evP/ENBJ7oT/PD+w4wnC1y5qpW9g1l6Zv0ypZa5YMSuQLEIiGaExGyhRJPDKR5+sau494bsS6PjDHLVd0Dmog0A98G3qmqIzJdf01M2fWFzpB+ovMcTVC9FrgWYOvWrbNtWT/B7Y/1UyyVScXDhEXoaorSN5afYq3HVyrDSLZEIlYmijKUKfDrR/roSMUYzRV93pkQsIYyBe7bP8S9ewfpbI6zqatpvMujRi6hWQA2xsyXujbbF5EoLph9VVW/45MP+2pE/P8jPn0/cErV7OuAAz593RTpE+YRkQjQBgzMsKy66R3NUSiV0bLyyOExBjJFyifQIASgDERDkIxG2NWfYTQXcEpXinQ+4KEDw9z9xCB7+sa4c3c/N929n/v3D3HP3kH29mfobo4TlhCPHB6jVNaGbrJvfQ4aY+ZTPVs5CvAF4GFV/ZeqUTcDlVaH24DvV6Vf4VsubsI1/rjTV0+OisjFfplXTpqnsqxXArf6+2w/AS4RkQ7fGOQSn1YXQ5kCB0dy/PyRfh49MkYmH5DOB7NuEFIRAZLxCOGwkM27Xj5Gc0VuefgI9+8f4d69A9z75DBNsQgRgW//dh/lMgRlJRGNjPewf2Ao29BdHtkzc8aY+VTPKsdnAW8A7heRe33a3wMfA24UkauAvcCrAFT1QRG5EXgI10LybXr0Ia63AtcBSeBH/g9cwPyyiOzClcyu8MsaEJEPA3f56T6kqgP12MihTIFfPdrL7t5RjoxkKASccCCriEahEJTIl0tEJEShVGY0F9A7nCMolwmJkM0HPNGfYX1XimyhzEA6T3M8Qj4okYhGiEdCjOSChm6yb8/MGWPmU90Cmqr+iqnvZQE8f5p5Pgp8dIr0HcA5U6Tn8AFxinFfBL5Ya35P1O6+NA8dGOHx3gww92AGUCpBKALJiCttRcNhjozmaUlFyRZKtCdjBCWIR8IcHMrS0xJnIFPgqWvb2XloBHD32CJhyBQCtqyq6xMLJ8z6HDTGzCfr+mqORrJFdjwxQC4okQvmZ5lBGeLhMK3xCMloiEQ0RKmkjOYKHBrJs38oTTofkC0GDGcDNq9oIRxyD3WfvrKFUlnpG8uzvjPV0A1C7Jk5Y8x8sq6v5kgE+kbzlLV8Ig0ajxEGIiFoTriXg56zppW+dIFiUKI/XaI9FaNcKlEslTg4lGXL6hZakxHOX9/OQLpArlji7LVtJ0Vrwcozc7v70gxmCrN6G4AxxkxmAW0etCaiHBjKzsuyohGIhUJEQiHWdiRJxCLE8wGJSJiWWIRTu5solMrEwyFS8TAtich4KWxDV31KNvVsWn+y9zlojx0Y0zisynGOVOGM1c3k5+PmGRCSEG1NMZriEUIIxaBELBxmtFCivSlGLijR2RRjVXuCy89fy1N6Wup6AbWm9dOzfWNMY7ES2hyJwJ6BLGFh1q+ImUq5XKYtGeXM1a2EBNLFMtGIcPGmTpJR17x9NF9gfWeKSDhEKl7f3yTVTeuB8f+7+9IndclqPti+MaaxWAltHhwYylKejxtoQCgkJCMhtqxqZevGLs5c1Uo8EmZtR4p8qUQhCFCFXLG8IA0oRrJFktHwhLRGfrZtIdm+MaaxWECbo0PDOTKFgBPsFGSCeBia4u4CmQ9KrGlPEguHWN2WoC0Zpas5TjwaYVVbgnBYFqQFo72OZnq2b4xpLFblOEe/PzRMaNrH7WbHhTJhZVuS5niElkSUQqnMcCYgFQvoaY6zZp17fUwsElqQxgebupu4Z+8g4Eof2WKpoZ9tW0i2b4xpLFZCm6PhbEAsLPOyI4vAipY455/STrkMR0ZyDKbzJGIhYuEQhaDEffsH6R3NLdizWvY6munZvjGmsVgJbY7akhHaUnH6xwpk59jSsSXu+mDcO5ChVCpzZCzPGavb6GmJc2Aoy1i+RHMiSmsyuqAXzZO9aX092b4xpnFYCW2Otm7sIhENEY+Fjz/xDEJAcyzC4ZE8+4eynL6qhVhY6E+7d6ptWdXKhRs6OHdtOzpPDVCMMWYpsYA2R3/wlG7OWt1KZo4PooVD0DeWJxkN0dMU4/BInocPjvD4kVF2HRkdn84aHRhjzNQsoM3RcLbIvsEs0fCJNwwRIBUN05KI0dkUIxeUCUmItR0p+tNFHnhyhJFswfo6NMaYGVhAm4OhTIGb732SIyN5YpETD2hNsRDdLTE6mlxvEz0tcWKREG2JKO2pKB2pGDsPj1ijA2OMmYE1CpmD3X1pekfzlMplgjnUOKbiIZpjYTb2tDCcKxKPhFCUdD4gFQvzR6d3E5SVC9Zbc3BjjJmOBbQ5GMkWyRQDesfyFEsn9mh1dypCRzLOU1a2sqEzBSIMZvLs6U8TlJQzVrXy4MFhIiGxzm+NMWYGVuU4ByJweCRHUFLi0RNr5ZiIR8gVA/b0jfG8M1dy+soWhjJFVrcmeNr6DnrH8jx6eJS17Snr/NYYY2ZgAW2OBCEZFUZzs69zDAOUobs5jojwRH+apniYl527ljNWt9E7lqc9GeOMVa2M5oLxjnB396XnfTuMMeZkZ1WOc6AK7akoipxQX47RMITDMJIrce4pbQxlihwZzbF1QxcrWhOM5Uu0JtxXNJJzHd4mo2EGrYRmjDHHqFsJTUS+KCJHROSBqrROEdkuIo/6/x1V494nIrtEZKeIXFqVfqGI3O/HfUpExKfHReSbPv0OEdlYNc82v45HRWRbvbaxNRmlGCiRcIj4CdQ4xqJhkrEIa9sTdDfFKZbKZApl7ntyiLufGKR/LMdgpkA+KNEcd4HNnkMzxpip1bPK8Trgsklp7wVuUdXNwC3+MyJyFnAFcLaf5zMiUgkRnwWuBjb7v8oyrwIGVfU04BPAx/2yOoFrgGcAFwHXVAfO+bSpu4lcoUSuEMy6lWMYaEtEOHt1K2esaSNfKlMslVFVxnJFYmFoT0Z5+NAIh4azrG5L2HNoxhgzg7oFNFX9BTAwKfly4Ho/fD3wiqr0b6hqXlV3A7uAi0RkNdCqqrepqgI3TJqnsqybgOf70tulwHZVHVDVQWA7xwbWeVMol1GYdZVjKhHm1BUtrGpLUiqVKZXKFIIyZ61u49x1HcQiYcLhEKevbKYtFSUoqz2HZowxM1joe2grVfUggKoeFJEVPn0tcHvVdPt9WtEPT06vzLPPLysQkWGgqzp9inkmEJGrcaU/1q9fP+uNuW//EJl8kbK63j5q7WIxDKxrT3BKR5L+dA4Q/uj0HlShp8U1ENmyylUrqiqDmQLP2bJixmUaY8xy1yitHKfqZkNnSD/ReSYmql6rqltVdWtPT09NGa123/4hekcLFILSrEpoPS0xnnVaN6d0NrGuPcUfnd5DUyzCWC6gdzQ/YVq7Z2aMMbVZ6IB22Fcj4v8f8en7gVOqplsHHPDp66ZInzCPiESANlwV53TLmnd7+tIMpAsUgtnNF4uEed4Zq3jq2jaKpTK/2zfE7t40w9kiO/b0c2Qkh6raPTNjjJmFhQ5oNwOVVofbgO9XpV/hWy5uwjX+uNNXT46KyMX+/tiVk+apLOuVwK3+PttPgEtEpMM3BrnEp827Q8M5CiWtuaqxYiCd4/HeMXYdGWUoWyRfVFqTUVoSUWLRMHsH0vbCSGOMmaW63UMTka8DzwW6RWQ/ruXhx4AbReQqYC/wKgBVfVBEbgQeAgLgbapaaTf4VlyLySTwI/8H8AXgyyKyC1cyu8Iva0BEPgzc5af7kKpObpwyL7KFgEgICrNo4RgNQSwc4scPHGRTdzOJaJimeBgRIRENs7IlQS4I7J6ZMcbMUt0Cmqq+dppRz59m+o8CH50ifQdwzhTpOXxAnGLcF4Ev1pzZE9SaipGKhglKtd1Di4XdDb6WRJSxfEBfukBPc4wNE6oUFZ3yNqAxxpiZNEqjkJPS0zd00pSMEY9M3RJlsng0THdTnFQ8QnM8QmcqSkdTjLC41oy5YsBIrsjmFc11z7sxxiw11vXVHLzkvDX8du8QD5VKlDIFcjM0DomHoT0RoSMVpzkR4SXnrmFtR5KRbJGhTJHhbIFoOMS6jhTnrmtfsG0wxpilwgLaHGzoauIdL9jM53/xGHftHkCyBYoBlHBFXxGIRaApFqGs7l5bd2uMF565ilVtifHAtbsvzUi2aK+HMcaYObCANkendKZ49mk9lMrKQweGGRgrgChRCZFKxGhNRPjjM1awqi3BE31jjBVKrO1Icu669vHAdcF6C2DGGDNXFtDmaHdfmkMjObKFgLJCUyKKoBRKZZpjIZ66ro1IKERzPMpZa9rpHcvRkohaKcwYY+aZBbQ5OjCU5Z69A/SOFoiHwzTHIChDPihRUkCVbNG1688HJTpTMUayxcXNtDHGLEHWynGOxnIB2XyJkAiJWIhQKEw4JETDQlAuM5DOk4yGyBUDcsUSnU1x68rKGGPqwALaHDUnIqTiEcpaJiRQCEoEJSUkwsrWBGURRCASEtZ3NhEKYV1ZGWNMHViV4xy1JCKsbItzaDhHfzpPRIRYNEQ8HObU7iZe+4wNBGW1VozGGFNnFtDmYChTYCRbpC0RpaclTmsiynCugAh0pGJsWd1CUFYLYsYYswAsoM3B7r40PS0J1nakKJaUgXSB1kKEkAjnrWsnFY1QCMrcs3fQOhk2xpg6s4A2ByPZIh2pGGUVzlnbjoiwp2+M4WyRVW1JRnJFUjG3i3f3pe15M2OMqSNrFDIHrcko2WKJ5niYfOC6Jx7OFWlLRsgHJZrjLpglo2Frqm+MMXVmAW0ONnU3kSkEdKRiZIsBw5k8IZR4NEyuWGJNexKwt04bY8xCsIA2B+2pGBes76CzOcbK1gTJWIQzVrcRi4RZ39lEczxib502xpgFYvfQ5sgFNRfYKoYyBXb3ubdOtyajbFllDUKMMabeLKDVQSXIGWOMWThW5WiMMWZJWNIBTUQuE5GdIrJLRN672PkxxhhTP0s2oIlIGPg34EXAWcBrReSsxc2VMcaYelmyAQ24CNilqo+ragH4BnD5IufJGGNMnSzlgLYW2Ff1eb9PM8YYswQt5VaOMkWaTphA5Grgav9xTER2nuC6uoG+E5x3ITR6/qDx89jo+YPGz2Oj5w8aP4+NmL8Ni52BiqUc0PYDp1R9XgccqJ5AVa8Frp3rikRkh6punety6qXR8weNn8dGzx80fh4bPX/Q+Hls9PwttqVc5XgXsFlENolIDLgCuHmR82SMMaZOlmwJTVUDEflr4CdAGPiiqj64yNkyxhhTJ0s2oAGo6g+BHy7AquZcbVlnjZ4/aPw8Nnr+oPHz2Oj5g8bPY6Pnb1GJqh5/KmOMMabBLeV7aMYYY5YRC2jGGGOWBAtoNTpev5DifMqPv09EntaAeXydz9t9IvIbETmvkfJXNd3TRaQkIq9cyPz5dR83jyLyXBG5V0QeFJGfN1L+RKRNRP5TRH7n8/emBc7fF0XkiIg8MM34RjhPjpfHRT1Paslj1XSLdq40JFW1v+P84VpJPgacCsSA3wFnTZrmxcCPcA90Xwzc0YB5/AOgww+/aCHzWEv+qqa7FdeY55UNuA/bgYeA9f7zigbL398DH/fDPcAAEFvAPP4R8DTggWnGL+p5UmMeF+08qTWPVcfDopwrjfpnJbTa1NIv5OXADercDrSLyOpGyqOq/kZVB/3H23EPmzdM/ry3A98Gjixg3ipqyeOfA99R1b0AqrqQ+awlfwq0iIgAzbiAFixUBlX1F36d01ns8+S4eVzk86SSh+PtR1jcc6UhWUCrTS39Qi5235GzXf9VuF/KC+W4+RORtcCfAJ9bwHxVq2Ufng50iMjPRORuEblywXJXW/4+DZyJ6xXnfuAdqlpemOzVZLHPk9la6POkJg1wrjSkJf0c2jw6br+QNU5TTzWvX0T+GHei/mFdczRptVOkTc7fJ4H3qGrJFTAWXC15jAAXAs8HksBtInK7qj5S78xRW/4uBe4Fngc8BdguIr9U1ZE6561Wi32e1GyRzpNafZLFPVcakgW02hy3X8gap6mnmtYvIucC/wG8SFX7FyhvUFv+tgLf8CdoN/BiEQlU9XsLksPav+c+VU0DaRH5BXAesBABrZb8vQn4mLqbLLtEZDdwBnDnAuSvFot9ntRkEc+TWi32udKQrMqxNrX0C3kzcKVvxXUxMKyqBxspjyKyHvgO8IYFKlHMKn+quklVN6rqRuAm4K8W+ASt5Xv+PvBsEYmISAp4BvBwA+VvL670iIisBLYAjy9Q/mqx2OfJcS3yeVKTBjhXGpKV0Gqg0/QLKSJv8eM/h2tp9GJgF5DB/VJutDy+H+gCPuN/2QW6QD1315i/RVVLHlX1YRH5MXAfUAb+Q1VnbFq9kPkDPgxcJyL346r33qOqC/a6ERH5OvBcoFtE9gPXANGq/C3qeVJjHhftPJlFHs0UrOsrY4wxS4JVORpjjFkSLKAZY4xZEiygGWOMWRIsoBljjFkSLKAZY8wyVWsnyFXTv1pEHvIdX3+t3vmbLQto5qQhImOzmPaNIrJmhvEREekTkf85P7k7cSJytYj83v/dKSJ175lCRD4gIn/rh6+bqrd2/6zYP4jIoyLyiIj83D9wfKLrfKOIfNoPv6XSbdjxvitTV9cBl9UyoYhsBt4HPEtVzwbeWb9snRgLaGapeiMw00XyEmAn8GqZpu8gEQnXIV+T1/FS4M3AH6rqGcBbgK+JyKp5WPZc8/82XM/z56nq6cBHgf8Ukaa55s0/03eD//hGZv6uTJ1M1QmyiDxFRH7s+yr9pYic4Uf9JfBvlY6bF7hj7ppYQDMnNRE5X0RuF/fuqu+KSIcvbWwFviruvWXJKWZ9LfCvuJ41Lq5a3h4Reb+I/Ap4lYhcIiK3ichvReRbItLsp3u/iNwlIg+IyLVTBUUR+X5VKeTNIvLVKfLxHuDvKg8/q+pvgeuBt4nIi0TkxqrlPVdE/tMPT5evyfn/S5/P34nIt33vJrV6D/B2Vc34vP0X8AvgdX5d4yVmEXmliFznh18mIneIyD0i8lNxPZZM3jcfEJG/neK7eomIfLdquheKyHdmkWczd9fivvcLgb8FPuPTTwdOF5Ff+3OuppLdQrKAZk52N+B6wzgX17v8Nap6E7ADeJ2qnq+q2eoZfIB7PvAD4Ou44FYtp6p/CPwU+AfgBar6NL/Md/lpPq2qT1fVc3CdFL90irxdDbxfRJ4N/A3udR+TnQ3cPSlth0/fDlxcVSJ6DfBNEemeIV/j+VfVb+BedfN0VT0P10XXVVPk4Rgi0go0qepjU+TtrOPM/ivgYlW9APeKm3dPN+Hk7wrXk8iZItLjJ3kT8KVa8mzmzv8w+gPgWyJyL/B5oPJ6nwiwGdeDyWuB/xCR9oXP5fSs6ytz0hKRNqBdVStvjb4e+FYNs74U+G9VzYjIt4F/FJH/W1VLfvw3/f+LcRfvX/sCWAy4zY/7YxF5N5ACOoEHgf+sXomqHhaR9wP/DfyJqh7v/Vbjm+Zm10BcN1svE5GbgJfggsNzZshXdf4BzhGRj+BeTNqM6zZrLmrp2n0dLvCu9nnbXevCVVVF5MvA60XkS8AzgYV8Rc9yFwKG/I+LyfYDt6tqEdgtIjtxAe6uBczfjKyEZpaj1wIvEJE9uNJRF/DHVePT/r8A230p73xVPUtVrxKRBK4a5pWq+lTg34HENOt6KtDP9PeIHsK9jqba03w6uOD0atzrYO5S1dHp8jVF/sHd9P9rn88PzpDPCfzrZtIicuoUedtRmawqvXq5/wdXgn0q7v5gTeus8iXg9bjv6VuqumAvKF3u/Pe+W0ReBeMNg87zo7+HP098LcHpNFbH1xbQzMlLVYeBQV+lB/AGoFJaGwVaJs/jq9L+EFhf1Vv52zi22hHc24qfJSKn+XlTInI6Ry/Qfb6K5pgWgn76i4AXARcAfysim6aY7J+Bj4tIl5/nfFwjicp9i5/hgshfcrTkNV2+ptICHBSRKP7e1yz8L+BTlXuQIvICXFXoTX78YRE5U0RCuJdNVrQBT/rhbTWsZ8J3paoHcK+U+QdcQDZ1Iq4T5NuALSKyX0Suwh0nV4nI73A1D5W3ov8E6BeRh3C1Dn/XaK/WsSpHczJJiet5vOJfcBfMz/nGDo9ztPf263x6Fnhm1X20PwVuVdV81XK+D/yziMSrV6aqvSLyRuDrVeP+QVUfEZF/x92z28MUVS5++n8H3qSqB0Tkb4AvisjztKpHcFW9Wdzbh38jIoq7uL++8koV/wLHH+CC3LaZ8sXU72T7R+AO4Amf32OC/Az+D66q8j4fEGPAOaqa8+Pfi7sPuQ94AFelCfAB3D2YJ3HBd6pAXu06jv2uvgr0qOpDM85p5kRVp/ohB1M05ffH7buYeL+2oVhv+8aY4/Il0e/iqj3/fgHW92ngHlX9Qr3XZZYOC2jGmIYiInfj7gO+cFJJ2pgZWUAzxhizJFijEGOMMUuCBTRjjDFLggU0Y4wxS4IFNGOMMUuCBTRjjDFLwv8PdHIgzTW7HHUAAAAASUVORK5CYII=\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["\n", "fig, ax = plt.subplots()\n", "ax.scatter(X_train[\"LotArea\"]*X_train[\"OverallQual\"], y_train, alpha=0.2)\n", "ax.set_xlabel(\"Lot Area x Overall Quality\")\n", "ax.set_ylabel(\"Sale Price\")\n", "ax.set_title(\"(Lot Area x Overall Quality) vs. Sale Price for Ames Housing Data\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["While we could manually add individual interaction terms, there is a preprocessor from scikit-learn called `PolynomialFeatures` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)) that will generate all combinations of interaction terms (as well as polynomial terms, e.g. `Lot Area` squared) for a set of columns.\n", "\n", "Specifically, let's generate interaction terms for `LotFrontage`, `LotArea`, `OverallQual`, `YearBuilt`, and `GrLivArea`.\n", "\n", "To use `PolynomialFeatures`, we'll follow the same steps as `OneHotEncoder` (creating a new dataframe before merging), because it is another transformer that creates additional columns."]}, {"cell_type": "code", "execution_count": 46, "metadata": {}, "outputs": [{"data": {"text/plain": ["['LotFrontage',\n", " 'LotArea',\n", " 'OverallQual',\n", " 'YearBuilt',\n", " 'GrLivArea',\n", " 'LotFrontage LotArea',\n", " 'LotFrontage OverallQual',\n", " 'LotFrontage YearBuilt',\n", " 'LotFrontage GrLivArea',\n", " 'LotArea OverallQual',\n", " 'LotArea YearBuilt',\n", " 'LotArea GrLivArea',\n", " 'OverallQual YearBuilt',\n", " 'OverallQual GrLivArea',\n", " 'YearBuilt GrLivArea']"]}, "execution_count": 46, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (0) import PolynomialFeatures from sklearn.preprocessing\n", "from sklearn.preprocessing import PolynomialFeatures\n", "\n", "# (1) Create a variable poly_columns\n", "# extracted from X_train\n", "poly_column_names = [\n", "    \"LotFrontage\",\n", "    \"LotArea\",\n", "    \"OverallQual\",\n", "    \"YearBuilt\",\n", "    \"GrLivArea\"\n", "]\n", "poly_columns_train = X_train[poly_column_names]\n", "\n", "# (2) Instantiate a PolynomialFeatures transformer\n", "# with interaction_only=True and include_bias=False\n", "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n", "\n", "# (3) Fit the transformer on poly_columns\n", "poly.fit(poly_columns_train)\n", "\n", "# Inspect the features created by the fitted transformer\n", "poly.get_feature_names(poly_column_names)"]}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[4.300000e+01, 3.182000e+03, 7.000000e+00, ..., 1.403500e+04,\n", "        1.052800e+04, 3.015520e+06],\n", "       [7.800000e+01, 1.014000e+04, 6.000000e+00, ..., 1.184400e+04,\n", "        7.854000e+03, 2.583966e+06],\n", "       [6.000000e+01, 9.060000e+03, 6.000000e+00, ..., 1.163400e+04,\n", "        7.548000e+03, 2.439262e+06],\n", "       ...,\n", "       [6.000000e+01, 8.172000e+03, 5.000000e+00, ..., 9.775000e+03,\n", "        4.320000e+03, 1.689120e+06],\n", "       [5.500000e+01, 7.642000e+03, 7.000000e+00, ..., 1.342600e+04,\n", "        9.982000e+03, 2.735068e+06],\n", "       [5.300000e+01, 3.684000e+03, 7.000000e+00, ..., 1.404900e+04,\n", "        1.088500e+04, 3.120885e+06]])"]}, "execution_count": 47, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (4) Transform poly_columns using the transformer and\n", "# assign the result poly_columns_expanded_train\n", "poly_columns_expanded_train = poly.transform(poly_columns_train)\n", "\n", "# Visually inspect poly_columns_expanded_train\n", "poly_columns_expanded_train"]}, {"cell_type": "code", "execution_count": 48, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>OverallQual</th>\n", "      <th>YearBuilt</th>\n", "      <th>GrLivArea</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>43.0</td>\n", "      <td>3182.0</td>\n", "      <td>7.0</td>\n", "      <td>2005.0</td>\n", "      <td>1504.0</td>\n", "      <td>136826.0</td>\n", "      <td>301.0</td>\n", "      <td>86215.0</td>\n", "      <td>64672.0</td>\n", "      <td>22274.0</td>\n", "      <td>6379910.0</td>\n", "      <td>4785728.0</td>\n", "      <td>14035.0</td>\n", "      <td>10528.0</td>\n", "      <td>3015520.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>78.0</td>\n", "      <td>10140.0</td>\n", "      <td>6.0</td>\n", "      <td>1974.0</td>\n", "      <td>1309.0</td>\n", "      <td>790920.0</td>\n", "      <td>468.0</td>\n", "      <td>153972.0</td>\n", "      <td>102102.0</td>\n", "      <td>60840.0</td>\n", "      <td>20016360.0</td>\n", "      <td>13273260.0</td>\n", "      <td>11844.0</td>\n", "      <td>7854.0</td>\n", "      <td>2583966.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>60.0</td>\n", "      <td>9060.0</td>\n", "      <td>6.0</td>\n", "      <td>1939.0</td>\n", "      <td>1258.0</td>\n", "      <td>543600.0</td>\n", "      <td>360.0</td>\n", "      <td>116340.0</td>\n", "      <td>75480.0</td>\n", "      <td>54360.0</td>\n", "      <td>17567340.0</td>\n", "      <td>11397480.0</td>\n", "      <td>11634.0</td>\n", "      <td>7548.0</td>\n", "      <td>2439262.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>70.0</td>\n", "      <td>12342.0</td>\n", "      <td>5.0</td>\n", "      <td>1960.0</td>\n", "      <td>1422.0</td>\n", "      <td>863940.0</td>\n", "      <td>350.0</td>\n", "      <td>137200.0</td>\n", "      <td>99540.0</td>\n", "      <td>61710.0</td>\n", "      <td>24190320.0</td>\n", "      <td>17550324.0</td>\n", "      <td>9800.0</td>\n", "      <td>7110.0</td>\n", "      <td>2787120.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>75.0</td>\n", "      <td>9750.0</td>\n", "      <td>6.0</td>\n", "      <td>1958.0</td>\n", "      <td>1442.0</td>\n", "      <td>731250.0</td>\n", "      <td>450.0</td>\n", "      <td>146850.0</td>\n", "      <td>108150.0</td>\n", "      <td>58500.0</td>\n", "      <td>19090500.0</td>\n", "      <td>14059500.0</td>\n", "      <td>11748.0</td>\n", "      <td>8652.0</td>\n", "      <td>2823436.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>78.0</td>\n", "      <td>9317.0</td>\n", "      <td>6.0</td>\n", "      <td>2006.0</td>\n", "      <td>1314.0</td>\n", "      <td>726726.0</td>\n", "      <td>468.0</td>\n", "      <td>156468.0</td>\n", "      <td>102492.0</td>\n", "      <td>55902.0</td>\n", "      <td>18689902.0</td>\n", "      <td>12242538.0</td>\n", "      <td>12036.0</td>\n", "      <td>7884.0</td>\n", "      <td>2635884.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>65.0</td>\n", "      <td>7804.0</td>\n", "      <td>4.0</td>\n", "      <td>1928.0</td>\n", "      <td>1981.0</td>\n", "      <td>507260.0</td>\n", "      <td>260.0</td>\n", "      <td>125320.0</td>\n", "      <td>128765.0</td>\n", "      <td>31216.0</td>\n", "      <td>15046112.0</td>\n", "      <td>15459724.0</td>\n", "      <td>7712.0</td>\n", "      <td>7924.0</td>\n", "      <td>3819368.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>60.0</td>\n", "      <td>8172.0</td>\n", "      <td>5.0</td>\n", "      <td>1955.0</td>\n", "      <td>864.0</td>\n", "      <td>490320.0</td>\n", "      <td>300.0</td>\n", "      <td>117300.0</td>\n", "      <td>51840.0</td>\n", "      <td>40860.0</td>\n", "      <td>15976260.0</td>\n", "      <td>7060608.0</td>\n", "      <td>9775.0</td>\n", "      <td>4320.0</td>\n", "      <td>1689120.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>55.0</td>\n", "      <td>7642.0</td>\n", "      <td>7.0</td>\n", "      <td>1918.0</td>\n", "      <td>1426.0</td>\n", "      <td>420310.0</td>\n", "      <td>385.0</td>\n", "      <td>105490.0</td>\n", "      <td>78430.0</td>\n", "      <td>53494.0</td>\n", "      <td>14657356.0</td>\n", "      <td>10897492.0</td>\n", "      <td>13426.0</td>\n", "      <td>9982.0</td>\n", "      <td>2735068.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>53.0</td>\n", "      <td>3684.0</td>\n", "      <td>7.0</td>\n", "      <td>2007.0</td>\n", "      <td>1555.0</td>\n", "      <td>195252.0</td>\n", "      <td>371.0</td>\n", "      <td>106371.0</td>\n", "      <td>82415.0</td>\n", "      <td>25788.0</td>\n", "      <td>7393788.0</td>\n", "      <td>5728620.0</td>\n", "      <td>14049.0</td>\n", "      <td>10885.0</td>\n", "      <td>3120885.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 15 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea  OverallQual  YearBuilt  GrLivArea  \\\n", "1023         43.0   3182.0          7.0     2005.0     1504.0   \n", "810          78.0  10140.0          6.0     1974.0     1309.0   \n", "1384         60.0   9060.0          6.0     1939.0     1258.0   \n", "626          70.0  12342.0          5.0     1960.0     1422.0   \n", "813          75.0   9750.0          6.0     1958.0     1442.0   \n", "...           ...      ...          ...        ...        ...   \n", "1095         78.0   9317.0          6.0     2006.0     1314.0   \n", "1130         65.0   7804.0          4.0     1928.0     1981.0   \n", "1294         60.0   8172.0          5.0     1955.0      864.0   \n", "860          55.0   7642.0          7.0     1918.0     1426.0   \n", "1126         53.0   3684.0          7.0     2007.0     1555.0   \n", "\n", "      LotFrontage LotArea  LotFrontage OverallQual  LotFrontage YearBuilt  \\\n", "1023             136826.0                    301.0                86215.0   \n", "810              790920.0                    468.0               153972.0   \n", "1384             543600.0                    360.0               116340.0   \n", "626              863940.0                    350.0               137200.0   \n", "813              731250.0                    450.0               146850.0   \n", "...                   ...                      ...                    ...   \n", "1095             726726.0                    468.0               156468.0   \n", "1130             507260.0                    260.0               125320.0   \n", "1294             490320.0                    300.0               117300.0   \n", "860              420310.0                    385.0               105490.0   \n", "1126             195252.0                    371.0               106371.0   \n", "\n", "      LotFrontage GrLivArea  LotArea OverallQual  LotArea YearBuilt  \\\n", "1023                64672.0              22274.0          6379910.0   \n", "810                102102.0              60840.0         20016360.0   \n", "1384                75480.0              54360.0         17567340.0   \n", "626                 99540.0              61710.0         24190320.0   \n", "813                108150.0              58500.0         19090500.0   \n", "...                     ...                  ...                ...   \n", "1095               102492.0              55902.0         18689902.0   \n", "1130               128765.0              31216.0         15046112.0   \n", "1294                51840.0              40860.0         15976260.0   \n", "860                 78430.0              53494.0         14657356.0   \n", "1126                82415.0              25788.0          7393788.0   \n", "\n", "      LotArea GrLivArea  OverallQual YearBuilt  OverallQual GrLivArea  \\\n", "1023          4785728.0                14035.0                10528.0   \n", "810          13273260.0                11844.0                 7854.0   \n", "1384         11397480.0                11634.0                 7548.0   \n", "626          17550324.0                 9800.0                 7110.0   \n", "813          14059500.0                11748.0                 8652.0   \n", "...                 ...                    ...                    ...   \n", "1095         12242538.0                12036.0                 7884.0   \n", "1130         15459724.0                 7712.0                 7924.0   \n", "1294          7060608.0                 9775.0                 4320.0   \n", "860          10897492.0                13426.0                 9982.0   \n", "1126          5728620.0                14049.0                10885.0   \n", "\n", "      YearBuilt GrLivArea  \n", "1023            3015520.0  \n", "810             2583966.0  \n", "1384            2439262.0  \n", "626             2787120.0  \n", "813             2823436.0  \n", "...                   ...  \n", "1095            2635884.0  \n", "1130            3819368.0  \n", "1294            1689120.0  \n", "860             2735068.0  \n", "1126            3120885.0  \n", "\n", "[1095 rows x 15 columns]"]}, "execution_count": 48, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5a) Make the transformed data into a dataframe\n", "poly_columns_expanded_train = pd.DataFrame(\n", "    # Pass in NumPy array created in previous step\n", "    poly_columns_expanded_train,\n", "    # Set the column names to the features created by poly\n", "    columns=poly.get_feature_names(poly_column_names),\n", "    # Set the index to match X_train's index\n", "    index=X_train.index\n", ")\n", "\n", "# Visually inspect new dataframe\n", "poly_columns_expanded_train"]}, {"cell_type": "code", "execution_count": 49, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Street</th>\n", "      <th>OverallCond</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>...</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>136826.0</td>\n", "      <td>301.0</td>\n", "      <td>86215.0</td>\n", "      <td>64672.0</td>\n", "      <td>22274.0</td>\n", "      <td>6379910.0</td>\n", "      <td>4785728.0</td>\n", "      <td>14035.0</td>\n", "      <td>10528.0</td>\n", "      <td>3015520.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>1999</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>790920.0</td>\n", "      <td>468.0</td>\n", "      <td>153972.0</td>\n", "      <td>102102.0</td>\n", "      <td>60840.0</td>\n", "      <td>20016360.0</td>\n", "      <td>13273260.0</td>\n", "      <td>11844.0</td>\n", "      <td>7854.0</td>\n", "      <td>2583966.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>1950</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>10</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>543600.0</td>\n", "      <td>360.0</td>\n", "      <td>116340.0</td>\n", "      <td>75480.0</td>\n", "      <td>54360.0</td>\n", "      <td>17567340.0</td>\n", "      <td>11397480.0</td>\n", "      <td>11634.0</td>\n", "      <td>7548.0</td>\n", "      <td>2439262.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>1978</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "      <td>...</td>\n", "      <td>863940.0</td>\n", "      <td>350.0</td>\n", "      <td>137200.0</td>\n", "      <td>99540.0</td>\n", "      <td>61710.0</td>\n", "      <td>24190320.0</td>\n", "      <td>17550324.0</td>\n", "      <td>9800.0</td>\n", "      <td>7110.0</td>\n", "      <td>2787120.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>1958</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>731250.0</td>\n", "      <td>450.0</td>\n", "      <td>146850.0</td>\n", "      <td>108150.0</td>\n", "      <td>58500.0</td>\n", "      <td>19090500.0</td>\n", "      <td>14059500.0</td>\n", "      <td>11748.0</td>\n", "      <td>8652.0</td>\n", "      <td>2823436.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2006</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>726726.0</td>\n", "      <td>468.0</td>\n", "      <td>156468.0</td>\n", "      <td>102492.0</td>\n", "      <td>55902.0</td>\n", "      <td>18689902.0</td>\n", "      <td>12242538.0</td>\n", "      <td>12036.0</td>\n", "      <td>7884.0</td>\n", "      <td>2635884.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>1950</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>12</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>507260.0</td>\n", "      <td>260.0</td>\n", "      <td>125320.0</td>\n", "      <td>128765.0</td>\n", "      <td>31216.0</td>\n", "      <td>15046112.0</td>\n", "      <td>15459724.0</td>\n", "      <td>7712.0</td>\n", "      <td>7924.0</td>\n", "      <td>3819368.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>1990</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>490320.0</td>\n", "      <td>300.0</td>\n", "      <td>117300.0</td>\n", "      <td>51840.0</td>\n", "      <td>40860.0</td>\n", "      <td>15976260.0</td>\n", "      <td>7060608.0</td>\n", "      <td>9775.0</td>\n", "      <td>4320.0</td>\n", "      <td>1689120.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>1998</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>420310.0</td>\n", "      <td>385.0</td>\n", "      <td>105490.0</td>\n", "      <td>78430.0</td>\n", "      <td>53494.0</td>\n", "      <td>14657356.0</td>\n", "      <td>10897492.0</td>\n", "      <td>13426.0</td>\n", "      <td>9982.0</td>\n", "      <td>2735068.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>195252.0</td>\n", "      <td>371.0</td>\n", "      <td>106371.0</td>\n", "      <td>82415.0</td>\n", "      <td>25788.0</td>\n", "      <td>7393788.0</td>\n", "      <td>5728620.0</td>\n", "      <td>14049.0</td>\n", "      <td>10885.0</td>\n", "      <td>3120885.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 31 columns</p>\n", "</div>"], "text/plain": ["      Street  OverallCond  YearRemodAdd  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "1023       1            5          2006         2             2             7   \n", "810        1            6          1999         1             3             5   \n", "1384       1            5          1950         1             2             6   \n", "626        1            5          1978         1             3             6   \n", "813        1            6          1958         1             4             7   \n", "...      ...          ...           ...       ...           ...           ...   \n", "1095       1            5          2006         2             3             6   \n", "1130       1            3          1950         2             4             7   \n", "1294       1            7          1990         1             2             5   \n", "860        1            8          1998         1             3             7   \n", "1126       1            5          2007         2             2             7   \n", "\n", "      Fireplaces  MoSold  YrSold  LotFrontage_Missing  ...  \\\n", "1023           1       5    2008                    0  ...   \n", "810            1       1    2006                    0  ...   \n", "1384           0      10    2009                    0  ...   \n", "626            1       8    2007                    1  ...   \n", "813            0       4    2007                    0  ...   \n", "...          ...     ...     ...                  ...  ...   \n", "1095           1       3    2007                    0  ...   \n", "1130           2      12    2009                    0  ...   \n", "1294           0       4    2006                    0  ...   \n", "860            1       6    2007                    0  ...   \n", "1126           1       6    2009                    0  ...   \n", "\n", "      LotFrontage LotArea  LotFrontage OverallQual  LotFrontage YearBuilt  \\\n", "1023             136826.0                    301.0                86215.0   \n", "810              790920.0                    468.0               153972.0   \n", "1384             543600.0                    360.0               116340.0   \n", "626              863940.0                    350.0               137200.0   \n", "813              731250.0                    450.0               146850.0   \n", "...                   ...                      ...                    ...   \n", "1095             726726.0                    468.0               156468.0   \n", "1130             507260.0                    260.0               125320.0   \n", "1294             490320.0                    300.0               117300.0   \n", "860              420310.0                    385.0               105490.0   \n", "1126             195252.0                    371.0               106371.0   \n", "\n", "      LotFrontage GrLivArea  LotArea OverallQual  LotArea YearBuilt  \\\n", "1023                64672.0              22274.0          6379910.0   \n", "810                102102.0              60840.0         20016360.0   \n", "1384                75480.0              54360.0         17567340.0   \n", "626                 99540.0              61710.0         24190320.0   \n", "813                108150.0              58500.0         19090500.0   \n", "...                     ...                  ...                ...   \n", "1095               102492.0              55902.0         18689902.0   \n", "1130               128765.0              31216.0         15046112.0   \n", "1294                51840.0              40860.0         15976260.0   \n", "860                 78430.0              53494.0         14657356.0   \n", "1126                82415.0              25788.0          7393788.0   \n", "\n", "      LotArea GrLivArea  OverallQual YearBuilt  OverallQual GrLivArea  \\\n", "1023          4785728.0                14035.0                10528.0   \n", "810          13273260.0                11844.0                 7854.0   \n", "1384         11397480.0                11634.0                 7548.0   \n", "626          17550324.0                 9800.0                 7110.0   \n", "813          14059500.0                11748.0                 8652.0   \n", "...                 ...                    ...                    ...   \n", "1095         12242538.0                12036.0                 7884.0   \n", "1130         15459724.0                 7712.0                 7924.0   \n", "1294          7060608.0                 9775.0                 4320.0   \n", "860          10897492.0                13426.0                 9982.0   \n", "1126          5728620.0                14049.0                10885.0   \n", "\n", "      YearBuilt GrLivArea  \n", "1023            3015520.0  \n", "810             2583966.0  \n", "1384            2439262.0  \n", "626             2787120.0  \n", "813             2823436.0  \n", "...                   ...  \n", "1095            2635884.0  \n", "1130            3819368.0  \n", "1294            1689120.0  \n", "860             2735068.0  \n", "1126            3120885.0  \n", "\n", "[1095 rows x 31 columns]"]}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5b) Drop original columns\n", "X_train.drop(poly_column_names, axis=1, inplace=True)\n", "\n", "# (5c) Concatenate the new dataframe with current X_train\n", "X_train = pd.concat([X_train, poly_columns_expanded_train], axis=1)\n", "\n", "# Visually inspect X_train\n", "X_train"]}, {"cell_type": "code", "execution_count": 50, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "Int64Index: 1095 entries, 1023 to 1126\n", "Data columns (total 31 columns):\n", " #   Column                   Non-Null Count  Dtype  \n", "---  ------                   --------------  -----  \n", " 0   Street                   1095 non-null   int64  \n", " 1   OverallCond              1095 non-null   int64  \n", " 2   YearRemodAdd             1095 non-null   int64  \n", " 3   FullBath                 1095 non-null   int64  \n", " 4   BedroomAbvGr             1095 non-null   int64  \n", " 5   TotRmsAbvGrd             1095 non-null   int64  \n", " 6   Fireplaces               1095 non-null   int64  \n", " 7   MoSold                   1095 non-null   int64  \n", " 8   YrSold                   1095 non-null   int64  \n", " 9   LotFrontage_Missing      1095 non-null   int64  \n", " 10  Ex                       1095 non-null   float64\n", " 11  Fa                       1095 non-null   float64\n", " 12  Gd                       1095 non-null   float64\n", " 13  N/A                      1095 non-null   float64\n", " 14  Po                       1095 non-null   float64\n", " 15  TA                       1095 non-null   float64\n", " 16  LotFrontage              1095 non-null   float64\n", " 17  LotArea                  1095 non-null   float64\n", " 18  OverallQual              1095 non-null   float64\n", " 19  YearBuilt                1095 non-null   float64\n", " 20  GrLivArea                1095 non-null   float64\n", " 21  LotFrontage LotArea      1095 non-null   float64\n", " 22  LotFrontage OverallQual  1095 non-null   float64\n", " 23  LotFrontage YearBuilt    1095 non-null   float64\n", " 24  LotFrontage GrLivArea    1095 non-null   float64\n", " 25  LotArea OverallQual      1095 non-null   float64\n", " 26  LotArea YearBuilt        1095 non-null   float64\n", " 27  LotArea GrLivArea        1095 non-null   float64\n", " 28  OverallQual YearBuilt    1095 non-null   float64\n", " 29  OverallQual GrLivArea    1095 non-null   float64\n", " 30  YearBuilt GrLivArea      1095 non-null   float64\n", "dtypes: float64(21), int64(10)\n", "memory usage: 273.8 KB\n"]}], "source": ["X_train.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, now we have 31 features instead of 21 features! Let's see how the model performs now:"]}, {"cell_type": "code", "execution_count": 51, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298739023179.6966, tolerance: 422550782.65263027\n", "  model = cd_fast.enet_coordinate_descent(\n", "//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 357401730994.73425, tolerance: 434287718.1245009\n", "  model = cd_fast.enet_coordinate_descent(\n", "//anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 402015942401.8634, tolerance: 471766118.83873975\n", "  model = cd_fast.enet_coordinate_descent(\n"]}, {"data": {"text/plain": ["array([0.75336526, 0.79206309, 0.75227628])"]}, "execution_count": 51, "metadata": {}, "output_type": "execute_result"}], "source": ["cross_val_score(model, X_train, y_train, cv=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hmm, got some metrics, so it didn't totally crash, but what is that warning message?\n", "\n", "A `ConvergenceWarning` means that the **gradient descent** algorithm within the `ElasticNet` model failed to find a minimum based on the specified parameters. While the warning message suggests modifyig the parameters (number of iterations), your first thought when you see a model fail to converge should be **do I need to scale the data**?\n", "\n", "Scaling data is especially important when there are substantial differences in the units of different features. Let's take a look at the values in our current `X_train`:"]}, {"cell_type": "code", "execution_count": 52, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Street</th>\n", "      <th>OverallCond</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>...</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>count</th>\n", "      <td>1095.000000</td>\n", "      <td>1095.00000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>...</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1095.000000</td>\n", "      <td>1095.000000</td>\n", "      <td>1.095000e+03</td>\n", "    </tr>\n", "    <tr>\n", "      <th>mean</th>\n", "      <td>0.996347</td>\n", "      <td>5.56895</td>\n", "      <td>1984.854795</td>\n", "      <td>1.578995</td>\n", "      <td>2.896804</td>\n", "      <td>6.564384</td>\n", "      <td>0.619178</td>\n", "      <td>6.361644</td>\n", "      <td>2007.818265</td>\n", "      <td>0.182648</td>\n", "      <td>...</td>\n", "      <td>8.308276e+05</td>\n", "      <td>438.181735</td>\n", "      <td>138690.935160</td>\n", "      <td>1.119997e+05</td>\n", "      <td>6.737676e+04</td>\n", "      <td>2.118694e+07</td>\n", "      <td>1.800923e+07</td>\n", "      <td>12105.757078</td>\n", "      <td>9805.720548</td>\n", "      <td>3.020889e+06</td>\n", "    </tr>\n", "    <tr>\n", "      <th>std</th>\n", "      <td>0.060357</td>\n", "      <td>1.10448</td>\n", "      <td>20.732472</td>\n", "      <td>0.544976</td>\n", "      <td>0.806361</td>\n", "      <td>1.625103</td>\n", "      <td>0.644338</td>\n", "      <td>2.680894</td>\n", "      <td>1.325752</td>\n", "      <td>0.386555</td>\n", "      <td>...</td>\n", "      <td>1.350715e+06</td>\n", "      <td>207.779337</td>\n", "      <td>45385.148925</td>\n", "      <td>7.993630e+04</td>\n", "      <td>7.490171e+04</td>\n", "      <td>2.176917e+07</td>\n", "      <td>2.596924e+07</td>\n", "      <td>2806.986068</td>\n", "      <td>5199.725503</td>\n", "      <td>1.047711e+06</td>\n", "    </tr>\n", "    <tr>\n", "      <th>min</th>\n", "      <td>0.000000</td>\n", "      <td>1.00000</td>\n", "      <td>1950.000000</td>\n", "      <td>0.000000</td>\n", "      <td>0.000000</td>\n", "      <td>2.000000</td>\n", "      <td>0.000000</td>\n", "      <td>1.000000</td>\n", "      <td>2006.000000</td>\n", "      <td>0.000000</td>\n", "      <td>...</td>\n", "      <td>3.101700e+04</td>\n", "      <td>50.000000</td>\n", "      <td>41370.000000</td>\n", "      <td>1.323000e+04</td>\n", "      <td>5.000000e+03</td>\n", "      <td>2.574000e+06</td>\n", "      <td>9.305100e+05</td>\n", "      <td>1922.000000</td>\n", "      <td>334.000000</td>\n", "      <td>6.499640e+05</td>\n", "    </tr>\n", "    <tr>\n", "      <th>25%</th>\n", "      <td>1.000000</td>\n", "      <td>5.00000</td>\n", "      <td>1966.000000</td>\n", "      <td>1.000000</td>\n", "      <td>2.000000</td>\n", "      <td>5.000000</td>\n", "      <td>0.000000</td>\n", "      <td>5.000000</td>\n", "      <td>2007.000000</td>\n", "      <td>0.000000</td>\n", "      <td>...</td>\n", "      <td>4.756920e+05</td>\n", "      <td>312.000000</td>\n", "      <td>116400.000000</td>\n", "      <td>7.078750e+04</td>\n", "      <td>4.034000e+04</td>\n", "      <td>1.494741e+07</td>\n", "      <td>8.749200e+06</td>\n", "      <td>9810.000000</td>\n", "      <td>5945.000000</td>\n", "      <td>2.259095e+06</td>\n", "    </tr>\n", "    <tr>\n", "      <th>50%</th>\n", "      <td>1.000000</td>\n", "      <td>5.00000</td>\n", "      <td>1994.000000</td>\n", "      <td>2.000000</td>\n", "      <td>3.000000</td>\n", "      <td>6.000000</td>\n", "      <td>1.000000</td>\n", "      <td>6.000000</td>\n", "      <td>2008.000000</td>\n", "      <td>0.000000</td>\n", "      <td>...</td>\n", "      <td>6.653500e+05</td>\n", "      <td>420.000000</td>\n", "      <td>137760.000000</td>\n", "      <td>1.001600e+05</td>\n", "      <td>5.670500e+04</td>\n", "      <td>1.877812e+07</td>\n", "      <td>1.368276e+07</td>\n", "      <td>11832.000000</td>\n", "      <td>8892.000000</td>\n", "      <td>2.918504e+06</td>\n", "    </tr>\n", "    <tr>\n", "      <th>75%</th>\n", "      <td>1.000000</td>\n", "      <td>6.00000</td>\n", "      <td>2004.000000</td>\n", "      <td>2.000000</td>\n", "      <td>3.000000</td>\n", "      <td>7.000000</td>\n", "      <td>1.000000</td>\n", "      <td>8.000000</td>\n", "      <td>2009.000000</td>\n", "      <td>0.000000</td>\n", "      <td>...</td>\n", "      <td>9.050150e+05</td>\n", "      <td>510.000000</td>\n", "      <td>156000.000000</td>\n", "      <td>1.360195e+05</td>\n", "      <td>7.761550e+04</td>\n", "      <td>2.302560e+07</td>\n", "      <td>2.041942e+07</td>\n", "      <td>14021.000000</td>\n", "      <td>12372.500000</td>\n", "      <td>3.543578e+06</td>\n", "    </tr>\n", "    <tr>\n", "      <th>max</th>\n", "      <td>1.000000</td>\n", "      <td>9.00000</td>\n", "      <td>2010.000000</td>\n", "      <td>3.000000</td>\n", "      <td>8.000000</td>\n", "      <td>14.000000</td>\n", "      <td>3.000000</td>\n", "      <td>12.000000</td>\n", "      <td>2010.000000</td>\n", "      <td>1.000000</td>\n", "      <td>...</td>\n", "      <td>3.228675e+07</td>\n", "      <td>3130.000000</td>\n", "      <td>628504.000000</td>\n", "      <td>1.765946e+06</td>\n", "      <td>1.506715e+06</td>\n", "      <td>4.229564e+08</td>\n", "      <td>4.382388e+08</td>\n", "      <td>20090.000000</td>\n", "      <td>56420.000000</td>\n", "      <td>1.132914e+07</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>8 rows \u00d7 31 columns</p>\n", "</div>"], "text/plain": ["            Street  OverallCond  YearRemodAdd     FullBath  BedroomAbvGr  \\\n", "count  1095.000000   1095.00000   1095.000000  1095.000000   1095.000000   \n", "mean      0.996347      5.56895   1984.854795     1.578995      2.896804   \n", "std       0.060357      1.10448     20.732472     0.544976      0.806361   \n", "min       0.000000      1.00000   1950.000000     0.000000      0.000000   \n", "25%       1.000000      5.00000   1966.000000     1.000000      2.000000   \n", "50%       1.000000      5.00000   1994.000000     2.000000      3.000000   \n", "75%       1.000000      6.00000   2004.000000     2.000000      3.000000   \n", "max       1.000000      9.00000   2010.000000     3.000000      8.000000   \n", "\n", "       TotRmsAbvGrd   Fireplaces       MoSold       YrSold  \\\n", "count   1095.000000  1095.000000  1095.000000  1095.000000   \n", "mean       6.564384     0.619178     6.361644  2007.818265   \n", "std        1.625103     0.644338     2.680894     1.325752   \n", "min        2.000000     0.000000     1.000000  2006.000000   \n", "25%        5.000000     0.000000     5.000000  2007.000000   \n", "50%        6.000000     1.000000     6.000000  2008.000000   \n", "75%        7.000000     1.000000     8.000000  2009.000000   \n", "max       14.000000     3.000000    12.000000  2010.000000   \n", "\n", "       LotFrontage_Missing  ...  LotFrontage LotArea  LotFrontage OverallQual  \\\n", "count          1095.000000  ...         1.095000e+03              1095.000000   \n", "mean              0.182648  ...         8.308276e+05               438.181735   \n", "std               0.386555  ...         1.350715e+06               207.779337   \n", "min               0.000000  ...         3.101700e+04                50.000000   \n", "25%               0.000000  ...         4.756920e+05               312.000000   \n", "50%               0.000000  ...         6.653500e+05               420.000000   \n", "75%               0.000000  ...         9.050150e+05               510.000000   \n", "max               1.000000  ...         3.228675e+07              3130.000000   \n", "\n", "       LotFrontage YearBuilt  LotFrontage GrLivArea  LotArea OverallQual  \\\n", "count            1095.000000           1.095000e+03         1.095000e+03   \n", "mean           138690.935160           1.119997e+05         6.737676e+04   \n", "std             45385.148925           7.993630e+04         7.490171e+04   \n", "min             41370.000000           1.323000e+04         5.000000e+03   \n", "25%            116400.000000           7.078750e+04         4.034000e+04   \n", "50%            137760.000000           1.001600e+05         5.670500e+04   \n", "75%            156000.000000           1.360195e+05         7.761550e+04   \n", "max            628504.000000           1.765946e+06         1.506715e+06   \n", "\n", "       LotArea YearBuilt  LotArea GrLivArea  OverallQual YearBuilt  \\\n", "count       1.095000e+03       1.095000e+03            1095.000000   \n", "mean        2.118694e+07       1.800923e+07           12105.757078   \n", "std         2.176917e+07       2.596924e+07            2806.986068   \n", "min         2.574000e+06       9.305100e+05            1922.000000   \n", "25%         1.494741e+07       8.749200e+06            9810.000000   \n", "50%         1.877812e+07       1.368276e+07           11832.000000   \n", "75%         2.302560e+07       2.041942e+07           14021.000000   \n", "max         4.229564e+08       4.382388e+08           20090.000000   \n", "\n", "       OverallQual GrLivArea  YearBuilt GrLivArea  \n", "count            1095.000000         1.095000e+03  \n", "mean             9805.720548         3.020889e+06  \n", "std              5199.725503         1.047711e+06  \n", "min               334.000000         6.499640e+05  \n", "25%              5945.000000         2.259095e+06  \n", "50%              8892.000000         2.918504e+06  \n", "75%             12372.500000         3.543578e+06  \n", "max             56420.000000         1.132914e+07  \n", "\n", "[8 rows x 31 columns]"]}, "execution_count": 52, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Looks like we have mean values ranging from about $0.6$ (for fireplaces) to $2.1 x 10^7$ (21 million, for `Lot Area x YearBuilt`). With the regularization applied by `ElasticNet`, the coefficients are being penalized very disproportionately!\n", "\n", "In the next step, we'll apply scaling to address this."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Scale Data\n", "\n", "This is the final scikit-learn preprocessing task of the lab! The `StandardScaler` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)) standarizes features by removing the mean and scaling to unit variance. This will help our data to meet the assumptions of the L1 and L2 regularizers in our `ElasticNet` model.\n", "\n", "Unlike previous preprocessing steps, we are going to apply the `StandardScaler` to the entire `X_train`, not just a single column or a subset of columns."]}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[ 0.06055048, -0.51536449,  1.02037363, ...,  0.68761455,\n", "         0.1389707 , -0.00512705],\n", "       [ 0.06055048,  0.39045271,  0.68258474, ..., -0.09329461,\n", "        -0.3755222 , -0.41721713],\n", "       [ 0.06055048, -0.51536449, -1.68193746, ..., -0.16814214,\n", "        -0.43439835, -0.55539469],\n", "       ...,\n", "       [ 0.06055048,  1.29626991,  0.24828475, ..., -0.83072093,\n", "        -1.05548402, -1.27170382],\n", "       [ 0.06055048,  2.20208711,  0.63432919, ...,  0.47055673,\n", "         0.03391718, -0.27293012],\n", "       [ 0.06055048, -0.51536449,  1.06862918, ...,  0.69260438,\n", "         0.20765954,  0.09548578]])"]}, "execution_count": 53, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (0) import StandardScaler from sklearn.preprocessing\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "# (1) We don't actually have to select anything since \n", "# we're using the full X_train\n", "\n", "# (2) Instantiate a StandardScaler\n", "scaler = StandardScaler()\n", "\n", "# (3) Fit the scaler on X_train\n", "scaler.fit(X_train)\n", "\n", "# (4) Transform X_train using the scaler and\n", "# assign the result to X_train_scaled\n", "X_train_scaled = scaler.transform(X_train)\n", "\n", "# Visually inspect X_train_scaled\n", "X_train_scaled"]}, {"cell_type": "code", "execution_count": 54, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Street</th>\n", "      <th>OverallCond</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>...</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>1023</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>1.020374</td>\n", "      <td>0.772872</td>\n", "      <td>-1.112669</td>\n", "      <td>0.268177</td>\n", "      <td>0.591298</td>\n", "      <td>-0.508139</td>\n", "      <td>0.137143</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.514038</td>\n", "      <td>-0.660530</td>\n", "      <td>-1.156764</td>\n", "      <td>-0.592338</td>\n", "      <td>-0.602434</td>\n", "      <td>-0.680494</td>\n", "      <td>-0.509431</td>\n", "      <td>0.687615</td>\n", "      <td>0.138971</td>\n", "      <td>-0.005127</td>\n", "    </tr>\n", "    <tr>\n", "      <th>810</th>\n", "      <td>0.06055</td>\n", "      <td>0.390453</td>\n", "      <td>0.682585</td>\n", "      <td>-1.062909</td>\n", "      <td>0.128036</td>\n", "      <td>-0.963076</td>\n", "      <td>0.591298</td>\n", "      <td>-2.000860</td>\n", "      <td>-1.372124</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.029559</td>\n", "      <td>0.143575</td>\n", "      <td>0.336851</td>\n", "      <td>-0.123876</td>\n", "      <td>-0.087311</td>\n", "      <td>-0.053797</td>\n", "      <td>-0.182452</td>\n", "      <td>-0.093295</td>\n", "      <td>-0.375522</td>\n", "      <td>-0.417217</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1384</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>-1.681937</td>\n", "      <td>-1.062909</td>\n", "      <td>-1.112669</td>\n", "      <td>-0.347450</td>\n", "      <td>-0.961392</td>\n", "      <td>1.357763</td>\n", "      <td>0.891777</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.212746</td>\n", "      <td>-0.376445</td>\n", "      <td>-0.492697</td>\n", "      <td>-0.457069</td>\n", "      <td>-0.173864</td>\n", "      <td>-0.166348</td>\n", "      <td>-0.254716</td>\n", "      <td>-0.168142</td>\n", "      <td>-0.434398</td>\n", "      <td>-0.555395</td>\n", "    </tr>\n", "    <tr>\n", "      <th>626</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>-0.330782</td>\n", "      <td>-1.062909</td>\n", "      <td>0.128036</td>\n", "      <td>-0.347450</td>\n", "      <td>0.591298</td>\n", "      <td>0.611402</td>\n", "      <td>-0.617490</td>\n", "      <td>2.115420</td>\n", "      <td>...</td>\n", "      <td>0.024526</td>\n", "      <td>-0.424595</td>\n", "      <td>-0.032866</td>\n", "      <td>-0.155942</td>\n", "      <td>-0.075691</td>\n", "      <td>0.138028</td>\n", "      <td>-0.017679</td>\n", "      <td>-0.821811</td>\n", "      <td>-0.518672</td>\n", "      <td>-0.223226</td>\n", "    </tr>\n", "    <tr>\n", "      <th>813</th>\n", "      <td>0.06055</td>\n", "      <td>0.390453</td>\n", "      <td>-1.295893</td>\n", "      <td>-1.062909</td>\n", "      <td>1.368742</td>\n", "      <td>0.268177</td>\n", "      <td>-0.961392</td>\n", "      <td>-0.881319</td>\n", "      <td>-0.617490</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.073756</td>\n", "      <td>0.056905</td>\n", "      <td>0.179856</td>\n", "      <td>-0.048182</td>\n", "      <td>-0.118566</td>\n", "      <td>-0.096347</td>\n", "      <td>-0.152162</td>\n", "      <td>-0.127511</td>\n", "      <td>-0.221982</td>\n", "      <td>-0.188548</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1095</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>1.020374</td>\n", "      <td>0.772872</td>\n", "      <td>0.128036</td>\n", "      <td>-0.347450</td>\n", "      <td>0.591298</td>\n", "      <td>-1.254499</td>\n", "      <td>-0.617490</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.077107</td>\n", "      <td>0.143575</td>\n", "      <td>0.391872</td>\n", "      <td>-0.118995</td>\n", "      <td>-0.153268</td>\n", "      <td>-0.114758</td>\n", "      <td>-0.222160</td>\n", "      <td>-0.024863</td>\n", "      <td>-0.369750</td>\n", "      <td>-0.367641</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1130</th>\n", "      <td>0.06055</td>\n", "      <td>-2.326999</td>\n", "      <td>-1.681937</td>\n", "      <td>0.772872</td>\n", "      <td>1.368742</td>\n", "      <td>0.268177</td>\n", "      <td>2.143989</td>\n", "      <td>2.104124</td>\n", "      <td>0.891777</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.239662</td>\n", "      <td>-0.857945</td>\n", "      <td>-0.294745</td>\n", "      <td>0.209829</td>\n", "      <td>-0.482997</td>\n", "      <td>-0.282217</td>\n", "      <td>-0.098219</td>\n", "      <td>-1.566009</td>\n", "      <td>-0.362054</td>\n", "      <td>0.762466</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1294</th>\n", "      <td>0.06055</td>\n", "      <td>1.296270</td>\n", "      <td>0.248285</td>\n", "      <td>-1.062909</td>\n", "      <td>-1.112669</td>\n", "      <td>-0.963076</td>\n", "      <td>-0.961392</td>\n", "      <td>-0.881319</td>\n", "      <td>-1.372124</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.252209</td>\n", "      <td>-0.665345</td>\n", "      <td>-0.471536</td>\n", "      <td>-0.752939</td>\n", "      <td>-0.354183</td>\n", "      <td>-0.239470</td>\n", "      <td>-0.421792</td>\n", "      <td>-0.830721</td>\n", "      <td>-1.055484</td>\n", "      <td>-1.271704</td>\n", "    </tr>\n", "    <tr>\n", "      <th>860</th>\n", "      <td>0.06055</td>\n", "      <td>2.202087</td>\n", "      <td>0.634329</td>\n", "      <td>-1.062909</td>\n", "      <td>0.128036</td>\n", "      <td>0.268177</td>\n", "      <td>0.591298</td>\n", "      <td>-0.134958</td>\n", "      <td>-0.617490</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.304065</td>\n", "      <td>-0.256070</td>\n", "      <td>-0.731872</td>\n", "      <td>-0.420148</td>\n", "      <td>-0.185431</td>\n", "      <td>-0.300083</td>\n", "      <td>-0.273978</td>\n", "      <td>0.470557</td>\n", "      <td>0.033917</td>\n", "      <td>-0.272930</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1126</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>1.068629</td>\n", "      <td>0.772872</td>\n", "      <td>-1.112669</td>\n", "      <td>0.268177</td>\n", "      <td>0.591298</td>\n", "      <td>-0.134958</td>\n", "      <td>0.891777</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.470762</td>\n", "      <td>-0.323480</td>\n", "      <td>-0.712451</td>\n", "      <td>-0.370273</td>\n", "      <td>-0.555498</td>\n", "      <td>-0.633899</td>\n", "      <td>-0.473107</td>\n", "      <td>0.692604</td>\n", "      <td>0.207660</td>\n", "      <td>0.095486</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>1095 rows \u00d7 31 columns</p>\n", "</div>"], "text/plain": ["       Street  OverallCond  YearRemodAdd  FullBath  BedroomAbvGr  \\\n", "1023  0.06055    -0.515364      1.020374  0.772872     -1.112669   \n", "810   0.06055     0.390453      0.682585 -1.062909      0.128036   \n", "1384  0.06055    -0.515364     -1.681937 -1.062909     -1.112669   \n", "626   0.06055    -0.515364     -0.330782 -1.062909      0.128036   \n", "813   0.06055     0.390453     -1.295893 -1.062909      1.368742   \n", "...       ...          ...           ...       ...           ...   \n", "1095  0.06055    -0.515364      1.020374  0.772872      0.128036   \n", "1130  0.06055    -2.326999     -1.681937  0.772872      1.368742   \n", "1294  0.06055     1.296270      0.248285 -1.062909     -1.112669   \n", "860   0.06055     2.202087      0.634329 -1.062909      0.128036   \n", "1126  0.06055    -0.515364      1.068629  0.772872     -1.112669   \n", "\n", "      TotRmsAbvGrd  Fireplaces    MoSold    YrSold  LotFrontage_Missing  ...  \\\n", "1023      0.268177    0.591298 -0.508139  0.137143            -0.472719  ...   \n", "810      -0.963076    0.591298 -2.000860 -1.372124            -0.472719  ...   \n", "1384     -0.347450   -0.961392  1.357763  0.891777            -0.472719  ...   \n", "626      -0.347450    0.591298  0.611402 -0.617490             2.115420  ...   \n", "813       0.268177   -0.961392 -0.881319 -0.617490            -0.472719  ...   \n", "...            ...         ...       ...       ...                  ...  ...   \n", "1095     -0.347450    0.591298 -1.254499 -0.617490            -0.472719  ...   \n", "1130      0.268177    2.143989  2.104124  0.891777            -0.472719  ...   \n", "1294     -0.963076   -0.961392 -0.881319 -1.372124            -0.472719  ...   \n", "860       0.268177    0.591298 -0.134958 -0.617490            -0.472719  ...   \n", "1126      0.268177    0.591298 -0.134958  0.891777            -0.472719  ...   \n", "\n", "      LotFrontage LotArea  LotFrontage OverallQual  LotFrontage YearBuilt  \\\n", "1023            -0.514038                -0.660530              -1.156764   \n", "810             -0.029559                 0.143575               0.336851   \n", "1384            -0.212746                -0.376445              -0.492697   \n", "626              0.024526                -0.424595              -0.032866   \n", "813             -0.073756                 0.056905               0.179856   \n", "...                   ...                      ...                    ...   \n", "1095            -0.077107                 0.143575               0.391872   \n", "1130            -0.239662                -0.857945              -0.294745   \n", "1294            -0.252209                -0.665345              -0.471536   \n", "860             -0.304065                -0.256070              -0.731872   \n", "1126            -0.470762                -0.323480              -0.712451   \n", "\n", "      LotFrontage GrLivArea  LotArea OverallQual  LotArea YearBuilt  \\\n", "1023              -0.592338            -0.602434          -0.680494   \n", "810               -0.123876            -0.087311          -0.053797   \n", "1384              -0.457069            -0.173864          -0.166348   \n", "626               -0.155942            -0.075691           0.138028   \n", "813               -0.048182            -0.118566          -0.096347   \n", "...                     ...                  ...                ...   \n", "1095              -0.118995            -0.153268          -0.114758   \n", "1130               0.209829            -0.482997          -0.282217   \n", "1294              -0.752939            -0.354183          -0.239470   \n", "860               -0.420148            -0.185431          -0.300083   \n", "1126              -0.370273            -0.555498          -0.633899   \n", "\n", "      LotArea GrLivArea  OverallQual YearBuilt  OverallQual GrLivArea  \\\n", "1023          -0.509431               0.687615               0.138971   \n", "810           -0.182452              -0.093295              -0.375522   \n", "1384          -0.254716              -0.168142              -0.434398   \n", "626           -0.017679              -0.821811              -0.518672   \n", "813           -0.152162              -0.127511              -0.221982   \n", "...                 ...                    ...                    ...   \n", "1095          -0.222160              -0.024863              -0.369750   \n", "1130          -0.098219              -1.566009              -0.362054   \n", "1294          -0.421792              -0.830721              -1.055484   \n", "860           -0.273978               0.470557               0.033917   \n", "1126          -0.473107               0.692604               0.207660   \n", "\n", "      YearBuilt GrLivArea  \n", "1023            -0.005127  \n", "810             -0.417217  \n", "1384            -0.555395  \n", "626             -0.223226  \n", "813             -0.188548  \n", "...                   ...  \n", "1095            -0.367641  \n", "1130             0.762466  \n", "1294            -1.271704  \n", "860             -0.272930  \n", "1126             0.095486  \n", "\n", "[1095 rows x 31 columns]"]}, "execution_count": 54, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (5) Make the transformed data back into a dataframe\n", "X_train = pd.DataFrame(\n", "    # Pass in NumPy array\n", "    X_train_scaled,\n", "    # Set the column names to the original names\n", "    columns=X_train.columns,\n", "    # Set the index to match X_train's original index\n", "    index=X_train.index\n", ")\n", "\n", "# Visually inspect new dataframe\n", "X_train"]}, {"cell_type": "code", "execution_count": 55, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Street</th>\n", "      <th>OverallCond</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>...</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>count</th>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>...</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "      <td>1.095000e+03</td>\n", "    </tr>\n", "    <tr>\n", "      <th>mean</th>\n", "      <td>3.617603e-16</td>\n", "      <td>-2.984928e-16</td>\n", "      <td>-3.202309e-15</td>\n", "      <td>-6.488975e-18</td>\n", "      <td>2.530700e-16</td>\n", "      <td>-6.813423e-17</td>\n", "      <td>-1.946692e-17</td>\n", "      <td>7.624545e-17</td>\n", "      <td>6.328535e-14</td>\n", "      <td>9.084565e-17</td>\n", "      <td>...</td>\n", "      <td>2.757814e-17</td>\n", "      <td>-1.492464e-16</td>\n", "      <td>2.984928e-16</td>\n", "      <td>-5.191180e-17</td>\n", "      <td>-4.380058e-17</td>\n", "      <td>8.111218e-18</td>\n", "      <td>6.326750e-17</td>\n", "      <td>2.271141e-17</td>\n", "      <td>-8.435667e-17</td>\n", "      <td>-1.460019e-16</td>\n", "    </tr>\n", "    <tr>\n", "      <th>std</th>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>...</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "      <td>1.000457e+00</td>\n", "    </tr>\n", "    <tr>\n", "      <th>min</th>\n", "      <td>-1.651514e+01</td>\n", "      <td>-4.138633e+00</td>\n", "      <td>-1.681937e+00</td>\n", "      <td>-2.898690e+00</td>\n", "      <td>-3.594081e+00</td>\n", "      <td>-2.809956e+00</td>\n", "      <td>-9.613917e-01</td>\n", "      <td>-2.000860e+00</td>\n", "      <td>-1.372124e+00</td>\n", "      <td>-4.727195e-01</td>\n", "      <td>...</td>\n", "      <td>-5.924092e-01</td>\n", "      <td>-1.869094e+00</td>\n", "      <td>-2.145314e+00</td>\n", "      <td>-1.236170e+00</td>\n", "      <td>-8.331620e-01</td>\n", "      <td>-8.554045e-01</td>\n", "      <td>-6.579525e-01</td>\n", "      <td>-3.629662e+00</td>\n", "      <td>-1.822413e+00</td>\n", "      <td>-2.263992e+00</td>\n", "    </tr>\n", "    <tr>\n", "      <th>25%</th>\n", "      <td>6.055048e-02</td>\n", "      <td>-5.153645e-01</td>\n", "      <td>-9.098486e-01</td>\n", "      <td>-1.062909e+00</td>\n", "      <td>-1.112669e+00</td>\n", "      <td>-9.630763e-01</td>\n", "      <td>-9.613917e-01</td>\n", "      <td>-5.081387e-01</td>\n", "      <td>-6.174901e-01</td>\n", "      <td>-4.727195e-01</td>\n", "      <td>...</td>\n", "      <td>-2.630443e-01</td>\n", "      <td>-6.075647e-01</td>\n", "      <td>-4.913748e-01</td>\n", "      <td>-5.157986e-01</td>\n", "      <td>-3.611281e-01</td>\n", "      <td>-2.867533e-01</td>\n", "      <td>-3.567399e-01</td>\n", "      <td>-8.182463e-01</td>\n", "      <td>-7.428247e-01</td>\n", "      <td>-7.274358e-01</td>\n", "    </tr>\n", "    <tr>\n", "      <th>50%</th>\n", "      <td>6.055048e-02</td>\n", "      <td>-5.153645e-01</td>\n", "      <td>4.413070e-01</td>\n", "      <td>7.728723e-01</td>\n", "      <td>1.280363e-01</td>\n", "      <td>-3.474496e-01</td>\n", "      <td>5.912984e-01</td>\n", "      <td>-1.349584e-01</td>\n", "      <td>1.371434e-01</td>\n", "      <td>-4.727195e-01</td>\n", "      <td>...</td>\n", "      <td>-1.225671e-01</td>\n", "      <td>-8.754500e-02</td>\n", "      <td>-2.052126e-02</td>\n", "      <td>-1.481819e-01</td>\n", "      <td>-1.425420e-01</td>\n", "      <td>-1.107031e-01</td>\n", "      <td>-1.666760e-01</td>\n", "      <td>-9.757162e-02</td>\n", "      <td>-1.758051e-01</td>\n", "      <td>-9.776744e-02</td>\n", "    </tr>\n", "    <tr>\n", "      <th>75%</th>\n", "      <td>6.055048e-02</td>\n", "      <td>3.904527e-01</td>\n", "      <td>9.238625e-01</td>\n", "      <td>7.728723e-01</td>\n", "      <td>1.280363e-01</td>\n", "      <td>2.681771e-01</td>\n", "      <td>5.912984e-01</td>\n", "      <td>6.114023e-01</td>\n", "      <td>8.917769e-01</td>\n", "      <td>-4.727195e-01</td>\n", "      <td>...</td>\n", "      <td>5.494964e-02</td>\n", "      <td>3.458047e-01</td>\n", "      <td>3.815560e-01</td>\n", "      <td>3.006240e-01</td>\n", "      <td>1.367581e-01</td>\n", "      <td>8.450031e-02</td>\n", "      <td>9.285201e-02</td>\n", "      <td>6.826247e-01</td>\n", "      <td>4.938631e-01</td>\n", "      <td>4.991145e-01</td>\n", "    </tr>\n", "    <tr>\n", "      <th>max</th>\n", "      <td>6.055048e-02</td>\n", "      <td>3.107904e+00</td>\n", "      <td>1.213396e+00</td>\n", "      <td>2.608653e+00</td>\n", "      <td>6.331565e+00</td>\n", "      <td>4.577564e+00</td>\n", "      <td>3.696679e+00</td>\n", "      <td>2.104124e+00</td>\n", "      <td>1.646410e+00</td>\n", "      <td>2.115420e+00</td>\n", "      <td>...</td>\n", "      <td>2.329899e+01</td>\n", "      <td>1.296110e+01</td>\n", "      <td>1.079730e+01</td>\n", "      <td>2.070026e+01</td>\n", "      <td>1.922514e+01</td>\n", "      <td>1.846433e+01</td>\n", "      <td>1.618922e+01</td>\n", "      <td>2.845718e+00</td>\n", "      <td>8.968854e+00</td>\n", "      <td>7.933529e+00</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>8 rows \u00d7 31 columns</p>\n", "</div>"], "text/plain": ["             Street   OverallCond  YearRemodAdd      FullBath  BedroomAbvGr  \\\n", "count  1.095000e+03  1.095000e+03  1.095000e+03  1.095000e+03  1.095000e+03   \n", "mean   3.617603e-16 -2.984928e-16 -3.202309e-15 -6.488975e-18  2.530700e-16   \n", "std    1.000457e+00  1.000457e+00  1.000457e+00  1.000457e+00  1.000457e+00   \n", "min   -1.651514e+01 -4.138633e+00 -1.681937e+00 -2.898690e+00 -3.594081e+00   \n", "25%    6.055048e-02 -5.153645e-01 -9.098486e-01 -1.062909e+00 -1.112669e+00   \n", "50%    6.055048e-02 -5.153645e-01  4.413070e-01  7.728723e-01  1.280363e-01   \n", "75%    6.055048e-02  3.904527e-01  9.238625e-01  7.728723e-01  1.280363e-01   \n", "max    6.055048e-02  3.107904e+00  1.213396e+00  2.608653e+00  6.331565e+00   \n", "\n", "       TotRmsAbvGrd    Fireplaces        MoSold        YrSold  \\\n", "count  1.095000e+03  1.095000e+03  1.095000e+03  1.095000e+03   \n", "mean  -6.813423e-17 -1.946692e-17  7.624545e-17  6.328535e-14   \n", "std    1.000457e+00  1.000457e+00  1.000457e+00  1.000457e+00   \n", "min   -2.809956e+00 -9.613917e-01 -2.000860e+00 -1.372124e+00   \n", "25%   -9.630763e-01 -9.613917e-01 -5.081387e-01 -6.174901e-01   \n", "50%   -3.474496e-01  5.912984e-01 -1.349584e-01  1.371434e-01   \n", "75%    2.681771e-01  5.912984e-01  6.114023e-01  8.917769e-01   \n", "max    4.577564e+00  3.696679e+00  2.104124e+00  1.646410e+00   \n", "\n", "       LotFrontage_Missing  ...  LotFrontage LotArea  LotFrontage OverallQual  \\\n", "count         1.095000e+03  ...         1.095000e+03             1.095000e+03   \n", "mean          9.084565e-17  ...         2.757814e-17            -1.492464e-16   \n", "std           1.000457e+00  ...         1.000457e+00             1.000457e+00   \n", "min          -4.727195e-01  ...        -5.924092e-01            -1.869094e+00   \n", "25%          -4.727195e-01  ...        -2.630443e-01            -6.075647e-01   \n", "50%          -4.727195e-01  ...        -1.225671e-01            -8.754500e-02   \n", "75%          -4.727195e-01  ...         5.494964e-02             3.458047e-01   \n", "max           2.115420e+00  ...         2.329899e+01             1.296110e+01   \n", "\n", "       LotFrontage YearBuilt  LotFrontage GrLivArea  LotArea OverallQual  \\\n", "count           1.095000e+03           1.095000e+03         1.095000e+03   \n", "mean            2.984928e-16          -5.191180e-17        -4.380058e-17   \n", "std             1.000457e+00           1.000457e+00         1.000457e+00   \n", "min            -2.145314e+00          -1.236170e+00        -8.331620e-01   \n", "25%            -4.913748e-01          -5.157986e-01        -3.611281e-01   \n", "50%            -2.052126e-02          -1.481819e-01        -1.425420e-01   \n", "75%             3.815560e-01           3.006240e-01         1.367581e-01   \n", "max             1.079730e+01           2.070026e+01         1.922514e+01   \n", "\n", "       LotArea YearBuilt  LotArea GrLivArea  OverallQual YearBuilt  \\\n", "count       1.095000e+03       1.095000e+03           1.095000e+03   \n", "mean        8.111218e-18       6.326750e-17           2.271141e-17   \n", "std         1.000457e+00       1.000457e+00           1.000457e+00   \n", "min        -8.554045e-01      -6.579525e-01          -3.629662e+00   \n", "25%        -2.867533e-01      -3.567399e-01          -8.182463e-01   \n", "50%        -1.107031e-01      -1.666760e-01          -9.757162e-02   \n", "75%         8.450031e-02       9.285201e-02           6.826247e-01   \n", "max         1.846433e+01       1.618922e+01           2.845718e+00   \n", "\n", "       OverallQual GrLivArea  YearBuilt GrLivArea  \n", "count           1.095000e+03         1.095000e+03  \n", "mean           -8.435667e-17        -1.460019e-16  \n", "std             1.000457e+00         1.000457e+00  \n", "min            -1.822413e+00        -2.263992e+00  \n", "25%            -7.428247e-01        -7.274358e-01  \n", "50%            -1.758051e-01        -9.776744e-02  \n", "75%             4.938631e-01         4.991145e-01  \n", "max             8.968854e+00         7.933529e+00  \n", "\n", "[8 rows x 31 columns]"]}, "execution_count": 55, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, now the means of the values are all much more centered. Let's see how the model performs now:"]}, {"cell_type": "code", "execution_count": 56, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0.75126826, 0.67341002, 0.80080353])"]}, "execution_count": 56, "metadata": {}, "output_type": "execute_result"}], "source": ["cross_val_score(model, X_train, y_train, cv=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Well, that was only a minor improvement over our first model. Seems like the interaction terms didn't provide that much information after all! There is plenty more feature engineering you could do if this were a real project, but we'll stop there.\n", "\n", "### Quick Scaling FAQs:\n", "\n", "1. **Do you only need to scale if you're using `PolynomialFeatures`?** No, we should have scaled regardless. `PolynomialFeatures` just exaggerated the difference in the units and caused the model to produce a warning, but it's a best practice to scale whenever your model has any distance-based metric. (In this case, the regularization within `ElasticNet` is distance-based.)\n", "2. **Do you really need to scale one-hot encoded features, if they are already just 0 or 1?** Professional opinions vary on this. Binary values already violate the assumptions of some models, so you might want to investigate empirically with your particular data and model whether you get better performance by scaling the one-hot encoded features or leaving them as just 0 and 1."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Preprocess Test Data\n", "\n", "> Apply Steps 1-5 to the test data in order to perform a final model evaluation.\n", "\n", "This part is done for you, and it should work automatically, assuming you didn't change the names of any of the transformer objects. Note that we are intentionally **not instantiating or fitting the transformers** here, because you always want to fit transformers on the training data only."]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Step 1: Drop Irrelevant Columns*"]}, {"cell_type": "code", "execution_count": 57, "metadata": {}, "outputs": [], "source": ["X_test = X_test.loc[:, relevant_columns]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Step 2: Handle Missing Values*"]}, {"cell_type": "code", "execution_count": 58, "metadata": {}, "outputs": [{"data": {"text/plain": ["LotFrontage            0\n", "LotArea                0\n", "Street                 0\n", "OverallQual            0\n", "OverallCond            0\n", "YearBuilt              0\n", "YearRemodAdd           0\n", "GrLivArea              0\n", "FullBath               0\n", "BedroomAbvGr           0\n", "TotRmsAbvGrd           0\n", "Fireplaces             0\n", "FireplaceQu            0\n", "MoSold                 0\n", "YrSold                 0\n", "LotFrontage_Missing    0\n", "dtype: int64"]}, "execution_count": 58, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Replace FireplaceQu NaNs with \"N/A\"s\n", "X_test[\"FireplaceQu\"] = X_test[\"FireplaceQu\"].fillna(\"N/A\")\n", "\n", "# Add missing indicator for lot frontage\n", "frontage_test = X_test[[\"LotFrontage\"]]\n", "frontage_missing_test = missing_indicator.transform(frontage_test)\n", "X_test[\"LotFrontage_Missing\"] = frontage_missing_test\n", "\n", "# Impute missing lot frontage values\n", "frontage_imputed_test = imputer.transform(frontage_test)\n", "X_test[\"LotFrontage\"] = frontage_imputed_test\n", "\n", "# Check that there are no more missing values\n", "X_test.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Step 3: Convert Categorical Features into Numbers*"]}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>LotFrontage</th>\n", "      <th>LotArea</th>\n", "      <th>Street</th>\n", "      <th>OverallQual</th>\n", "      <th>OverallCond</th>\n", "      <th>YearBuilt</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>GrLivArea</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>...</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>Ex</th>\n", "      <th>Fa</th>\n", "      <th>Gd</th>\n", "      <th>N/A</th>\n", "      <th>Po</th>\n", "      <th>TA</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>892</th>\n", "      <td>70.0</td>\n", "      <td>8414</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>8</td>\n", "      <td>1963</td>\n", "      <td>2003</td>\n", "      <td>1068</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>2</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1105</th>\n", "      <td>98.0</td>\n", "      <td>12256</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>5</td>\n", "      <td>1994</td>\n", "      <td>1995</td>\n", "      <td>2622</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>2010</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>413</th>\n", "      <td>56.0</td>\n", "      <td>8960</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>6</td>\n", "      <td>1927</td>\n", "      <td>1950</td>\n", "      <td>1028</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>2010</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>522</th>\n", "      <td>50.0</td>\n", "      <td>5000</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>7</td>\n", "      <td>1947</td>\n", "      <td>1950</td>\n", "      <td>1664</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>2</td>\n", "      <td>10</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1036</th>\n", "      <td>89.0</td>\n", "      <td>12898</td>\n", "      <td>1</td>\n", "      <td>9</td>\n", "      <td>5</td>\n", "      <td>2007</td>\n", "      <td>2008</td>\n", "      <td>1620</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>9</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>988</th>\n", "      <td>70.0</td>\n", "      <td>12046</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1976</td>\n", "      <td>1976</td>\n", "      <td>2030</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>243</th>\n", "      <td>75.0</td>\n", "      <td>10762</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>6</td>\n", "      <td>1980</td>\n", "      <td>1980</td>\n", "      <td>1217</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1342</th>\n", "      <td>70.0</td>\n", "      <td>9375</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>5</td>\n", "      <td>2002</td>\n", "      <td>2002</td>\n", "      <td>2169</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1057</th>\n", "      <td>70.0</td>\n", "      <td>29959</td>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>6</td>\n", "      <td>1994</td>\n", "      <td>1994</td>\n", "      <td>1850</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>2009</td>\n", "      <td>1</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1418</th>\n", "      <td>71.0</td>\n", "      <td>9204</td>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>5</td>\n", "      <td>1963</td>\n", "      <td>1963</td>\n", "      <td>1144</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>...</td>\n", "      <td>0</td>\n", "      <td>8</td>\n", "      <td>2008</td>\n", "      <td>0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>365 rows \u00d7 21 columns</p>\n", "</div>"], "text/plain": ["      LotFrontage  LotArea  Street  OverallQual  OverallCond  YearBuilt  \\\n", "892          70.0     8414       1            6            8       1963   \n", "1105         98.0    12256       1            8            5       1994   \n", "413          56.0     8960       1            5            6       1927   \n", "522          50.0     5000       1            6            7       1947   \n", "1036         89.0    12898       1            9            5       2007   \n", "...           ...      ...     ...          ...          ...        ...   \n", "988          70.0    12046       1            6            6       1976   \n", "243          75.0    10762       1            6            6       1980   \n", "1342         70.0     9375       1            8            5       2002   \n", "1057         70.0    29959       1            7            6       1994   \n", "1418         71.0     9204       1            5            5       1963   \n", "\n", "      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  ...  Fireplaces  \\\n", "892           2003       1068         1             3  ...           0   \n", "1105          1995       2622         2             3  ...           2   \n", "413           1950       1028         1             2  ...           1   \n", "522           1950       1664         2             3  ...           2   \n", "1036          2008       1620         2             2  ...           1   \n", "...            ...        ...       ...           ...  ...         ...   \n", "988           1976       2030         2             4  ...           1   \n", "243           1980       1217         1             3  ...           1   \n", "1342          2002       2169         2             3  ...           1   \n", "1057          1994       1850         2             3  ...           1   \n", "1418          1963       1144         1             3  ...           0   \n", "\n", "      MoSold  YrSold  LotFrontage_Missing   Ex   Fa   Gd  N/A   Po   TA  \n", "892        2    2006                    0  0.0  0.0  0.0  1.0  0.0  0.0  \n", "1105       4    2010                    0  0.0  0.0  0.0  0.0  0.0  1.0  \n", "413        3    2010                    0  0.0  0.0  1.0  0.0  0.0  0.0  \n", "522       10    2006                    0  0.0  0.0  1.0  0.0  0.0  0.0  \n", "1036       9    2009                    0  1.0  0.0  0.0  0.0  0.0  0.0  \n", "...      ...     ...                  ...  ...  ...  ...  ...  ...  ...  \n", "988        6    2007                    1  0.0  0.0  0.0  0.0  0.0  1.0  \n", "243        4    2009                    0  0.0  0.0  0.0  0.0  0.0  1.0  \n", "1342       8    2007                    1  0.0  0.0  1.0  0.0  0.0  0.0  \n", "1057       1    2009                    1  0.0  0.0  1.0  0.0  0.0  0.0  \n", "1418       8    2008                    0  0.0  0.0  0.0  1.0  0.0  0.0  \n", "\n", "[365 rows x 21 columns]"]}, "execution_count": 59, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Binarize street type\n", "street_test = X_test[\"Street\"]\n", "street_binarized_test = binarizer_street.transform(street_test)\n", "X_test[\"Street\"] = street_binarized_test\n", "\n", "# Binarize frontage missing\n", "frontage_missing_test = X_test[\"LotFrontage_Missing\"]\n", "frontage_missing_binarized_test = binarizer_frontage_missing.transform(frontage_missing_test)\n", "X_test[\"LotFrontage_Missing\"] = frontage_missing_binarized_test\n", "\n", "# One-hot encode fireplace quality\n", "fireplace_qu_test = X_test[[\"FireplaceQu\"]]\n", "fireplace_qu_encoded_test = ohe.transform(fireplace_qu_test)\n", "fireplace_qu_encoded_test = pd.DataFrame(\n", "    fireplace_qu_encoded_test,\n", "    columns=ohe.categories_[0],\n", "    index=X_test.index\n", ")\n", "X_test.drop(\"FireplaceQu\", axis=1, inplace=True)\n", "X_test = pd.concat([X_test, fireplace_qu_encoded_test], axis=1)\n", "\n", "# Visually inspect X_test\n", "X_test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Step 4: Add Interaction Terms*"]}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Street</th>\n", "      <th>OverallCond</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>...</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>892</th>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>2003</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>2</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>588980.0</td>\n", "      <td>420.0</td>\n", "      <td>137410.0</td>\n", "      <td>74760.0</td>\n", "      <td>50484.0</td>\n", "      <td>16516682.0</td>\n", "      <td>8986152.0</td>\n", "      <td>11778.0</td>\n", "      <td>6408.0</td>\n", "      <td>2096484.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1105</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>1995</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>9</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>2010</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>1201088.0</td>\n", "      <td>784.0</td>\n", "      <td>195412.0</td>\n", "      <td>256956.0</td>\n", "      <td>98048.0</td>\n", "      <td>24438464.0</td>\n", "      <td>32135232.0</td>\n", "      <td>15952.0</td>\n", "      <td>20976.0</td>\n", "      <td>5228268.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>413</th>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>1950</td>\n", "      <td>1</td>\n", "      <td>2</td>\n", "      <td>5</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>2010</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>501760.0</td>\n", "      <td>280.0</td>\n", "      <td>107912.0</td>\n", "      <td>57568.0</td>\n", "      <td>44800.0</td>\n", "      <td>17265920.0</td>\n", "      <td>9210880.0</td>\n", "      <td>9635.0</td>\n", "      <td>5140.0</td>\n", "      <td>1980956.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>522</th>\n", "      <td>1</td>\n", "      <td>7</td>\n", "      <td>1950</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>2</td>\n", "      <td>10</td>\n", "      <td>2006</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>250000.0</td>\n", "      <td>300.0</td>\n", "      <td>97350.0</td>\n", "      <td>83200.0</td>\n", "      <td>30000.0</td>\n", "      <td>9735000.0</td>\n", "      <td>8320000.0</td>\n", "      <td>11682.0</td>\n", "      <td>9984.0</td>\n", "      <td>3239808.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1036</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2008</td>\n", "      <td>2</td>\n", "      <td>2</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>9</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>1147922.0</td>\n", "      <td>801.0</td>\n", "      <td>178623.0</td>\n", "      <td>144180.0</td>\n", "      <td>116082.0</td>\n", "      <td>25886286.0</td>\n", "      <td>20894760.0</td>\n", "      <td>18063.0</td>\n", "      <td>14580.0</td>\n", "      <td>3251340.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>988</th>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>1976</td>\n", "      <td>2</td>\n", "      <td>4</td>\n", "      <td>8</td>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "      <td>...</td>\n", "      <td>843220.0</td>\n", "      <td>420.0</td>\n", "      <td>138320.0</td>\n", "      <td>142100.0</td>\n", "      <td>72276.0</td>\n", "      <td>23802896.0</td>\n", "      <td>24453380.0</td>\n", "      <td>11856.0</td>\n", "      <td>12180.0</td>\n", "      <td>4011280.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>243</th>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>1980</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>1</td>\n", "      <td>4</td>\n", "      <td>2009</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>807150.0</td>\n", "      <td>450.0</td>\n", "      <td>148500.0</td>\n", "      <td>91275.0</td>\n", "      <td>64572.0</td>\n", "      <td>21308760.0</td>\n", "      <td>13097354.0</td>\n", "      <td>11880.0</td>\n", "      <td>7302.0</td>\n", "      <td>2409660.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1342</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>2002</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>8</td>\n", "      <td>2007</td>\n", "      <td>1</td>\n", "      <td>...</td>\n", "      <td>656250.0</td>\n", "      <td>560.0</td>\n", "      <td>140140.0</td>\n", "      <td>151830.0</td>\n", "      <td>75000.0</td>\n", "      <td>18768750.0</td>\n", "      <td>20334375.0</td>\n", "      <td>16016.0</td>\n", "      <td>17352.0</td>\n", "      <td>4342338.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1057</th>\n", "      <td>1</td>\n", "      <td>6</td>\n", "      <td>1994</td>\n", "      <td>2</td>\n", "      <td>3</td>\n", "      <td>7</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>2009</td>\n", "      <td>1</td>\n", "      <td>...</td>\n", "      <td>2097130.0</td>\n", "      <td>490.0</td>\n", "      <td>139580.0</td>\n", "      <td>129500.0</td>\n", "      <td>209713.0</td>\n", "      <td>59738246.0</td>\n", "      <td>55424150.0</td>\n", "      <td>13958.0</td>\n", "      <td>12950.0</td>\n", "      <td>3688900.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1418</th>\n", "      <td>1</td>\n", "      <td>5</td>\n", "      <td>1963</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>6</td>\n", "      <td>0</td>\n", "      <td>8</td>\n", "      <td>2008</td>\n", "      <td>0</td>\n", "      <td>...</td>\n", "      <td>653484.0</td>\n", "      <td>355.0</td>\n", "      <td>139373.0</td>\n", "      <td>81224.0</td>\n", "      <td>46020.0</td>\n", "      <td>18067452.0</td>\n", "      <td>10529376.0</td>\n", "      <td>9815.0</td>\n", "      <td>5720.0</td>\n", "      <td>2245672.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>365 rows \u00d7 31 columns</p>\n", "</div>"], "text/plain": ["      Street  OverallCond  YearRemodAdd  FullBath  BedroomAbvGr  TotRmsAbvGrd  \\\n", "892        1            8          2003         1             3             6   \n", "1105       1            5          1995         2             3             9   \n", "413        1            6          1950         1             2             5   \n", "522        1            7          1950         2             3             7   \n", "1036       1            5          2008         2             2             6   \n", "...      ...          ...           ...       ...           ...           ...   \n", "988        1            6          1976         2             4             8   \n", "243        1            6          1980         1             3             6   \n", "1342       1            5          2002         2             3             7   \n", "1057       1            6          1994         2             3             7   \n", "1418       1            5          1963         1             3             6   \n", "\n", "      Fireplaces  MoSold  YrSold  LotFrontage_Missing  ...  \\\n", "892            0       2    2006                    0  ...   \n", "1105           2       4    2010                    0  ...   \n", "413            1       3    2010                    0  ...   \n", "522            2      10    2006                    0  ...   \n", "1036           1       9    2009                    0  ...   \n", "...          ...     ...     ...                  ...  ...   \n", "988            1       6    2007                    1  ...   \n", "243            1       4    2009                    0  ...   \n", "1342           1       8    2007                    1  ...   \n", "1057           1       1    2009                    1  ...   \n", "1418           0       8    2008                    0  ...   \n", "\n", "      LotFrontage LotArea  LotFrontage OverallQual  LotFrontage YearBuilt  \\\n", "892              588980.0                    420.0               137410.0   \n", "1105            1201088.0                    784.0               195412.0   \n", "413              501760.0                    280.0               107912.0   \n", "522              250000.0                    300.0                97350.0   \n", "1036            1147922.0                    801.0               178623.0   \n", "...                   ...                      ...                    ...   \n", "988              843220.0                    420.0               138320.0   \n", "243              807150.0                    450.0               148500.0   \n", "1342             656250.0                    560.0               140140.0   \n", "1057            2097130.0                    490.0               139580.0   \n", "1418             653484.0                    355.0               139373.0   \n", "\n", "      LotFrontage GrLivArea  LotArea OverallQual  LotArea YearBuilt  \\\n", "892                 74760.0              50484.0         16516682.0   \n", "1105               256956.0              98048.0         24438464.0   \n", "413                 57568.0              44800.0         17265920.0   \n", "522                 83200.0              30000.0          9735000.0   \n", "1036               144180.0             116082.0         25886286.0   \n", "...                     ...                  ...                ...   \n", "988                142100.0              72276.0         23802896.0   \n", "243                 91275.0              64572.0         21308760.0   \n", "1342               151830.0              75000.0         18768750.0   \n", "1057               129500.0             209713.0         59738246.0   \n", "1418                81224.0              46020.0         18067452.0   \n", "\n", "      LotArea GrLivArea  OverallQual YearBuilt  OverallQual GrLivArea  \\\n", "892           8986152.0                11778.0                 6408.0   \n", "1105         32135232.0                15952.0                20976.0   \n", "413           9210880.0                 9635.0                 5140.0   \n", "522           8320000.0                11682.0                 9984.0   \n", "1036         20894760.0                18063.0                14580.0   \n", "...                 ...                    ...                    ...   \n", "988          24453380.0                11856.0                12180.0   \n", "243          13097354.0                11880.0                 7302.0   \n", "1342         20334375.0                16016.0                17352.0   \n", "1057         55424150.0                13958.0                12950.0   \n", "1418         10529376.0                 9815.0                 5720.0   \n", "\n", "      YearBuilt GrLivArea  \n", "892             2096484.0  \n", "1105            5228268.0  \n", "413             1980956.0  \n", "522             3239808.0  \n", "1036            3251340.0  \n", "...                   ...  \n", "988             4011280.0  \n", "243             2409660.0  \n", "1342            4342338.0  \n", "1057            3688900.0  \n", "1418            2245672.0  \n", "\n", "[365 rows x 31 columns]"]}, "execution_count": 60, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# (1) select relevant data\n", "poly_columns_test = X_test[poly_column_names]\n", "\n", "# (4) transform using fitted transformer\n", "poly_columns_expanded_test = poly.transform(poly_columns_test) \n", "\n", "# (5) add back to original dataset\n", "poly_columns_expanded_test = pd.DataFrame(\n", "    poly_columns_expanded_test,\n", "    columns=poly.get_feature_names(poly_column_names),\n", "    index=X_test.index\n", ")\n", "X_test.drop(poly_column_names, axis=1, inplace=True)\n", "X_test = pd.concat([X_test, poly_columns_expanded_test], axis=1)\n", "\n", "# Visually inspect X_test\n", "X_test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Step 5: Scale Data*"]}, {"cell_type": "code", "execution_count": 61, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Street</th>\n", "      <th>OverallCond</th>\n", "      <th>YearRemodAdd</th>\n", "      <th>FullBath</th>\n", "      <th>BedroomAbvGr</th>\n", "      <th>TotRmsAbvGrd</th>\n", "      <th>Fireplaces</th>\n", "      <th>MoSold</th>\n", "      <th>YrSold</th>\n", "      <th>LotFrontage_Missing</th>\n", "      <th>...</th>\n", "      <th>LotFrontage LotArea</th>\n", "      <th>LotFrontage OverallQual</th>\n", "      <th>LotFrontage YearBuilt</th>\n", "      <th>LotFrontage GrLivArea</th>\n", "      <th>LotArea OverallQual</th>\n", "      <th>LotArea YearBuilt</th>\n", "      <th>LotArea GrLivArea</th>\n", "      <th>OverallQual YearBuilt</th>\n", "      <th>OverallQual GrLivArea</th>\n", "      <th>YearBuilt GrLivArea</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>892</th>\n", "      <td>0.06055</td>\n", "      <td>2.202087</td>\n", "      <td>0.875607</td>\n", "      <td>-1.062909</td>\n", "      <td>0.128036</td>\n", "      <td>-0.347450</td>\n", "      <td>-0.961392</td>\n", "      <td>-1.627680</td>\n", "      <td>-1.372124</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.179133</td>\n", "      <td>-0.087545</td>\n", "      <td>-0.028237</td>\n", "      <td>-0.466080</td>\n", "      <td>-0.225635</td>\n", "      <td>-0.214633</td>\n", "      <td>-0.347611</td>\n", "      <td>-0.116818</td>\n", "      <td>-0.653741</td>\n", "      <td>-0.882713</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1105</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>0.489563</td>\n", "      <td>0.772872</td>\n", "      <td>0.128036</td>\n", "      <td>1.499430</td>\n", "      <td>2.143989</td>\n", "      <td>-0.881319</td>\n", "      <td>1.646410</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>0.274247</td>\n", "      <td>1.665114</td>\n", "      <td>1.250343</td>\n", "      <td>1.814226</td>\n", "      <td>0.409674</td>\n", "      <td>0.149432</td>\n", "      <td>0.544200</td>\n", "      <td>1.370866</td>\n", "      <td>2.149226</td>\n", "      <td>2.107822</td>\n", "    </tr>\n", "    <tr>\n", "      <th>413</th>\n", "      <td>0.06055</td>\n", "      <td>0.390453</td>\n", "      <td>-1.681937</td>\n", "      <td>-1.062909</td>\n", "      <td>-1.112669</td>\n", "      <td>-0.963076</td>\n", "      <td>0.591298</td>\n", "      <td>-1.254499</td>\n", "      <td>1.646410</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.243736</td>\n", "      <td>-0.761645</td>\n", "      <td>-0.678482</td>\n", "      <td>-0.681250</td>\n", "      <td>-0.301556</td>\n", "      <td>-0.180200</td>\n", "      <td>-0.338954</td>\n", "      <td>-0.880619</td>\n", "      <td>-0.897711</td>\n", "      <td>-0.993030</td>\n", "    </tr>\n", "    <tr>\n", "      <th>522</th>\n", "      <td>0.06055</td>\n", "      <td>1.296270</td>\n", "      <td>-1.681937</td>\n", "      <td>0.772872</td>\n", "      <td>0.128036</td>\n", "      <td>0.268177</td>\n", "      <td>2.143989</td>\n", "      <td>1.357763</td>\n", "      <td>-1.372124</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.430211</td>\n", "      <td>-0.665345</td>\n", "      <td>-0.911307</td>\n", "      <td>-0.360448</td>\n", "      <td>-0.499239</td>\n", "      <td>-0.526303</td>\n", "      <td>-0.373275</td>\n", "      <td>-0.151034</td>\n", "      <td>0.034302</td>\n", "      <td>0.209045</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1036</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>1.116885</td>\n", "      <td>0.772872</td>\n", "      <td>-1.112669</td>\n", "      <td>-0.347450</td>\n", "      <td>0.591298</td>\n", "      <td>0.984583</td>\n", "      <td>0.891777</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>0.234868</td>\n", "      <td>1.746969</td>\n", "      <td>0.880251</td>\n", "      <td>0.402758</td>\n", "      <td>0.650552</td>\n", "      <td>0.215970</td>\n", "      <td>0.111164</td>\n", "      <td>2.123261</td>\n", "      <td>0.918599</td>\n", "      <td>0.220057</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>988</th>\n", "      <td>0.06055</td>\n", "      <td>0.390453</td>\n", "      <td>-0.427293</td>\n", "      <td>0.772872</td>\n", "      <td>1.368742</td>\n", "      <td>0.883804</td>\n", "      <td>0.591298</td>\n", "      <td>-0.134958</td>\n", "      <td>-0.617490</td>\n", "      <td>2.115420</td>\n", "      <td>...</td>\n", "      <td>0.009179</td>\n", "      <td>-0.087545</td>\n", "      <td>-0.008177</td>\n", "      <td>0.376726</td>\n", "      <td>0.065439</td>\n", "      <td>0.120223</td>\n", "      <td>0.248259</td>\n", "      <td>-0.089018</td>\n", "      <td>0.456825</td>\n", "      <td>0.945722</td>\n", "    </tr>\n", "    <tr>\n", "      <th>243</th>\n", "      <td>0.06055</td>\n", "      <td>0.390453</td>\n", "      <td>-0.234271</td>\n", "      <td>-1.062909</td>\n", "      <td>0.128036</td>\n", "      <td>-0.347450</td>\n", "      <td>0.591298</td>\n", "      <td>-0.881319</td>\n", "      <td>0.891777</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.017538</td>\n", "      <td>0.056905</td>\n", "      <td>0.216228</td>\n", "      <td>-0.259384</td>\n", "      <td>-0.037463</td>\n", "      <td>0.005599</td>\n", "      <td>-0.189229</td>\n", "      <td>-0.080464</td>\n", "      <td>-0.481730</td>\n", "      <td>-0.583662</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1342</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>0.827351</td>\n", "      <td>0.772872</td>\n", "      <td>0.128036</td>\n", "      <td>0.268177</td>\n", "      <td>0.591298</td>\n", "      <td>0.611402</td>\n", "      <td>-0.617490</td>\n", "      <td>2.115420</td>\n", "      <td>...</td>\n", "      <td>-0.129307</td>\n", "      <td>0.586555</td>\n", "      <td>0.031943</td>\n", "      <td>0.498503</td>\n", "      <td>0.101823</td>\n", "      <td>-0.111134</td>\n", "      <td>0.089575</td>\n", "      <td>1.393676</td>\n", "      <td>1.451947</td>\n", "      <td>1.261849</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1057</th>\n", "      <td>0.06055</td>\n", "      <td>0.390453</td>\n", "      <td>0.441307</td>\n", "      <td>0.772872</td>\n", "      <td>0.128036</td>\n", "      <td>0.268177</td>\n", "      <td>0.591298</td>\n", "      <td>-2.000860</td>\n", "      <td>0.891777</td>\n", "      <td>2.115420</td>\n", "      <td>...</td>\n", "      <td>0.937934</td>\n", "      <td>0.249505</td>\n", "      <td>0.019598</td>\n", "      <td>0.219028</td>\n", "      <td>1.901175</td>\n", "      <td>1.771722</td>\n", "      <td>1.441398</td>\n", "      <td>0.660170</td>\n", "      <td>0.604977</td>\n", "      <td>0.637882</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1418</th>\n", "      <td>0.06055</td>\n", "      <td>-0.515364</td>\n", "      <td>-1.054615</td>\n", "      <td>-1.062909</td>\n", "      <td>0.128036</td>\n", "      <td>-0.347450</td>\n", "      <td>-0.961392</td>\n", "      <td>0.611402</td>\n", "      <td>0.137143</td>\n", "      <td>-0.472719</td>\n", "      <td>...</td>\n", "      <td>-0.131356</td>\n", "      <td>-0.400520</td>\n", "      <td>0.015035</td>\n", "      <td>-0.385179</td>\n", "      <td>-0.285261</td>\n", "      <td>-0.143364</td>\n", "      <td>-0.288159</td>\n", "      <td>-0.816464</td>\n", "      <td>-0.786116</td>\n", "      <td>-0.740253</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>365 rows \u00d7 31 columns</p>\n", "</div>"], "text/plain": ["       Street  OverallCond  YearRemodAdd  FullBath  BedroomAbvGr  \\\n", "892   0.06055     2.202087      0.875607 -1.062909      0.128036   \n", "1105  0.06055    -0.515364      0.489563  0.772872      0.128036   \n", "413   0.06055     0.390453     -1.681937 -1.062909     -1.112669   \n", "522   0.06055     1.296270     -1.681937  0.772872      0.128036   \n", "1036  0.06055    -0.515364      1.116885  0.772872     -1.112669   \n", "...       ...          ...           ...       ...           ...   \n", "988   0.06055     0.390453     -0.427293  0.772872      1.368742   \n", "243   0.06055     0.390453     -0.234271 -1.062909      0.128036   \n", "1342  0.06055    -0.515364      0.827351  0.772872      0.128036   \n", "1057  0.06055     0.390453      0.441307  0.772872      0.128036   \n", "1418  0.06055    -0.515364     -1.054615 -1.062909      0.128036   \n", "\n", "      TotRmsAbvGrd  Fireplaces    MoSold    YrSold  LotFrontage_Missing  ...  \\\n", "892      -0.347450   -0.961392 -1.627680 -1.372124            -0.472719  ...   \n", "1105      1.499430    2.143989 -0.881319  1.646410            -0.472719  ...   \n", "413      -0.963076    0.591298 -1.254499  1.646410            -0.472719  ...   \n", "522       0.268177    2.143989  1.357763 -1.372124            -0.472719  ...   \n", "1036     -0.347450    0.591298  0.984583  0.891777            -0.472719  ...   \n", "...            ...         ...       ...       ...                  ...  ...   \n", "988       0.883804    0.591298 -0.134958 -0.617490             2.115420  ...   \n", "243      -0.347450    0.591298 -0.881319  0.891777            -0.472719  ...   \n", "1342      0.268177    0.591298  0.611402 -0.617490             2.115420  ...   \n", "1057      0.268177    0.591298 -2.000860  0.891777             2.115420  ...   \n", "1418     -0.347450   -0.961392  0.611402  0.137143            -0.472719  ...   \n", "\n", "      LotFrontage LotArea  LotFrontage OverallQual  LotFrontage YearBuilt  \\\n", "892             -0.179133                -0.087545              -0.028237   \n", "1105             0.274247                 1.665114               1.250343   \n", "413             -0.243736                -0.761645              -0.678482   \n", "522             -0.430211                -0.665345              -0.911307   \n", "1036             0.234868                 1.746969               0.880251   \n", "...                   ...                      ...                    ...   \n", "988              0.009179                -0.087545              -0.008177   \n", "243             -0.017538                 0.056905               0.216228   \n", "1342            -0.129307                 0.586555               0.031943   \n", "1057             0.937934                 0.249505               0.019598   \n", "1418            -0.131356                -0.400520               0.015035   \n", "\n", "      LotFrontage GrLivArea  LotArea OverallQual  LotArea YearBuilt  \\\n", "892               -0.466080            -0.225635          -0.214633   \n", "1105               1.814226             0.409674           0.149432   \n", "413               -0.681250            -0.301556          -0.180200   \n", "522               -0.360448            -0.499239          -0.526303   \n", "1036               0.402758             0.650552           0.215970   \n", "...                     ...                  ...                ...   \n", "988                0.376726             0.065439           0.120223   \n", "243               -0.259384            -0.037463           0.005599   \n", "1342               0.498503             0.101823          -0.111134   \n", "1057               0.219028             1.901175           1.771722   \n", "1418              -0.385179            -0.285261          -0.143364   \n", "\n", "      LotArea GrLivArea  OverallQual YearBuilt  OverallQual GrLivArea  \\\n", "892           -0.347611              -0.116818              -0.653741   \n", "1105           0.544200               1.370866               2.149226   \n", "413           -0.338954              -0.880619              -0.897711   \n", "522           -0.373275              -0.151034               0.034302   \n", "1036           0.111164               2.123261               0.918599   \n", "...                 ...                    ...                    ...   \n", "988            0.248259              -0.089018               0.456825   \n", "243           -0.189229              -0.080464              -0.481730   \n", "1342           0.089575               1.393676               1.451947   \n", "1057           1.441398               0.660170               0.604977   \n", "1418          -0.288159              -0.816464              -0.786116   \n", "\n", "      YearBuilt GrLivArea  \n", "892             -0.882713  \n", "1105             2.107822  \n", "413             -0.993030  \n", "522              0.209045  \n", "1036             0.220057  \n", "...                   ...  \n", "988              0.945722  \n", "243             -0.583662  \n", "1342             1.261849  \n", "1057             0.637882  \n", "1418            -0.740253  \n", "\n", "[365 rows x 31 columns]"]}, "execution_count": 61, "metadata": {}, "output_type": "execute_result"}], "source": ["X_test_scaled = scaler.transform(X_test)\n", "X_test = pd.DataFrame(\n", "    X_test_scaled,\n", "    columns=X_test.columns,\n", "    index=X_test.index\n", ")\n", "X_test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit the model on the full training set, evaluate on test set:"]}, {"cell_type": "code", "execution_count": 62, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.7943110080438888"]}, "execution_count": 62, "metadata": {}, "output_type": "execute_result"}], "source": ["model.fit(X_train, y_train)\n", "model.score(X_test, y_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great, that worked! Now we have completed the full process of preprocessing the Ames Housing data in preparation for machine learning!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "In this cumulative lab, you used various techniques to prepare the Ames Housing data for modeling. You filtered down the full dataset to only relevant columns, filled in missing values, converted categorical data into numeric data, added interaction terms, and scaled the data. Each time, you practiced the scikit-learn transformer workflow by instantiating the transformer, fitting on the relevant training data, transforming the training data, and transforming the test data at the end (without re-instantiating or re-fitting the transformer object)."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}